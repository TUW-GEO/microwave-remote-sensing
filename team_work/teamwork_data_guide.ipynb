{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Team work: Handling of available data\n",
    "\n",
    "For testing your hypothesis in the team work part of the course, different datasets are provided:\n",
    "\n",
    "- [EODC STAC Catalog](https://services.eodc.eu/browser/#/v1/): Sentinel-1 and other datasets\n",
    "- Data on JupyterHub:\n",
    "    - Data used within the hands-on exercise (`~/shared/datasets/rs`): ALOS, ASCAT, soil moisture, ...\n",
    "    - Austrian Datacube (`~/shared/datasets/fe/data`): Sentinel-1, Sentinel-2, Corine Land Cover, ...\n",
    "- Additionally, you can bring in your own datasets or access other STAC catalogs.\n",
    "\n",
    "In this notebook, examples are given how to access the different data sources through the JupyterHub. All shown methods aim to load a `xarray` object, which allows to use many predefined functions and offers a detailed [documentdation](https://docs.xarray.dev/). Besides that you can also work in QGIS, run local Python environments on you own PC or pick tools you are used to. Please be aware that your work needs to end up in a report and presentation at the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## STAC data access\n",
    "\n",
    "Here, a quick recap of [Unit 1]() of the course on how to access data available through STAC. For more details re-visit the corresponding notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import pystac_client\n",
    "from odc import stac as odc_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "EODC offers a lot of datasets through STAC, but be aware that not all might be accessible. To get an overview, have a look at the collections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collections provided by the EODC STAC Catalog\n",
    "eodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n",
    "collections = eodc_catalog.get_collections()\n",
    "\n",
    "max_length = max(len(collection.id) for collection in collections)\n",
    "for collection in eodc_catalog.get_collections():\n",
    "    print(f\"{collection.id.ljust(max_length)}: {collection.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "We will now load Sentinel-1 data for the area of Innsbruck from STAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = \"2022-03-01/2022-03-31\"\n",
    "innsbruck_bbox = [11.070099, 47.148400, 11.729279, 47.380219]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_collection_id = \"SENTINEL1_SIG0_20M\"\n",
    "search = eodc_catalog.search(\n",
    "    collections=s1_collection_id,\n",
    "    bbox=innsbruck_bbox,\n",
    "    datetime=time_range,\n",
    ")\n",
    "s1_items = search.item_collection()\n",
    "len(s1_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = \"VV\"\n",
    "chunks = {\"time\": 1, \"latitude\": 500, \"longitude\": 500}\n",
    "\n",
    "sig0_dc = odc_stac.load(\n",
    "    s1_items,\n",
    "    bands=bands,\n",
    "    crs=\"EPSG:27704\",\n",
    "    resolution=20,\n",
    "    bbox=innsbruck_bbox,\n",
    "    chunks=chunks,\n",
    "    resampling=\"bilinear\",\n",
    ")\n",
    "\n",
    "scale = s1_items[0].assets[\"VV\"].extra_fields.get(\"raster:bands\")[0][\"scale\"]\n",
    "nodata = s1_items[0].assets[\"VV\"].extra_fields.get(\"raster:bands\")[0][\"nodata\"]\n",
    "sig0_dc = sig0_dc.where(sig0_dc != nodata) / scale\n",
    "sig0_dc = sig0_dc.dropna(dim=\"time\")\n",
    "sig0_dc.VV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig0_mean = sig0_dc.mean(dim=\"time\", skipna=True)\n",
    "sig0_mean.VV.plot(robust=True, cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sig0_dc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Data on JupyterHub\n",
    "\n",
    "Besides the data you saw in the hand-on exercises, the Austrian Datacube (=ACube) is available through the JupyterHub. You can find the data under: `/shared/datasets/fe/data`\n",
    "\n",
    "Currently, there are 3 types of datasets available:\n",
    "\n",
    "- Sentinel-1 data\n",
    "- Sentinel-2 data\n",
    "- Auxiliary data\n",
    "\n",
    "### Data structure\n",
    "\n",
    "The data is projected and tiled based on the Equi7Grid. Therefore, all datasets follow the same folder structure:\n",
    "\n",
    "PRODUCT / SUBGRID / TILE / LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Consequently, we can define our input paths like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = Path(r\"~/shared/datasets/fe/data\").expanduser()\n",
    "# additional data for team part\n",
    "\n",
    "res = 10  # 10m or 500m\n",
    "sentinel1_parameter_path = (\n",
    "    source_path / \"sentinel1\" / \"parameters\" / (f\"EU{str(res).zfill(3)}M\")\n",
    ")\n",
    "sentinel1_preprocessed_path = (\n",
    "    source_path / \"sentinel1\" / \"preprocessed\" / (f\"EU{str(res).zfill(3)}M\")\n",
    ")\n",
    "sentinel2_path = source_path / \"sentinel2\" / \"L2A\" / \"EU010M\"\n",
    "\n",
    "sentinel1_parameter_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Once the input paths are defined, one can collect the required data. In the following examples, you can see how single or multiple files can be loaded as xarray object.\n",
    "\n",
    "#### Sentinel-1 (single file)\n",
    "How to load a single Sentinel-1 observation file:\n",
    "- Collect file from file system\n",
    "- Load it as `xarray.DataSet`\n",
    "- Prepare the data for further usage (decoding and clean-up)\n",
    "- Work with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acube_s1_preprocess(x: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"Decode and clean up Sentinel-1 ACube data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : xarray.Dataset\n",
    "        Input dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.Dataset\n",
    "\n",
    "    \"\"\"\n",
    "    path = Path(x.encoding[\"source\"])\n",
    "    filename = path.name\n",
    "\n",
    "    date_str = filename.split(\"_\")[0][1:]\n",
    "    time_str = filename.split(\"_\")[1][:6]\n",
    "    datetime_str = date_str + time_str\n",
    "    date = pd.to_datetime(datetime_str, format=\"%Y%m%d%H%M%S\")\n",
    "    x = x.expand_dims(dim={\"time\": [date]})\n",
    "\n",
    "    x = (\n",
    "        x.rename({\"band_data\": \"s1_\" + path.parent.stem})\n",
    "        .squeeze(\"band\")\n",
    "        .drop_vars(\"band\")\n",
    "    )\n",
    "\n",
    "    return x * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_path = (\n",
    "    sentinel1_preprocessed_path\n",
    "    / \"E051N015T1\"\n",
    "    / \"sig0\"\n",
    "    / \"D20210122_165830--_SIG0-----_S1BIWGRDH1VVA_044_A0105_EU010M_E051N015T1.tif\"\n",
    ")\n",
    "\n",
    "s1 = xr.open_dataset(\n",
    "    single_path,\n",
    "    engine=\"rasterio\",\n",
    ")\n",
    "s1 = acube_s1_preprocess(s1)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data\n",
    "s1.hvplot.image(robust=True, data_aspect=1, cmap=\"Greys_r\", rasterize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "del s1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Sentinel-1 (multiple files)\n",
    "Similar to the hands-on exercises, one can load multiple Sentinel-1 files at once, but be aware of the limited availability of memory in the JupyterHub. It is suggested to use the provided statistical parameters (introduced below) instead of loading multi-temporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_path = single_path = sentinel1_preprocessed_path / \"E051N015T1\" / \"sig0\"\n",
    "sig0_day_paths = list(tile_path.glob(\"D20210122*S1*IWGRDH1VV*.tif\"))\n",
    "len(sig0_day_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_day = xr.open_mfdataset(\n",
    "    sig0_day_paths,\n",
    "    engine=\"rasterio\",\n",
    "    combine=\"nested\",\n",
    "    chunks=-1,\n",
    "    preprocess=acube_s1_preprocess,\n",
    ")\n",
    "\n",
    "s1_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_day = s1_day.mean(dim=\"time\", skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_day.hvplot.image(robust=True, data_aspect=1, cmap=\"Greys_r\", rasterize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "del s1_day\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Sentinel-1 (parameters)\n",
    "Parameters are statistics based on the Sentinel-1 backscatter and they are provided under: `~/shared/data/sentinel1/parameters`\n",
    "\n",
    "The most relevant statistical parameters are:\n",
    "\n",
    "- tmaxsig0: Maximum SIG0 backscatter per relative orbit\n",
    "- tmaxsig38: Maximum SIG0 backscatter normalized to an incidence angle of 38 degree\n",
    "- tmensig0: Average SIG0 backscatter per relative orbit\n",
    "- tmensig38: Average SIG0 backscatter normalized to an incidence angle of 38 degree\n",
    "- tminsig0: Minimum SIG0 backscatter per relative orbit\n",
    "- tminsig38: Minimum SIG0 backscatter normalized to an incidence angle of 38 degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_path = (\n",
    "    sentinel1_parameter_path\n",
    "    / \"E051N015T1\"\n",
    "    / \"tmensig0\"\n",
    "    / \"M20160101_20171231_TMENSIG0-_S1-IWGRDH1VV-_124_B0104_EU010M_E051N015T1.tif\"\n",
    ")\n",
    "\n",
    "par = xr.open_dataset(\n",
    "    par_path,\n",
    "    engine=\"rasterio\",\n",
    ")\n",
    "par = acube_s1_preprocess(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "par.hvplot.image(robust=True, data_aspect=1, cmap=\"Greys_r\", rasterize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "del par\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Sentinel-2\n",
    "Sentinel-2 data is available under `~/shared/datasets/fe/data/sentinel2`\n",
    "\n",
    "In this example, we will load the true-color image (TCI), but the dataset contains all the available bands from Sentinel-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_path = (\n",
    "    sentinel2_path\n",
    "    / \"E051N015T1\"\n",
    "    / \"tci\"\n",
    "    / \"TCI-------_SEN2COR_S2B_L2A------_20210125_20210125_EU010M_E051N015T1.tif\"\n",
    ")\n",
    "\n",
    "s2 = xr.open_dataset(\n",
    "    s2_path,\n",
    "    engine=\"rasterio\",\n",
    ")\n",
    "s2.coords[\"band\"] = [0, 1, 2]\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.hvplot.rgb(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    bands=\"band\",\n",
    "    rasterize=True,\n",
    "    xlabel=\"x\",\n",
    "    ylabel=\"y\",\n",
    ").redim.nodata(z=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "del s2\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrs-env",
   "language": "python",
   "name": "mrs-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
