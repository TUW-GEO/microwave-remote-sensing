[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JupyterHub Guide",
    "section": "",
    "text": "JupyterHub Guide\nThis is a short guide to create and run the notbooks and environments in the JupiterHub for the Master course Microwave Remote Sensing (120.030) at the TU Wien.",
    "crumbs": [
      "JupyterHub Guide"
    ]
  },
  {
    "objectID": "index.html#starting-jupyterhub",
    "href": "index.html#starting-jupyterhub",
    "title": "JupyterHub Guide",
    "section": "Starting JupyterHub",
    "text": "Starting JupyterHub\nIn TUWEL, click on the JupyterHub icon , which redirects you to your own JupyterLab user environment. You should then select the image for the 120.030 Microwave Remote Sensing 2025W: Science Notebook. Be patient - this can take a couple of minutes.\n\n\n\nPlease note that all screenshots in this guide refer to the lecture 120.030 Microwave Remote Sensing (2025W), even if a few things are different for you, the overall functionality and interface remain the same.",
    "crumbs": [
      "JupyterHub Guide"
    ]
  },
  {
    "objectID": "index.html#exploring-jupyterlab",
    "href": "index.html#exploring-jupyterlab",
    "title": "JupyterHub Guide",
    "section": "Exploring JupyterLab",
    "text": "Exploring JupyterLab\nWhen you start your server for the first time, your point of entry will be this starting page:\n\n\n\nIn the center, you have the Launcher where you can create Python or other files, play around with Jupyter Notebooks, store intermediate data. You can also open a Python console, a terminal, a text file, and many more. On the left, you can see your home directory where you have the folders microwave-remote-sensing, lectures and shared. There might be other folders as well, but don’t be concerned about them. The folder microwave-remote-sensing contains the course materials.\n\n\nAfter some intense coding and analysis, it can happen that you have many terminal and notebook tabs open. However, simply closing them does not quit the processes and running kernels in the background. Therefore, we recommend that you tidy up your running processes after some time, which can be done as marked by the top-left circle. As an overview, the number of running kernels and terminals are always shown at the bottom-left corner.",
    "crumbs": [
      "JupyterHub Guide"
    ]
  },
  {
    "objectID": "index.html#fetch-jupyter-notebooks",
    "href": "index.html#fetch-jupyter-notebooks",
    "title": "JupyterHub Guide",
    "section": "Fetch Jupyter Notebooks",
    "text": "Fetch Jupyter Notebooks\nThe Jupyter notebooks for the course can be obtained by executing the following command from the terminal line.\nStart by launching a terminal.\n\nThen type the following at the prompt.\ngit clone --depth=1 --branch tuwel https://github.com/TUW-GEO/microwave-remote-sensing.git",
    "crumbs": [
      "JupyterHub Guide"
    ]
  },
  {
    "objectID": "index.html#editing-jupyter-notebooks",
    "href": "index.html#editing-jupyter-notebooks",
    "title": "JupyterHub Guide",
    "section": "Editing Jupyter Notebooks",
    "text": "Editing Jupyter Notebooks\nThe homework exercises of the course are labeled as homework_exercise.ipynb. You are supposed to use these notebooks for the homework assignments and the completed notebooks should be submitted through TUWEL. The notebooks consist of two types of cells: Python and Markdown cells. Python cells contain executable Python code, whereas Markdown cells are used for open text and multiple choice questions. Double click on an existing cell to alter its content. To add new cells click select the cell type from the drop-down menu and click on the plus sign, as follows for Python cells:\n\nAnd for Markdown cells:\n\nFor the multiple choice questions double click on the Markdown cell and replace the correct answers, as follows:\n- [ ] Original\n- [x] Selected answer\n\nOriginal\nSelected answer\n\nTo save your work use the drop-down menu under File and select Save Notebook or use the shortcut CTRL + S.",
    "crumbs": [
      "JupyterHub Guide"
    ]
  },
  {
    "objectID": "unit_01/01_in_class_exercise.html",
    "href": "unit_01/01_in_class_exercise.html",
    "title": "1  Discover and Read SAR Data",
    "section": "",
    "text": "1.1 Data Discovery\nThis notebook demonstrates how to access radar data in a SpatioTemporal Asset Catalog (STAC) Catalog using the pystac library. In this example, we use Sentinel-1 data from the EODC (earth observation data and high performance computing service provider based in Vienna) STAC catalog. In the further process, we will learn how to query a STAC catalog, select specific items, and display the metadata and the actual image.\neodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n\neodc_catalog\n\n\n\n\n\n\n    &lt;Client id=stac-fastapi&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Catalog\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"stac-fastapi\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"A STAC-compliant API to query for metadata within the EODC Data Catalogue.\"\n        \n    \n                \n            \n                \n                    \n        links[] 9 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Root\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/collections\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Collections available for this Catalog\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"conformance\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/conformance\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC/OGC conformance classes implemented by this server\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search [GET]\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search [POST]\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"POST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables available for this Catalog\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        \n            rel\n            \"service-desc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/openapi.json\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd.oai.openapi+json;version=3.0\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service description\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        \n            rel\n            \"service-doc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/docs\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service documentation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        conformsTo[] 28 items\n        \n            \n        \n            \n                \n        \n            0\n            \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"http://www.opengis.net/spec/ogcapi-common-2/1.0/conf/simple-query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/features-filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#free-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"https://api.stacspec.org/v1.0.0-rc.2/item-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"https://api.stacspec.org/v1.0.0/collections\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"https://api.stacspec.org/v1.0.0/collections/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"https://api.stacspec.org/v1.0.0/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"https://api.stacspec.org/v1.0.0/item-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"https://api.stacspec.org/v1.0.0/item-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            21\n            \"https://api.stacspec.org/v1.0.0/item-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            22\n            \"https://api.stacspec.org/v1.0.0/item-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            23\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            24\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            25\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            26\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            27\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"EODC Data Catalogue\"\nThe URL https://stac.eodc.eu/api/v1, served over Hypertext Transfer Protocol (HTTP), is a STAC-compliant API endpoint (specific URL address where an API service is available) that leads to the EODC catalog. Besides EODC’s, other catalogs can be found on STAC Index, such as United States Geological Survey (USGS) Landsat imagery, Sentinel Hub, Copernicus Data Space Ecosystem, and so on. Briefly spoken, STAC can be used to search, discover, and access metadata of these datasets with the same code. The EODC STAC catalog can be accessed on the web via this link as well.\nEach STAC catalog, composed by different providers, has many collections. To get all collections of a catalog, we can print all of them and their ids, which are used to fetch them from the catalog.\ncollections = eodc_catalog.get_collections()\n\n# length of string of collection.id, for pretty print\nmax_length = max(len(collection.id) for collection in collections)\n\nfor collection in eodc_catalog.get_collections():\n    print(f\"{collection.id.ljust(max_length)}: {collection.title}\")\n\nAI4SAR_SIG0                      : AI4SAR Despeckled Sentinel-1 Sigma0 (20m)\nASA_IMP_1P                       : Envisat ASAR Image Mode Precision Level-1\nASA_IMS_1P                       : Envisat ASAR Image Mode Single Look Complex Level-1\nAUSTRIA_GROUND_MOTION            : Austria Ground Motion\nAUT_DEM                          : Austrian High Resolution DEM\nBOA_LANDSAT_8                    : Bottom of Atmosphere Landsat-8 at 30m resolution.\nBOA_SENTINEL_2                   : Bottom of Atmosphere Sentinel-2 at 10m resolution.\nCGLS_SSM_1KM                     : Copernicus Global Land Surface Soil Moisture\nCOP_DEM                          : Copernicus Digital Elevation Model (DEM)\nCORINE_LAND_COVER                : Corine Land Cover\nDOP_AUT_K_KLAGENFURT             : Digital Orthophotos (DOP) Austria - Land Kärnten: Orthofotos Flugblock Klagenfurt\nDOP_AUT_K_OSTTIROL               : Digital Orthophotos (DOP) Austria - Land Kärnten: Orthofotos Flugblock Osttirol\nDOP_AUT_K_TAMSWEG                : Digital Orthophotos (DOP) Austria - Land Kärnten: Orthofotos Flugblock Tamsweg\nDOP_AUT_K_VILLACH                : Digital Orthophotos (DOP) Austria - Land Kärnten: Orthofotos Flugblock Villach\nDOP_AUT_K_WOLFSBERG              : Digital Orthophotos (DOP) Austria - Land Kärnten: Orthofotos Flugblock Wolfsberg\nDOP_AUT_K_ZELL_AM_SEE            : Digital Orthophotos (DOP) Austria - Land Kärnten: Orthofotos Flugblock Zell am See\nDOP_AUT_K_ZELTWEG                : Digital Orthophotos (DOP) Austria - Land Kärnten: Orthofotos Flugblock Zeltweg\nDOP_AUT_ST_BISCHOFSHOFEN         : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Bischofshofen\nDOP_AUT_ST_GRAZ                  : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Graz\nDOP_AUT_ST_KLAGENFURT            : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Klagenfurt\nDOP_AUT_ST_MARIAZELL             : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Mariazell\nDOP_AUT_ST_MURTAL                : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Murtal\nDOP_AUT_ST_SUEDBURGENLAND        : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Suedburgenland\nDOP_AUT_ST_VILLACH               : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Villach\nDOP_AUT_ST_WINDISCHGARSTEN       : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Windischgarsten\nDROUGHT_VULNERABILITY            : Drought Vulnerability\nDSM_AUT                          : Austrian Digital Surface Model\nERS_ENVISAT_NRB                  : ERS-1/2 SAR and ENVISAT ASAR ARD Normalized Radar Backscatter (NRB)\nGFM                              : Global Flood Monitoring\nincal-hourly                     : INCA analysis hourly data (1km)\nINTRA_FIELD_CROP_GROWTH_POTENTIAL: Intra-field Crop Growth Potential\nRUCIO_SENTINEL2_MFCOVER          : Monthly Composite of Fraction of Vegetation Cover\nSAR_IMP_1P                       : ERS-1/2 SAR Image Mode Precision Level-1\nSAR_IMS_1P                       : ERS-1/2 SAR Image Mode Single Look Complex Level-1\nSENTINEL1_ALPS_WETSNOW           : Sentinel-1 Alps WetSnow\nSENTINEL1_GMR0                   : SENTINEL1 Radiometric Terrain Corrected Gamma Nought\nSENTINEL1_GRD                    : Sentinel-1 SAR L1 GRD\nSENTINEL1_GRD_COVERAGE           : Sentinel-1 Coverage Maps\nSENTINEL1_HPAR                   : SENTINEL1 Harmonic Parameters\nSentinel-1_Lacken_Extent         : SENTINEL-1 Lacken Extent\nSENTINEL1_MPLIA                  : SENTINEL1 Mean PLIA\nSentinel-1_Reed_Extent           : SENTINEL-1 Reed Extent\nSENTINEL1_SCENE_GMR0             : SENTINEL1 Scene-based Radiometric Terrain Corrected Gamma Nought\nSENTINEL1_SIG0_20M               : SENTINEL1 Sigma Nought (SIG0) Backscatter in 20 meter resolution\nSENTINEL1_SLC                    : Sentinel-1 SLC\nSentinel-2-Greenness-Austria     : Sentinel-2 Greenness Austria\nSENTINEL2_GRI_L1C                : Multi-Layer Copernicus Sentinel-2 GRI in L1C\nSENTINEL2_L1C                    : Sentinel-2 MSI Products: Level-1C data\nSENTINEL2_L1C_COVERAGE           : Sentinel-2 L1C Coverage Maps\nSENTINEL2_L2A                    : Sentinel-2 MSI Products: Level-2A data\nsentinel2-landsat8-l2f           : Harmonized Landsat and Sentinel 2 L2F\nSENTINEL2_MFCOVER                : Monthly Composite of Fraction of Vegetation Cover\nSENTINEL3_SRAL_L2                : Sentinel-3 Products: SRAL Level-2 data\nspartacus-daily                  : Spartacus Analysis Daily (1 km)\nSSM-RT0-SIG0-R-EXTR              : SSM-RT0-SIG0-R-EXTR\ntopo-dc-austria                  : Topographic datacube Austria\nVEGETATION_CHANGE_AUSTRIA        : Vegetation-Change-Austria\nTo get a specific collection from the catalog, we can use the client.get_collection() method and provide the collection name. We can then display its description, id, temporal and spatial extent, license, etc. In this notebook, we will work with the Sentinel-1 sigma naught 20m collection.\ncolllection_id = \"SENTINEL1_SIG0_20M\"\n\ncollection = eodc_catalog.get_collection(colllection_id)\ncollection\n\n\n\n\n\n\n    &lt;CollectionClient id=SENTINEL1_SIG0_20M&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"SENTINEL1_SIG0_20M\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"Sentinel-1 Sigma Nought (SIG0) Products are radiometric calibrated and georeferenced backscatter data generated from Sentinel-1 level-1 Interferometric Wide (IW) Swath Ground Range Detected (GRD) High resolution products using TUWien Sentinel-1 preprocesssing workflow. The preprocessing workflow includes following steps: applying precise orbit file, radiometric calibration, thermal noise removal, and range doppler terrain correction. In the end, Sigma0 backscatter image is reprojected and resampled into Equi7 Grid system at 20m pixels spacing.\"\n        \n    \n                \n            \n                \n                    \n        links[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/collections/SENTINEL1_SIG0_20M/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"EODC Data Catalogue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/collections/SENTINEL1_SIG0_20M\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/ingestion/v1/collections/SENTINEL1_SIG0_20M/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/collections/SENTINEL1_SIG0_20M/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        stac_extensions[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/sat/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/sar/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"https://stac-extensions.github.io/item-assets/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"https://stac-extensions.github.io/datacube/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            cube:dimensions\n            \n        \n            \n                \n        \n            x\n            \n        \n            \n                \n        \n            axis\n            \"x\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"spatial\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -180\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            180\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            y\n            \n        \n            \n                \n        \n            axis\n            \"y\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"spatial\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -90\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            90\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            time\n            \n        \n            \n                \n        \n            type\n            \"temporal\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"2014-10-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"SENTINEL1 Sigma Nought (SIG0) Backscatter in 20 meter resolution\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        bbox[] 1 items\n        \n            \n        \n            \n                \n        0[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -180\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            -90\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            180\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            90\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        interval[] 1 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"2014-10-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"proprietary\"\n        \n    \n                \n            \n                \n                    \n        providers[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"TU Wien\"\n        \n    \n            \n        \n            \n                \n        roles[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"licensor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.tuwien.at/mg/geo\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"EODC\"\n        \n    \n            \n        \n            \n                \n        roles[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"host\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://eodc.eu/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            summaries\n            \n        \n            \n                \n        gsd[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            20\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        eo:bands[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"VV\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_VV\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in VV polarization\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"VH\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_VH\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in VH polarization\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"HH\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_HH\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in HH polarization\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"HV\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_HV\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in HV polarization\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        platform[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"sentinel-1a\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"sentinel-1b\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            item_assets\n            \n        \n            \n                \n        \n            HH\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sigma Nought (HH)\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"HH\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_HH\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in HH polarization\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            HV\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sigma Nought (HV)\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"HV\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_HV\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in HV polarization\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            VH\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sigma Nought (VH)\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"VH\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_VH\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in VH polarization\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            VV\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sigma Nought (VV)\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"VV\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_VV\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in VV polarization\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"A medium sized thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            constellation\n            \"sentinel-1\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://objectstore.eodc.eu:2222/swift/v1/AUTH_68e13833a1624f43ba2cac01376a18af/thumbnails/SENTINEL1_SIG0_20M.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"SENTINEL1_SIG0_20M collection thumbnail.\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\nEach collection has multiple items. An item is one spatio-temporal instance in the collection, for instance a satellite image. If items are needed for a specific timeframe or for a specific region of interest, we can define this as a query.\ntime_range = \"2022-10-01/2022-10-07\"  # a closed range\n# \"2022-01\" -&gt; entire month (the same can be done for a year and a day)\n# \"2022-01-01/..\" -&gt; up to the current date, an open range\n# \"2022-01-01T05:34:46\" -&gt;  a specific time instance\nA spatial region of interest can be defined in different ways. One option is to define a simple bounding box:\nlatmin, latmax = 46.3, 49.3  # South to North\nlonmin, lonmax = 13.8, 17.8  # West to East\n\nbounding_box = (lonmin, latmin, lonmax, latmax)\nIf the region of interest is not rectangular, we can also define a polygon:\n# GEOJSON can be created on geojson.io\n\n# This specific area of interest is a rectangle, but since it is\n# a closed polygon it seems like it has five nodes\n\narea_of_interest = {\n    \"coordinates\": [\n        [\n            [17.710928010825853, 49.257630084442496],\n            [13.881798300915221, 49.257630084442496],\n            [13.881798300915221, 46.34747715326259],\n            [17.710928010825853, 46.34747715326259],\n            [17.710928010825853, 49.257630084442496],\n        ],\n    ],\n    \"type\": \"Polygon\",\n}\nUsing our previously loaded STAC catalog, we can now search for items fullfilling our query. In this example we are using the bounding box. If we want to use an area of interest specified in the geojson format - one has to use the intersects parameter as documented in the comment below.\nsearch = eodc_catalog.search(\n    collections=colllection_id,  # can also be a list of several collections\n    bbox=bounding_box,  # search by bounding box\n    datetime=time_range,\n)\n\n# If we comment everything besides colllection_id, we will load whole\n# collection for available region and time_range\n\nitems_eodc = search.item_collection()\nprint(f\"On EODC we found {len(items_eodc)} items for the given search query\")\n\nOn EODC we found 52 items for the given search query\nNow, we can fetch a single item, in this case a Sentinel-1 image, from the query results. A good practice is to always check what metadata the data provider has stored on the item level. This can be done by looking into the item properties.\nitem = items_eodc[0]\nitem.properties\n\n{'gsd': 20,\n 'parent': 'S1A_IW_GRDH_1SDV_20221007T170811_20221007T170836_045339_056BBA_D830.zip',\n 'checksum': '576abe68a715e5ee177d8b640871e873',\n 'datetime': '2022-10-07T17:08:11Z',\n 'blocksize': {'x': 15000, 'y': 5},\n 'proj:bbox': [4800000, 1500000, 5100000, 1800000],\n 'proj:wkt2': 'PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]',\n 'proj:shape': [15000, 15000],\n 'Equi7_TileID': 'EU020M_E048N015T3',\n 'constellation': 'sentinel-1',\n 'proj:geometry': {'type': 'Polygon',\n  'coordinates': [[[4800000.0, 1500000.0],\n    [4800000.0, 1800000.0],\n    [5100000.0, 1800000.0],\n    [5100000.0, 1500000.0],\n    [4800000.0, 1500000.0]]]},\n 'proj:transform': [20, 0, 4800000, 0, -20, 1800000],\n 'sat:orbit_state': 'ascending',\n 'sar:product_type': 'GRD',\n 'slice_gap_filled': False,\n 'sar:polarizations': ['VH', 'VV'],\n 'sar:frequency_band': 'C',\n 'sat:relative_orbit': 117,\n 'sar:instrument_mode': 'IW',\n 'border_noise_removed': True,\n 'sar:center_frequency': 5.405,\n 'sar:resolution_range': 40,\n 'thermal_noise_removed': True,\n 'sar:resolution_azimuth': 40,\n 'sar:pixel_spacing_range': 20,\n 'sar:observation_direction': 'right',\n 'sar:pixel_spacing_azimuth': 20,\n 'sat:platform_international_designator': '2014-016A'}\nFor now, let’s display only the vertical-vertical (VV) polarized band of the item and some information about the data.\nitem.assets[\"VV\"].extra_fields.get(\"raster:bands\")[0]\n\n{'scale': 10,\n 'nodata': -9999,\n 'offset': 0,\n 'data_type': 'int16',\n 'spatial_resolution': 20}\nIn the EODC STAC catalog an item can conveniently be displayed using its thumbnail.\nitem.assets[\"thumbnail\"].href\n\n'https://data.eodc.eu/collections/SENTINEL1_SIG0_20M/V1M1R1/EQUI7_EU020M/E048N015T3/SIG0_20221007T170811__VV_A117_E048N015T3_EU020M_V1M1R1_S1AIWGRDH_TUWIEN.tif/thumbnail'\nNow we will plot the data on a map using the thumbnail and the python package folium. This is an easy way to quickly check how the data found by a search query looks on a map.\nfmap = folium.Map(\n    location=[(latmin + latmax) / 2, (lonmin + lonmax) / 2],\n    zoom_start=7,\n    zoom_control=False,\n    scrollWheelZoom=False,\n    dragging=False,\n)\n\nfolium.GeoJson(area_of_interest, name=\"Area of Interest\").add_to(fmap)\n\nfor item in items_eodc:\n    # url leading to display of an item, can also be used as hyperlink\n    image_url = item.assets[\"thumbnail\"].href\n    bounds = item.bbox\n    ImageOverlay(\n        image=image_url,\n        bounds=[[bounds[1], bounds[0]], [bounds[3], bounds[2]]],\n    ).add_to(fmap)\n\nfolium.LayerControl().add_to(fmap)\n\nfmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\nFigure 1: Map of study area. Blue rectangle is the area covered by the discovered data.",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>EO Data Discovery</span>"
    ]
  },
  {
    "objectID": "unit_01/01_in_class_exercise.html#data-reading",
    "href": "unit_01/01_in_class_exercise.html#data-reading",
    "title": "1  Discover and Read SAR Data",
    "section": "1.2 Data Reading",
    "text": "1.2 Data Reading\nSTAC can also be a useful tool for the discovery of data, however it only loads metadata. This saves memory, but if one would like to do further analysis, the data has to be loaded into memory or downloaded on disk.\nIn the following, we will demonstrate this with the library odc-stac. Here we can define what data will loaded as bands; in this case VV sigma naught. Moreover we can resample the data by providing any coordinate reference system (CRS) and resolution as well as a method for resampling of continuos data (e.g. bilinear resampling). In the example below, we use the EQUI7 Grid of Europe and a 20 meter sampling. This is the native format of sigma naught stored at EODC, so there will be no actual resampling. Note, also, that resampling is not advisable for this data, as it is provided on a logarithmic scale. More about this in notebook 2 “Unit Conversion”.\nThe chunks argument is an advancement method for performing parallel computations on the data. We will not cover this in further detail.\n\nbands = \"VV\"  # Vertical-vertical polarized\ncrs = \"EPSG:27704\"  # Coordinate Reference System: EQUI7 Grid of Europe\nres = 20  # 20 meter\nchunks = {\"time\": 1, \"latitude\": 1000, \"longitude\": 1000}\nsig0_dc = odc_stac.load(\n    items_eodc,\n    bands=bands,\n    crs=crs,\n    resolution=res,\n    bbox=bounding_box,\n    chunks=chunks,\n    resampling=\"bilinear\",\n)\n\nLet’s have a look at the VV polarized band of the dataset.\n\nsig0_dc.VV\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'VV' (time: 31, y: 18269, x: 16725)&gt; Size: 19GB\ndask.array&lt;VV, shape=(31, 18269, 16725), dtype=int16, chunksize=(1, 18269, 16725), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time         (time) datetime64[ns] 248B 2022-10-01T05:09:56 ... 2022-10-0...\n  * y            (y) float64 146kB 1.762e+06 1.762e+06 ... 1.396e+06 1.396e+06\n  * x            (x) float64 134kB 5.052e+06 5.052e+06 ... 5.387e+06 5.387e+06\n    spatial_ref  int32 4B 27704\nAttributes:\n    nodata:   -9999xarray.DataArray'VV'time: 31y: 18269x: 16725dask.array&lt;chunksize=(1, 18269, 16725), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n17.64 GiB\n582.79 MiB\n\n\nShape\n(31, 18269, 16725)\n(1, 18269, 16725)\n\n\nDask graph\n31 chunks in 3 graph layers\n\n\nData type\nint16 numpy.ndarray\n\n\n\n\n                                                             16725 18269 31\n\n\n\n\nCoordinates: (4)time(time)datetime64[ns]2022-10-01T05:09:56 ... 2022-10-...array(['2022-10-01T05:09:56.000000000', '2022-10-01T05:10:21.000000000',\n       '2022-10-01T05:10:46.000000000', '2022-10-01T05:11:11.000000000',\n       '2022-10-01T05:11:36.000000000', '2022-10-02T16:58:39.000000000',\n       '2022-10-02T16:59:04.000000000', '2022-10-02T16:59:29.000000000',\n       '2022-10-02T16:59:54.000000000', '2022-10-03T04:53:37.000000000',\n       '2022-10-03T04:54:02.000000000', '2022-10-03T04:54:27.000000000',\n       '2022-10-03T04:54:52.000000000', '2022-10-03T18:02:55.000000000',\n       '2022-10-04T05:34:54.000000000', '2022-10-04T05:35:19.000000000',\n       '2022-10-04T16:42:01.000000000', '2022-10-04T16:42:26.000000000',\n       '2022-10-04T16:42:51.000000000', '2022-10-04T16:43:16.000000000',\n       '2022-10-04T16:43:41.000000000', '2022-10-06T05:18:07.000000000',\n       '2022-10-06T05:18:32.000000000', '2022-10-06T05:18:57.000000000',\n       '2022-10-06T05:19:22.000000000', '2022-10-06T05:19:47.000000000',\n       '2022-10-07T17:06:31.000000000', '2022-10-07T17:06:56.000000000',\n       '2022-10-07T17:07:21.000000000', '2022-10-07T17:07:46.000000000',\n       '2022-10-07T17:08:11.000000000'], dtype='datetime64[ns]')y(y)float641.762e+06 1.762e+06 ... 1.396e+06units :metreresolution :-20.0crs :EPSG:27704array([1761670., 1761650., 1761630., ..., 1396350., 1396330., 1396310.],\n      shape=(18269,))x(x)float645.052e+06 5.052e+06 ... 5.387e+06units :metreresolution :20.0crs :EPSG:27704array([5052090., 5052110., 5052130., ..., 5386530., 5386550., 5386570.],\n      shape=(16725,))spatial_ref()int3227704spatial_ref :PROJCRS[\"WGS 84 / Equi7 Europe\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Equi7 projection - Europe\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.82,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.696,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Continental mapping of raster data.\"],AREA[\"Europe including Russia west of the Ural Mountains.\"],BBOX[29.24,-42.52,83.67,51.73]],ID[\"EPSG\",27704]]crs_wkt :PROJCRS[\"WGS 84 / Equi7 Europe\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Equi7 projection - Europe\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.82,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.696,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Continental mapping of raster data.\"],AREA[\"Europe including Russia west of the Ural Mountains.\"],BBOX[29.24,-42.52,83.67,51.73]],ID[\"EPSG\",27704]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensembleprojected_crs_name :WGS 84 / Equi7 Europegrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.82false_northing :2121415.696GeoTransform :5052080 20 0 1761680 0 -20array(27704, dtype=int32)Attributes: (1)nodata :-9999\n\n\nAs we can see, the data is stored as a xarray DataArray. Xarray is a convenient package for multidimensional labeled arrays, like temperature, humidity, pressure, different bands of satellite imagery, and so on. The link provides a detailed documentation. In a later notebook, we will explore some more of the functionality of xarray. As we can see in the coordinates, the data here consists of 21 time steps.\nIn general, data from STAC is “lazily” loaded, which means that the structure of the DataArray is constructed, but the data is not loaded yet. It is loaded only at instance when it is needed, for example, for plotting, computations, and so on.\nSince the DataArray currently has a size of almost 18 GiB, we will subset it to the region of Vienna.\n\n# Create a bounding box covering the region of Vienna\nlatmin_smaller, latmax_smaller = 48, 48.4\nlonmin_smaller, lonmax_smaller = 16, 16.5\n\nsmaller_bounding_box = [\n    [latmin_smaller, lonmin_smaller],\n    [latmax_smaller, lonmax_smaller],\n]\n\nfmap = folium.Map(\n    location=[\n        (latmin_smaller + latmax_smaller) / 2,\n        (lonmin_smaller + lonmax_smaller) / 2,\n    ],\n    zoom_start=8,\n    zoom_control=False,\n    scrollWheelZoom=False,\n    dragging=False,\n)\n\nfolium.GeoJson(area_of_interest, name=\"Area of Interest\").add_to(fmap)\n\nfolium.Rectangle(\n    bounds=smaller_bounding_box,\n    color=\"red\",\n).add_to(fmap)\n\nfor item in items_eodc:\n    image_url = item.assets[\"thumbnail\"].href\n    bounds = item.bbox\n    ImageOverlay(\n        image=image_url,\n        bounds=[[bounds[1], bounds[0]], [bounds[3], bounds[2]]],\n    ).add_to(fmap)\n\nfolium.LayerControl().add_to(fmap)\n\nfmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFigure 2: Map of study area. The blue rectangle is the area covered by the discovered data. The red rectangle covers the selected data.\nWe will create now a new dataset with the smaller bounding box covering the region of Vienna. We will leave out the arguments for resampling and directly use the native format as defined in the metadata.\n\nsig0_dc = odc_stac.load(\n    items_eodc,\n    bands=bands,\n    bbox=(lonmin_smaller, latmin_smaller, lonmax_smaller, latmax_smaller),\n    chunks=chunks,\n)\n\nDue to the way the data is acquired and stored, some items include “no data” areas. In our case, no data has the value -9999, but this can vary from data provider to data provider. This information can usually be found in the metadata. Furthermore, to save memory, data is often stored as integer (e.g. 25) and not in float (e.g. 2.5) format. For this reason, the backscatter values are often multiplied by a scale factor, in this case factor 10.\nAs Sentinel-1 satellites overpasses Austria every few days, only some time steps of the dataset will have physical data. As a final step, we will now decode the data and create a plot of two consecutive Sentinel-1 acquisitions of Vienna.\n\n# Retrieve the scale factor and NoData value from the metadata. raster:bands is\n# a STAC raster extension\nscale = item.assets[\"VV\"].extra_fields.get(\"raster:bands\")[0][\"scale\"]\nnodata = item.assets[\"VV\"].extra_fields.get(\"raster:bands\")[0][\"nodata\"]\n\n# Decode data with the NoData value and the scale factor\nsig0_dc = sig0_dc.where(sig0_dc != nodata) / scale\n\n# We should remove unnecessary dates when there was no data\n# (no satellite overpass)\nsig0_dc = sig0_dc.dropna(dim=\"time\")\n\n\nsig0_dc.VV.plot(col=\"time\", robust=True, cmap=\"Greys_r\", aspect=1, size=10)\n\n\n\n\n\n\n\n\nFigure 3: Sentinel-1 microwave backscatter image for two timeslices.",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>EO Data Discovery</span>"
    ]
  },
  {
    "objectID": "unit_01/02_in_class_exercise.html",
    "href": "unit_01/02_in_class_exercise.html",
    "title": "2  Unit Conversion",
    "section": "",
    "text": "2.1 Exploring the Data\nIn this notebook, we are going to have a look at the conversion of units. Sentinel-1 data, and most other SAR data, is usually provided in decibels (dB). In this notebook, we will discover the advantages of displaying SAR data in decibels and why we need to convert the data to a linear scale in order to make meaningful calculations. Let’s start with importing some libraries.\n\\[\n\\text{logarithmic} \\longleftrightarrow \\text{linear}\n\\] \\[\n[\\text{dB}] \\longleftrightarrow [\\text{m}^2 \\cdot \\text{m}^{-2}]\n\\]\nLet’s start by loading some sample data, in order to demonstrate why this conversion is important. Here we will have a look at some SAR data from the Sentinel-1 mission. The data is provided in decibels (dB). In the following example, we will:",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Unit Conversions</span>"
    ]
  },
  {
    "objectID": "unit_01/02_in_class_exercise.html#exploring-the-data",
    "href": "unit_01/02_in_class_exercise.html#exploring-the-data",
    "title": "2  Unit Conversion",
    "section": "",
    "text": "load data from Sentinel-1\nvisualize the data in logarithmic scale\ncompare the data with linear scale",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Unit Conversions</span>"
    ]
  },
  {
    "objectID": "unit_01/02_in_class_exercise.html#search-for-some-data",
    "href": "unit_01/02_in_class_exercise.html#search-for-some-data",
    "title": "2  Unit Conversion",
    "section": "2.2 Search for some Data",
    "text": "2.2 Search for some Data\nNow, we start by loading data from Sentinel-1 from the EODC STAC Catalogue. We do this in the same way as in the previous notebook “Discover and Read SAR Data”.\n\nlatmin, latmax = 48, 48.5\nlonmin, lonmax = 16, 17\nbounds = (lonmin, latmin, lonmax, latmax)\n\ntime_range = \"2022-07-01/2022-07-31\"\n\nitems = (\n    pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n    .search(\n        bbox=bounds,\n        collections=[\"SENTINEL1_SIG0_20M\"],\n        datetime=time_range,\n        limit=100,\n    )\n    .item_collection()\n)\n\nprint(len(items), \"scenes found\")\n\n60 scenes found\n\n\n\n\nbands = \"VV\"\n\nsig0_dc: Dataset = odc.stac.stac_load(\n    items,\n    bands=bands,\n    bbox=bounds,\n    chunks={\"time\": 5, \"x\": 1000, \"y\": 1000},\n)\nmetadata = items[0].assets[\"VV\"].extra_fields[\"raster:bands\"][0]\nnodata: float = metadata[\"nodata\"]\nscale: float = metadata[\"scale\"]\n\nsig0_dc: DataArray = (sig0_dc.where(sig0_dc != nodata) / scale).VV\nsig0_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'VV' (time: 60, y: 3150, x: 3978)&gt; Size: 3GB\ndask.array&lt;truediv, shape=(60, 3150, 3978), dtype=float32, chunksize=(5, 1000, 1000), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time         (time) datetime64[ns] 480B 2022-07-02T05:18:03 ... 2022-07-3...\n  * y            (y) float64 25kB 1.653e+06 1.653e+06 ... 1.59e+06 1.59e+06\n  * x            (x) float64 32kB 5.241e+06 5.241e+06 ... 5.32e+06 5.32e+06\n    spatial_ref  int32 4B 27704xarray.DataArray'VV'time: 60y: 3150x: 3978dask.array&lt;chunksize=(5, 1000, 1000), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.80 GiB\n19.07 MiB\n\n\nShape\n(60, 3150, 3978)\n(5, 1000, 1000)\n\n\nDask graph\n192 chunks in 7 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                           3978 3150 60\n\n\n\n\nCoordinates: (4)time(time)datetime64[ns]2022-07-02T05:18:03 ... 2022-07-...array(['2022-07-02T05:18:03.000000000', '2022-07-02T05:18:28.000000000',\n       '2022-07-02T05:18:53.000000000', '2022-07-04T05:01:44.000000000',\n       '2022-07-04T05:02:09.000000000', '2022-07-04T05:02:34.000000000',\n       '2022-07-05T16:50:50.000000000', '2022-07-05T16:51:15.000000000',\n       '2022-07-05T16:51:40.000000000', '2022-07-07T16:34:45.000000000',\n       '2022-07-07T16:35:10.000000000', '2022-07-07T16:35:35.000000000',\n       '2022-07-09T05:09:52.000000000', '2022-07-09T05:10:17.000000000',\n       '2022-07-09T05:10:42.000000000', '2022-07-10T16:59:00.000000000',\n       '2022-07-10T16:59:25.000000000', '2022-07-10T16:59:50.000000000',\n       '2022-07-11T04:53:33.000000000', '2022-07-11T04:53:58.000000000',\n       '2022-07-11T04:54:23.000000000', '2022-07-12T16:42:47.000000000',\n       '2022-07-12T16:43:12.000000000', '2022-07-12T16:43:37.000000000',\n       '2022-07-14T05:18:03.000000000', '2022-07-14T05:18:28.000000000',\n       '2022-07-14T05:18:53.000000000', '2022-07-16T05:01:45.000000000',\n       '2022-07-16T05:02:10.000000000', '2022-07-16T05:02:35.000000000',\n       '2022-07-17T16:50:51.000000000', '2022-07-17T16:51:16.000000000',\n       '2022-07-17T16:51:41.000000000', '2022-07-19T16:34:46.000000000',\n       '2022-07-19T16:35:11.000000000', '2022-07-19T16:35:36.000000000',\n       '2022-07-21T05:09:52.000000000', '2022-07-21T05:10:17.000000000',\n       '2022-07-21T05:10:42.000000000', '2022-07-22T16:59:01.000000000',\n       '2022-07-22T16:59:26.000000000', '2022-07-22T16:59:51.000000000',\n       '2022-07-23T04:53:34.000000000', '2022-07-23T04:53:59.000000000',\n       '2022-07-23T04:54:24.000000000', '2022-07-24T16:42:48.000000000',\n       '2022-07-24T16:43:13.000000000', '2022-07-24T16:43:38.000000000',\n       '2022-07-26T05:18:04.000000000', '2022-07-26T05:18:29.000000000',\n       '2022-07-26T05:18:54.000000000', '2022-07-28T05:01:45.000000000',\n       '2022-07-28T05:02:10.000000000', '2022-07-28T05:02:35.000000000',\n       '2022-07-29T16:50:51.000000000', '2022-07-29T16:51:16.000000000',\n       '2022-07-29T16:51:41.000000000', '2022-07-31T16:34:46.000000000',\n       '2022-07-31T16:35:11.000000000', '2022-07-31T16:35:36.000000000'],\n      dtype='datetime64[ns]')y(y)float641.653e+06 1.653e+06 ... 1.59e+06units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([1653150., 1653130., 1653110., ..., 1590210., 1590190., 1590170.],\n      shape=(3150,))x(x)float645.241e+06 5.241e+06 ... 5.32e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5240690., 5240710., 5240730., ..., 5320190., 5320210., 5320230.],\n      shape=(3978,))spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5240680 20 0 1653160 0 -20array(27704, dtype=int32)",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Unit Conversions</span>"
    ]
  },
  {
    "objectID": "unit_01/02_in_class_exercise.html#comparison-of-the-data-in-db-and-linear-scale",
    "href": "unit_01/02_in_class_exercise.html#comparison-of-the-data-in-db-and-linear-scale",
    "title": "2  Unit Conversion",
    "section": "2.3 Comparison of the Data in dB and Linear Scale",
    "text": "2.3 Comparison of the Data in dB and Linear Scale\nIn the next two cells we will select a subset of the data. This is done to reduce the amount of data we are working with. The precise workflow is not important for now, since the theory is explained after the cells. They are just here to show the data we are working with.\n\nsubset = sig0_dc.sel(time=slice(\"2022-07-01\", \"2022-07-07\"))\nsubset = subset.dropna(\"time\", how=\"all\")\n\nNow plot the data.\n\naoi = subset.isel(time=0, x=slice(0, 500), y=slice(0, 500))\naoi_lin = 10 ** (aoi / 10)\n\nfig, ax = plt.subplots(2, 3, figsize=(14, 8))\n# upper left\nax_ul = ax[0, 0]\naoi.plot.imshow(robust=True, ax=ax_ul, cmap=\"Greys_r\")\nax_ul.set_title(r\"$\\sigma^0$ [$dB$] (robust plot)\")\nax_ul.axes.set_aspect(\"equal\")\n\n# upper middle\nax_um = ax[0, 1]\naoi.plot.imshow(robust=False, ax=ax_um, cmap=\"Greys_r\")\nax_um.set_title(r\"$\\sigma^0$ [$dB$] (not robust plot)\")\nax_um.axes.set_aspect(\"equal\")\n\n# upper right\nax_ur = ax[0, 2]\naoi.plot.hist(bins=50, ax=ax_ur, edgecolor=\"black\")\nax_ur.set_xlabel(r\"$\\sigma^0$ [$dB$]\")\nax_ur.set_title(r\"$\\sigma^0$ [$dB$] distribution\")\nax_ur.set_ylabel(\"n (number of pixels)\")\n\n# lower left\nax_ll = ax[1, 0]\naoi_lin.plot.imshow(robust=True, ax=ax_ll, cmap=\"Greys_r\")\nax_ll.set_title(r\"$\\sigma^0$ [$m^2 \\cdot m^{-2}$] (robust plot)\")\nax_ll.axes.set_aspect(\"equal\")\n\n# lower middle\nax_lm = ax[1, 1]\naoi_lin.plot.imshow(robust=False, ax=ax_lm, cmap=\"Greys_r\")\nax_lm.set_title(r\"$\\sigma^0$ [$m^2 \\cdot m^{-2}$] (not robust plot)\")\nax_lm.axes.set_aspect(\"equal\")\n\n# lower right\nax_lr = ax[1, 2]\naoi_lin.plot.hist(bins=50, ax=ax_lr, edgecolor=\"black\")\nax_lr.set_xlabel(r\"$\\sigma^0$ [$m^2 \\cdot m^{-2}$]\")\nax_lr.set_ylabel(\"n (number of pixels)\")\nax_lr.set_title(r\"$\\sigma^0$ [$m^2 \\cdot m^{-2}$] distribution\")\n\ntitle = (\n    r\"Sentinel-1 backscatter $\\sigma^0$ comparison\"\n    r\" in linear and logarithmic domain\"\n)\nfig.suptitle(title, horizontalalignment=\"center\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nFigure 1: Visually comparing \\(\\sigma^0\\) on a logarithmic and linear scale (left column). In addition, the benefit of using the robust plotting method is shown (middle column). The robust argument uses the \\(2^{\\text{nd}}\\) and \\(98^{\\text{th}}\\) percentiles of the data to compute the color limits to eliminate washing out the plot due to data outliers.\nIn the plot above, you can see the difference between the two scales. The values in dB are more evenly distributed and are therefore easier to plot. The values in linear scale are more spread out and are therefore harder to interpret. This is why we use the dB scale for plotting/visualization.\nWhile the logarithmic scale facilitates visual interpretation, it has implications for mathematical operations. In the following, we’ll have a closer look at this. But first, let’s see how we can convert between the linear and the logarithmic domains.",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Unit Conversions</span>"
    ]
  },
  {
    "objectID": "unit_01/02_in_class_exercise.html#conversion-formulas",
    "href": "unit_01/02_in_class_exercise.html#conversion-formulas",
    "title": "2  Unit Conversion",
    "section": "2.4 Conversion Formulas",
    "text": "2.4 Conversion Formulas\nThe decibel (dB) is a logarithmic unit used to express the ratio of two values of a physical quantity, often power or intensity. In the case of SAR data, the backscatter coefficient is often expressed in dB to facilitate visualization.\nIn order to convert the data from dB to linear scale, we use the following formula. Let \\(D\\) be the original value (dB) and \\(I\\) the converted value (\\(m^2m^{-2}\\)). The conversion of units can be expressed as: \\[\nD =  10  \\cdot \\log_{10} (I) = 10 \\cdot \\log_{10} (e) \\cdot \\ln (I)\\longrightarrow [dB]\n\\] Similarly, the conversion back to the original unit can be expressed as: \\[\nI = e^{\\frac{D}{10\\cdot \\log_{10}(e)}} = 10^{\\frac{D}{10}} \\longrightarrow [m^2m^{-2}]\n\\] You can find these formulas in the script for Microwave Remote Sensing on page 136 (equation 6.40).\nNow let’s implement the conversion in Python.\n\ndef lin2db[T](val: T) -&gt; T:\n    \"\"\"Convert linear units to decibel (db).\n\n    Parameters\n    ----------\n    val : float | ArrayLike\n        Value in linear units.\n\n    Returns\n    -------\n    float | ArrayLike\n        Value in decibels (dB).\n\n    \"\"\"\n    return 10 * np.log10(val)\n\n\ndef db2lin[T](val: T) -&gt; T:\n    \"\"\"Convert decibel (db) to linear units.\n\n    Parameters\n    ----------\n    val : float | ArrayLike\n        Value in decibel.\n\n    Returns\n    -------\n    float | ArrayLike\n        Value in linear units.\n\n    \"\"\"\n    return 10 ** (val / 10)  # type: ignore[unsupported-operator]\n\nWhen performing mathematical operations with SAR data it is important to be aware, that adding values in the logarithmic scale doesn’t work in the same way as adding regular (linear) values. This is because in the logarithmic scale, each unit step represents an equal multiplication. This means that an addition of two values in the logarithmic scale equals a multiplication of the values in the linear scale. Vice versa, a subtraction in a logarithmic scale equals a division in a linear scale. Let’s have a look at an example, where we add two values, once without the conversion to linear scale and once with the conversion to linear scale.\n\n# Logarithmic addition\n# Values in linear and decibel units\nval1_db, val2_db = 10, 12\n\n# Logarithmic addition\nsum_db = val1_db + val2_db\n\n# Linear addition\nval1_lin, val2_lin = db2lin(val1_db), db2lin(val2_db)\nsum_lin = val1_lin + val2_lin\nprint(\n    f\"Logarithmic values: \\t{val1_db}, {val2_db}\" + r\" \\[dB]\" + \"\\n\\n\"\n    \"Addition in logarithmic Domain:\\n\"\n    f\"\\tSum: \\t\\t{val1_db} + {val2_db} = {sum_db}\" + r\" \\[dB]\" + \"\\n\"\n    f\"\\tTransform:\\t{sum_db}\" + r\" \\[dB]\"\n    f\" :arrow_right: {db2lin(val1_db + val2_db):.2f}\"\n    r\" \\[lin]\"\n    \"\\n\\n\\n\"\n    \"\\nAddition in linear Domain:\\n\"\n    f\"\\tTransform:\\t{val1_db}\" + r\" \\[dB]\" + f\" :arrow_right: {val1_lin}\" + r\" \\[lin]\"\n    f\"\\n\\t\\t\\t{val2_db}\" + r\" \\[dB]\" + f\" :arrow_right: {val2_lin:.2f}\" + r\" \\[lin]\"\n    f\"\\n\\tSum: \\t\\t{val1_lin} + {val2_lin:.2f} = {sum_lin:.2f}\" + r\" \\[lin]\"\n    f\"\\n\\tTransform:\\t{sum_lin:.2f}\" + r\" \\[lin]\"\n    f\" :arrow_right: {lin2db(sum_lin):.2f}\" + r\" \\[dB]\"\n    \"\\n\\n\\n\"\n    f\"\\t[bold red]Attention:[/bold red]\\t{sum_db:.2f}\" + r\" \\[dB]\"\n    f\" != {lin2db(sum_lin):.2f}\" + r\" \\[dB]\"\n    f\"\\n\\t[bold red]Attention:[/bold red]\\t{db2lin(val1_db + val2_db):.2f}\" + r\" \\[lin]\"\n    f\" != {sum_lin:.2f}\" + r\" \\[lin]\"\n)\n\nLogarithmic values:     10, 12 [dB]\n\nAddition in logarithmic Domain:\n        Sum:            10 + 12 = 22 [dB]\n        Transform:      22 [dB] ➡ 158.49 [lin]\n\n\n\nAddition in linear Domain:\n        Transform:      10 [dB] ➡ 10.0 [lin]\n                        12 [dB] ➡ 15.85 [lin]\n        Sum:            10.0 + 15.85 = 25.85 [lin]\n        Transform:      25.85 [lin] ➡ 14.12 [dB]\n\n\n        Attention:      22.00 [dB] != 14.12 [dB]\n        Attention:      158.49 [lin] != 25.85 [lin]\n\n\n\nAs you can see, the values in dB and in linear scale differ quite a bit. In the example above, the values differ by a factor of around 6 when looked at in linear scale.\nNow that we have some data, we will have a look at some practical examples where we will convert the data to linear scale. When we try to calculate the average \\(\\sigma^0\\) value across the scene, we need to do this by converting the data to linear scale first and then calculating the average and converting it back to dB.",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Unit Conversions</span>"
    ]
  },
  {
    "objectID": "unit_01/02_in_class_exercise.html#creating-a-monthly-mosaic",
    "href": "unit_01/02_in_class_exercise.html#creating-a-monthly-mosaic",
    "title": "2  Unit Conversion",
    "section": "2.5 Creating a Monthly Mosaic",
    "text": "2.5 Creating a Monthly Mosaic\nSo in the beginning we have lazily loaded data for an area across a whole year. We therefore have around 700 images. We will now essentially compress the data of each month into one timestamp. This is done by using the resampling method together with an operation method like mean that includes summation. Since the data is in dB we need to convert it to linear scale first, then we can resample the data and convert it back to dB.\n\n# Convert to linear scale and calculate monthly means\n# Conversion by calculating with the xarray Object\nsig0_lin = 10 ** (sig0_dc / 10)\n\n# Resample to monthly means. Time accepts intervals identical to the pandas\n# resample function. 'D' for days, 'W' for weeks, 'ME' for months.\nsig0_lin_monthly = sig0_lin.resample(time=\"1ME\").mean()\n\n# Convert back to dB scale\n# Conversion by applying a function\nsig0_monthly: DataArray = lin2db(sig0_lin_monthly)\nsig0_monthly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'VV' (time: 1, y: 3150, x: 3978)&gt; Size: 50MB\ndask.array&lt;mul, shape=(1, 3150, 3978), dtype=float32, chunksize=(1, 1000, 1000), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time         (time) datetime64[ns] 8B 2022-07-31\n  * y            (y) float64 25kB 1.653e+06 1.653e+06 ... 1.59e+06 1.59e+06\n  * x            (x) float64 32kB 5.241e+06 5.241e+06 ... 5.32e+06 5.32e+06\n    spatial_ref  int32 4B 27704xarray.DataArray'VV'time: 1y: 3150x: 3978dask.array&lt;chunksize=(1, 1000, 1000), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n47.80 MiB\n3.81 MiB\n\n\nShape\n(1, 3150, 3978)\n(1, 1000, 1000)\n\n\nDask graph\n16 chunks in 15 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                     3978 3150 1\n\n\n\n\nCoordinates: (4)time(time)datetime64[ns]2022-07-31array(['2022-07-31T00:00:00.000000000'], dtype='datetime64[ns]')y(y)float641.653e+06 1.653e+06 ... 1.59e+06units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([1653150., 1653130., 1653110., ..., 1590210., 1590190., 1590170.],\n      shape=(3150,))x(x)float645.241e+06 5.241e+06 ... 5.32e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5240690., 5240710., 5240730., ..., 5320190., 5320210., 5320230.],\n      shape=(3978,))spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5240680 20 0 1653160 0 -20array(27704, dtype=int32)\n\n\nThe dataset has now only 12 timestamps, one for each month. Next, we want to calculate the average \\(\\sigma^0\\) value across a subset of the scene for one month. We will do this again by converting the data to linear scale first and then calculating the average and converting it back to dB.\n\n# Lets take a data array with db values\ndb_array = (\n    sig0_monthly.sel(time=\"2022-07-30\", method=\"nearest\")\n    .isel(x=slice(300, 400), y=slice(500, 600))\n    .compute()\n)\n\n# Compute the linear values\nlin_array = db2lin(db_array)\n\n\n# Compute the average backscatter value in linear units across the whole scene\nlin_mean = lin_array.mean()\ndb_from_lin_mean = lin2db(lin_mean)\n\n# Compute the average backscatter value in dB across the whole scene\ndb_mean = db_array.mean()\nprint(\n    f\"Average backscatter value in linear units: {lin_mean.values: .3f}\"\n    f\"\\nThat value in dB: {db_from_lin_mean.values: .3f}\"\n    f\"\\nAverage backscatter value in dB: {db_mean.values: .3f}\"\n)\n\nAverage backscatter value in linear units:  0.114\nThat value in dB: -9.424\nAverage backscatter value in dB: -10.392\n\n\n\nAs you can see in the example, the mean values across the scene are different in dB and linear scale. Therefore, it is important to be aware in which scale the data is stored to perform the correct type of mathematical operation or always convert the data to linear scale before doing any calculations.",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Unit Conversions</span>"
    ]
  },
  {
    "objectID": "unit_01/03_in_class_exercise.html",
    "href": "unit_01/03_in_class_exercise.html",
    "title": "3  Backscattering Coefficients",
    "section": "",
    "text": "3.1 Loading Backscatter Data\nIn this notebook, we will introduce some of the steps involved in the processing of Sentinel-1 Level1 Ground Range Detected (GRD) data to \\(\\sigma^0\\) (sig0) and \\(\\gamma^0\\) (gmr). Moreover, the notebook illustrates the importance and impact of geometric and radiometric terrain correction. As the processing of SAR data is a very time and hardware-intense task, we won’t perform the actual processing in this notebook. Instead, data at different processing steps is illustrated to highlight the impact of the processing steps.\nWe first load our data from the following intake catalog. Intake is somewhat similar to STAC in that it makes it easy to discover and load data. More importantly, this package allows us to hide some of the complexities involved with getting the data in the right format, which are not of concern in this notebook.\nurl = get_intake_url()\ncat = intake.open_catalog(url)\ngtc_dc = cat[\"gtc\"].read().compute()\ngtc_dc\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 116MB\nDimensions:      (band: 2, y: 3800, x: 3801)\nCoordinates:\n  * band         (band) &lt;U8 64B 'grd' 'sig0_gtc'\n  * y            (y) float64 30kB 47.5 47.5 47.5 47.5 ... 47.0 47.0 47.0 47.0\n  * x            (x) float64 30kB 9.5 9.5 9.5 9.5 9.501 ... 10.0 10.0 10.0 10.0\n    spatial_ref  int64 8B 0\nData variables:\n    band_data    (band, y, x) float32 116MB 151.0 119.0 119.0 ... nan nan nanxarray.DatasetDimensions:band: 2y: 3800x: 3801Coordinates: (4)band(band)&lt;U8'grd' 'sig0_gtc'array(['grd', 'sig0_gtc'], dtype='&lt;U8')y(y)float6447.5 47.5 47.5 ... 47.0 47.0 47.0array([47.499874, 47.499742, 47.499611, ..., 47.000355, 47.000224, 47.000092],\n      shape=(3800,))x(x)float649.5 9.5 9.5 9.5 ... 10.0 10.0 10.0array([9.500026, 9.500158, 9.500289, ..., 9.999676, 9.999808, 9.99994 ],\n      shape=(3801,))spatial_ref()int640GeoTransform :9.499960609331326 0.000131556088961555 0.0 47.499939478018426 0.0 -0.00013155608896155463crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]geographic_crs_name :WGS 84grid_mapping_name :latitude_longitudehorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]array(0)Data variables: (1)band_data(band, y, x)float32151.0 119.0 119.0 ... nan nan nanarray([[[151.      , 119.      , 119.      , ...,  88.      ,\n          82.      ,  78.      ],\n        [113.      , 121.      , 110.      , ..., 129.      ,\n         127.      , 105.      ],\n        [ 98.      ,  96.      , 115.      , ..., 119.      ,\n         119.      , 109.      ],\n        ...,\n        [  0.      ,   0.      ,   0.      , ...,        nan,\n                nan,        nan],\n        [  0.      ,   0.      ,   0.      , ...,        nan,\n                nan,        nan],\n        [  0.      ,   0.      ,   0.      , ...,        nan,\n                nan,        nan]],\n\n       [[-12.86    , -12.21    , -11.66    , ...,  -8.639999,\n          -8.849999,  -9.15    ],\n        [-14.21    , -13.61    , -14.2     , ...,  -9.059999,\n         -12.2     , -13.66    ],\n        [-11.42    , -12.19    , -13.65    , ..., -13.44    ,\n         -13.549999, -12.57    ],\n        ...,\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan]]], shape=(2, 3800, 3801), dtype=float32)\nband1 = gtc_dc.band[0]\nband2 = gtc_dc.band[1]\n\n\nimg1 = (\n    gtc_dc.sel(band=band1)\n    .hvplot.image(\n        x=\"x\",\n        y=\"y\",\n        robust=True,\n        cmap=\"Greys_r\",\n        rasterize=True,\n        data_aspect=1,\n    )\n    .opts(frame_height=400, aspect=\"equal\", colorbar_position=\"top\", framewise=False)\n)\n\nimg2 = (\n    gtc_dc.sel(band=band2)\n    .hvplot.image(\n        x=\"x\",\n        y=\"y\",\n        robust=True,\n        cmap=\"Greys_r\",\n        rasterize=True,\n        data_aspect=1,\n    )\n    .opts(frame_height=400, aspect=\"equal\", framewise=False, colorbar_position=\"top\")\n)\n\n\nswipe = pn.Swipe(img1, img2, height=500)\nswipe.servable()\nFigure 1: You can blend over between the ground range detected image (GRD) and the geometrically terrain corrected Sigma0 image using the swipe slider.\nThe geometrically terrain corrected values from the gtc_dc object (Figure 1) can be approximated to a certain extent, as we have sufficiently detailed information of topography in this area. This corrects for at least one typically occurring distortion in mountainous regions: “foreshortening”.\nFigure 2: Side Looking radar distortions (script Chapter 4).\nForeshortening can be spotted by eye, as it often has a radiometric consequence, where unusually bright areas fringe mountain ridges; a phenomenon called “highlighting”. This geometric artifact occurs due to the compression of the distance in the image of slopes facing the radar system and the consequentially higher density of scatterers per unit length. Now let’s zoom in on an example from the same datacube and display the original and corrected values side-by-side.\nfor_dc = gtc_dc.sel(x=slice(9.651, 9.706), y=slice(47.134, 47.079)).band_data\n\nfig, ax = plt.subplots(1, 2, figsize=(20, 8))\n\nbbox = {\"boxstyle\": \"round\", \"fc\": \"0.8\"}\narrowprops = {\"facecolor\": \"red\", \"shrink\": 0.05}\n\nax[1].annotate(\n    \"foreshortening/layover\",\n    xy=(9.674, 47.092),\n    xytext=(0.574, 0.192),\n    textcoords=\"subfigure fraction\",\n    bbox=bbox,\n    arrowprops=arrowprops,\n)\nax[1].annotate(\n    \"radar shadows\",\n    xy=(9.68, 47.119),\n    xytext=(0.6, 0.625),\n    textcoords=\"subfigure fraction\",\n    bbox=bbox,\n    arrowprops=arrowprops,\n)\n\nax[0].axes.set_aspect(\"equal\")\nax[1].axes.set_aspect(\"equal\")\n\nfor_dc.sel(band=\"grd\").plot(ax=ax[0], robust=True, cmap=\"Greys_r\")\nfor_dc.sel(band=\"sig0_gtc\").plot(ax=ax[1], robust=True, cmap=\"Greys_r\")\nFigure 3: Close-up inspection of geometric distortions in side-looking radar\nAs we can see, not all the geometric distortions can be corrected by the algorithm. Some of the pixels at the mountain ranges appear stretched, as in these areas not enough valid measurements are available. Moreover, we can see dark areas which are indicating radar shadows. These are image areas that could not be captured by the radar sensor and have values close to the noise floor of the Sensor (minimum detectable signal strength) ~ -28dB. It is important to note, that radar shadows are not the same for every image, as they depend on the acquisition geometry, in particular, the incidence angle and the flight direction of the satellite.",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Backscattering Coefficients</span>"
    ]
  },
  {
    "objectID": "unit_01/03_in_class_exercise.html#backscattering-coefficients",
    "href": "unit_01/03_in_class_exercise.html#backscattering-coefficients",
    "title": "3  Backscattering Coefficients",
    "section": "3.2 Backscattering Coefficients",
    "text": "3.2 Backscattering Coefficients\nIn this chapter, we will look at some of the different backscatter coefficients in more detail (\\(\\sigma^0_E\\) or \\(\\gamma^0_E\\)), where both coefficients are geometrically terrain corrected. The difference is the plane of the reference area, which is the ground area as a tangent on an ellipsoidal Earth model for \\(\\sigma^0_E\\) and perpendicular to the line of sight for \\(\\gamma^0_E\\). For this, we load a new datacube which includes \\(\\sigma^0_E\\) and the Incidence Angle for each pixel. We visualize the cube with the same method as before.\n\ncoef_dc = cat.coef.read().compute()\nband1 = coef_dc.band[0]\nband2 = coef_dc.band[1]\n\n\nimg1 = (\n    coef_dc.sel(band=band1)\n    .hvplot.image(\n        x=\"x\",\n        y=\"y\",\n        robust=True,\n        cmap=\"Greys_r\",\n        rasterize=True,\n        data_aspect=1,\n    )\n    .opts(frame_height=400, aspect=\"equal\", colorbar_position=\"top\", framewise=False)\n)\n\nimg2 = (\n    coef_dc.sel(band=band2)\n    .hvplot.image(\n        x=\"x\",\n        y=\"y\",\n        robust=True,\n        cmap=\"Greys_r\",\n        rasterize=True,\n        data_aspect=1,\n    )\n    .opts(frame_height=400, aspect=\"equal\", framewise=False, colorbar_position=\"top\")\n)\n\nswipe = pn.Swipe(img1, img2, height=500, name=f\"Swipe {band1} vs {band2}\")\nswipe.servable()\n\n\n\n\n\n\n\n\n  \n\n\n\n\nFigure 4: You can blend over between the \\(\\sigma^0_E\\) image and the incidence angle image using the swipe slider.\nIn Figure 4 we can see the incidence angle image of our scene. We can see, that it depicts the differences between near to far range, but not the actual terrain as it refers to the ellipsoid. The slight patterns of the terrain that are visible are originating from the geometric terrain correction. We will use this information now to convert our (\\(\\sigma^0_E\\) to \\(\\gamma^0_E\\)) with the following equation (equation 6.20 in the script):\n\\[ \\gamma^0_E = \\sigma^0_E / \\cos(\\theta_i) \\]\nWe can perform this transformation with basic numpy operations on the xarray datacube.\n\n# linear scale\nsig0_db = coef_dc.sel(band=\"sig0_gtc\") / 10\nsig0_lin = 10 ** (coef_dc.sel(band=\"sig0_gtc\") / 10)\n# conversion to gamma\ngam0_lin = sig0_lin / np.cos(np.radians(coef_dc.sel(band=\"incidence_angle\")))\n# dB scale\ngam0_db = 10 * np.log(gam0_lin)\n# add to existing cube\ncoef_dc = xr.concat(\n    [coef_dc.sel(band=\"sig0_gtc\"), gam0_db.expand_dims(band=[\"gam0_gtc\"])],\n    dim=\"band\",\n)\n\n\nband1 = coef_dc.sel(band=\"sig0_gtc\")\nband2 = coef_dc.sel(band=\"gam0_gtc\")\n\nimg1 = band1.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    cmap=\"Greys_r\",\n    rasterize=True,\n    data_aspect=1,\n).opts(frame_height=400, aspect=\"equal\", colorbar_position=\"top\", framewise=False)\n\nimg2 = band2.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    cmap=\"Greys_r\",\n    rasterize=True,\n    data_aspect=1,\n).opts(frame_height=400, aspect=\"equal\", framewise=False, colorbar_position=\"top\")\n\nswipe = pn.Swipe(img1, img2, height=500, name=f\"Swipe {band1} vs {band2}\")\nswipe.servable()\n\n\n\n\n\n\n\n\n  \n\n\n\n\nFigure 5: You can blend over between the \\(\\sigma^0_E\\) image and the \\(\\gamma^0_E\\) image using the swipe slider.\nComparing \\(\\sigma^0_E\\) and \\(\\gamma^0_E\\) in the figure, we can see that both look identical except for the range. This is because the only difference between \\(\\sigma^0_E\\) and \\(\\gamma^0_E\\) is the change of the reference area. While \\(\\sigma^0_E\\) is defined to be ground range, \\(\\gamma^0_E\\) is defined to be in the plane perpendicular to the line of sight from the sensor. This way, \\(\\gamma^0_E\\) mitigates the impact of the incidence angle. However, \\(\\gamma^0_E\\) is still based on the ellipsoid and does not account for the impact of the terrain on the radiometry.",
    "crumbs": [
      "Unit 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Backscattering Coefficients</span>"
    ]
  },
  {
    "objectID": "unit_02/04_in_class_exercise.html",
    "href": "unit_02/04_in_class_exercise.html",
    "title": "4  Datacubes",
    "section": "",
    "text": "4.1 Loading Data\nIn this notebook we discuss how we can easily compare images of two or more different time slices, satellites or other earth observation products. We limit our selves to products on a regular grid with an associated coordinate reference system (CRS), known as a raster. This means that each cell of the raster contains an attribute value and location coordinates. The process of combining such rasters to form datacubes is called raster stacking. We can have datacubes in many forms, such as the spatiotemporal datacube:\n\\[Z = f(x,y,t) \\quad \\text{,}\\]\nor when dealing with electromagnetic spectrum, the spectral wavelengths may form an additional dimension of a cube:\n\\[Z = f(x,y,t, \\lambda ) \\quad \\text{.} \\]\nWe also have already encountered the case where \\(Z\\) consists of multiple variables, such as seen in the xarray dataset.\n\\[{Z_1,Z_2,...,Z_3} = f(x,y,t) \\]\nTo perform raster stacking, we generally follow a certain routine (see also Figure 1).\nTo get the same projection, resolution, and region we have to resample one (or more) products. The desired projection, resolution, and region can be adopted from one of the original rasters or it can be a completely new projection of the data.\nFigure 1: Stacking of arrays to form datacubes (source: https://eox.at).\nIn this notebook we will study two different SAR products. SAR data from the Advanced Land Observing Satellite (Alos-2), which is a Japanese Satellite platform with an L-band sensor (PALSAR-2) from the Japan Aerospace Exploration Agency (JAXA), and C-band data from the Copernicus Sentinel-1 mission. It is our goal to compare C- with L-band, so we need to somehow stack these arrays.\nBefore loading the data into memory we will first look at the area covered by the Sentinel-1 dataset on a map. This way we can select a region of interest for our hypothetical study. We will extract and transform the bounds of the data to longitude and latitude.\nbbox = xr.open_mfdataset(\n    make_gitlab_urls(\"sentinel-1\"),\n    engine=\"rasterio\",\n    combine=\"nested\",\n    concat_dim=\"band\",\n).rio.transform_bounds(\"EPSG:4326\")\n\nbbox = box(*bbox)\n\narea_map = folium.Map(\n    max_bounds=True,\n    location=[bbox.centroid.y, bbox.centroid.x],\n    scrollWheelZoom=False,\n)\n\n# bounds of image\nfolium.GeoJson(mapping(bbox), name=\"Area of Interest\", color=\"red\").add_to(area_map)\n\n# minimum longitude, minimum latitude, maximum longitude, maximum latitude\narea_of_interest = box(10.3, 45.5, 10.6, 45.6)\n\nfolium.GeoJson(mapping(area_of_interest), name=\"Area of Interest\").add_to(area_map)\n\narea_map\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\nFigure 2: Map of study area. Red rectangle is the area covered by the Sentinel-1 raster. Blue rectangle is the area of interest.\nOn the map we have drawn rectangles of the area covered by the images and of our selected study area. To prevent loading too much data we will now only load the data as defined by the blue rectangle on the folium map.\nThe Sentinel-1 data is now stored on disk as separate two-dimensional GeoTIFF files with a certain timestamp. The following s1_preprocess function allows to load all files in one go as a spatiotemporal datacube. Basically, the preprocessing function helps reading the timestamp from the file and adds this as a new dimension to the array. The latter allows a concatenation procedure where all files are joined along the new time dimension. In addition by providing area_of_interest.bounds to the parameter bbox we will only load the data of the previously defined area of interest.\ndef s1_preprocess(\n    x: xr.Dataset,\n    bbox: tuple[float, float, float, float],\n    scale: float,\n) -&gt; xr.Dataset:\n    \"\"\"Preprocess file.\n\n    Parameters\n    ----------\n    x : xarray.Dataset\n      Input raster\n    bbox: tuple\n      Minimum longitude minimum latitude maximum longitude maximum latitude\n    scale: float\n      Scaling factor\n\n    Returns\n    -------\n    xarray.Dataset : Output stacked raster\n\n    \"\"\"\n    path = Path(urllib.parse.unquote_plus(x.encoding[\"source\"]))\n    filename = path.parent.name\n    x = x.rio.clip_box(*bbox, crs=\"EPSG:4326\")\n\n    date_str = filename.split(\"_\")[0][1:]\n    time_str = filename.split(\"_\")[1][:6]\n    datetime_str = date_str + time_str\n    date = pd.to_datetime(datetime_str, format=\"%Y%m%d%H%M%S\")\n    x = x.expand_dims(dim={\"time\": [date]})\n\n    x = (\n        x.rename({\"band_data\": \"s1_\" + path.parent.parent.stem})\n        .squeeze(\"band\")\n        .drop_vars(\"band\")\n    )\n\n    return x * scale\nWe load the data again with open_mfdataset and by providing the preprocess function, including the bounds of the area of interest and the scaling factor, as follows:\npartial_ = partial(s1_preprocess, bbox=area_of_interest.bounds, scale=0.01)\n\ns1_ds = xr.open_mfdataset(\n    make_gitlab_urls(\"sentinel-1\"),\n    engine=\"rasterio\",\n    combine=\"nested\",\n    chunks=-1,\n    preprocess=partial_,\n    compat=\"no_conflicts\",\n    join=\"outer\",\n)",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "unit_02/04_in_class_exercise.html#unlocking-geospatial-information",
    "href": "unit_02/04_in_class_exercise.html#unlocking-geospatial-information",
    "title": "4  Datacubes",
    "section": "4.2 Unlocking Geospatial Information",
    "text": "4.2 Unlocking Geospatial Information\nTo enable further stacking of ALOS-2 and Sentinel-1 data we need to know some more information about the raster. Hence we define the following function print_raster to get the projection (CRS), resolution, and region (bounds). The function leverages the functionality of rioxarray; a package for rasters.\n\ndef print_raster(raster: xr.Dataset | xr.DataArray, name: str) -&gt; None:\n    \"\"\"Print Raster Metadata.\n\n    Parameters\n    ----------\n    raster: xarray.DataArray|xarray.DataSet\n        raster to process\n    name: string\n        name of product\n\n    \"\"\"\n    print(\n        f\"{name} Raster: \\n----------------\\n\"\n        f\"resolution: {raster.rio.resolution()} {raster.rio.crs.units_factor}\\n\"\n        f\"bounds: {raster.rio.bounds()}\\n\"\n        f\"CRS: {raster.rio.crs}\\n\",\n    )\n\n\nprint_raster(s1_ds, \"Sentinel-1\")\n\nSentinel-1 Raster: \n----------------\nresolution: (10.0, -10.0) ('metre', 1.0)\nbounds: (4769370.0, 1382090.0, 4794450.0, 1397370.0)\nCRS: EPSG:27704\n\n\n\n\nThe CRS “EPSG 27704” is part of the EQUI7Grid. This grid provides equal-area tiles, meaning each tile represents the same area, which helps reducing distorsions. This feature is important for remote sensing as it reduces the so-called oversampling due to geometric distortions when projecting on a sphere. This particular projection is developed by TUWien.\nNow we will proceed with loading the ALOS-2 L-band data in much the same fashion as for Sentinel-1. Again timeslices are stored separately as individual GeoTIFFS and they need to be concatenated along the time dimension. We use a slightly different preprocessing function alos_preprocess for this purpose. The most notable difference of this function is the inclusion of a scaling factor for the 16-bit digital numbers (DN):\n\\[\\gamma^0_T = 10 * log_{10}(\\text{DN}^2) - 83.0 \\,dB\\]\nto correctly convert the integers to \\(\\gamma^0_T\\) in the dB range.\n\ndef alos_preprocess(\n    x: xr.Dataset,\n    bbox: tuple[float, float, float, float],\n) -&gt; xr.Dataset:\n    \"\"\"Preprocess file.\n\n    Parameters\n    ----------\n    x : xarray.Dataset\n      Input raster\n    bbox: tuple\n      minimum longitude minimum latitude maximum longitude maximum latitude\n\n    Returns\n    -------\n    xarray.Dataset : Output stacked raster\n\n    \"\"\"\n    path = Path(urllib.parse.unquote_plus(x.encoding[\"source\"]))\n    filename = path.parent.name\n    x = x.rio.clip_box(*bbox, crs=\"EPSG:4326\")\n\n    date_str = filename.split(\"_\")[0][15:22]\n    date = pd.to_datetime(date_str, format=\"%y%m%d\")\n    x = x.expand_dims(dim={\"time\": [date]})\n\n    x = (\n        x.rename({\"band_data\": \"alos_\" + path.parent.parent.stem})\n        .squeeze(\"band\")\n        .drop_vars(\"band\")\n    )\n\n    # conversion to dB scale of alos\n    return 10 * np.log10(x**2) - 83.0\n\nNow we load the data with the open_mfdataset function of xarray and we provide the preprocessing function (see above), which includes the selection of the bounds of an area of interest and the extraction of time stamps from the file name.\n\narea_of_interest = affinity.scale(area_of_interest, xfact=1.7, yfact=1.7)\npartial_ = partial(alos_preprocess, bbox=area_of_interest.bounds)\n\nalos_ds = xr.open_mfdataset(\n    make_gitlab_urls(\"alos-2\"),\n    engine=\"rasterio\",\n    combine=\"nested\",\n    chunks=-1,\n    preprocess=partial_,\n    compat=\"no_conflicts\",\n    join=\"outer\",\n)\n\nAlso, for this dataset we will look at the metadata in order to compare it with Sentinel-1.\n\nprint_raster(alos_ds, \"ALOS-2\")\n\nALOS-2 Raster: \n----------------\nresolution: (25.0, -25.0) ('metre', 1.0)\nbounds: (593137.5, 5035287.5, 633312.5, 5054912.5)\nCRS: EPSG:32632",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "unit_02/04_in_class_exercise.html#reprojecting",
    "href": "unit_02/04_in_class_exercise.html#reprojecting",
    "title": "4  Datacubes",
    "section": "4.3 Reprojecting",
    "text": "4.3 Reprojecting\nThe ALOS-2 is projected on an UTM grid. We would therefore like to reproject this data to match the projection of Sentinel-1. Furthermore, we will upsample the data to match the Sentinel-1 sampling. The rioxarray package has a very convenient method that can do this all in one go:reproject_match. For continuous data it is best to use a bilinear resampling strategy. As always you have to consider again that we deal with values in the dB range, so we need to convert to the linear scale before bilinear resampling.\n\nalos_ds_lin = 10 ** (alos_ds / 10)  # type: ignore[invalid-assignment]\nalos_ds_lin = alos_ds_lin.rio.reproject_match(  # type: ignore[unresolved-attribute]\n    s1_ds,\n    resampling=Resampling.bilinear,\n)\nalos_ds = 10 * np.log10(alos_ds_lin)\n\nWe will overwrite the coordinate values of ALOS-2 with those of Sentinel-1. If we would not do this last step, small errors in how the numbers are stored would prevent stacking of the rasters.\n\nalos_ds = alos_ds.assign_coords(\n    {\n        \"x\": s1_ds.x.data,\n        \"y\": s1_ds.y.data,\n    },\n)\n\nLastly, we will turn the xarray.DataSet to an xarray.DataArray where a new dimension will constitute the sensor for measurement (satellite + polarization).\n\ns1_da = s1_ds.to_array(dim=\"sensor\")\nalos_da = alos_ds.to_array(dim=\"sensor\")\ns1_da\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (sensor: 2, time: 9, y: 1528, x: 2508)&gt; Size: 276MB\ndask.array&lt;stack, shape=(2, 9, 1528, 2508), dtype=float32, chunksize=(1, 1, 1528, 2508), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * sensor       (sensor) object 16B 's1_VH' 's1_VV'\n  * time         (time) datetime64[ns] 72B 2022-06-25T05:27:26 ... 2022-10-11...\n  * y            (y) float64 12kB 1.397e+06 1.397e+06 ... 1.382e+06 1.382e+06\n  * x            (x) float64 20kB 4.769e+06 4.769e+06 ... 4.794e+06 4.794e+06\n    spatial_ref  int64 8B 0xarray.DataArraysensor: 2time: 9y: 1528x: 2508dask.array&lt;chunksize=(1, 1, 1528, 2508), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n263.14 MiB\n14.62 MiB\n\n\nShape\n(2, 9, 1528, 2508)\n(1, 1, 1528, 2508)\n\n\nDask graph\n18 chunks in 223 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n          2 1                                          2508 1528 9\n\n\n\n\nCoordinates: (5)sensor(sensor)object's1_VH' 's1_VV'array(['s1_VH', 's1_VV'], dtype=object)time(time)datetime64[ns]2022-06-25T05:27:26 ... 2022-10-...array(['2022-06-25T05:27:26.000000000', '2022-07-07T05:27:27.000000000',\n       '2022-07-19T05:27:28.000000000', '2022-07-31T05:27:29.000000000',\n       '2022-08-12T05:27:29.000000000', '2022-09-05T05:27:31.000000000',\n       '2022-09-17T05:27:31.000000000', '2022-09-29T05:27:31.000000000',\n       '2022-10-11T05:27:31.000000000'], dtype='datetime64[ns]')y(y)float641.397e+06 1.397e+06 ... 1.382e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1397365., 1397355., 1397345., ..., 1382115., 1382105., 1382095.],\n      shape=(1528,))x(x)float644.769e+06 4.769e+06 ... 4.794e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([4769375., 4769385., 4769395., ..., 4794425., 4794435., 4794445.],\n      shape=(2508,))spatial_ref()int640crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0array(0)",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "unit_02/04_in_class_exercise.html#stacking-of-multiple-arrays",
    "href": "unit_02/04_in_class_exercise.html#stacking-of-multiple-arrays",
    "title": "4  Datacubes",
    "section": "4.4 Stacking of Multiple Arrays",
    "text": "4.4 Stacking of Multiple Arrays\nNow we are finally ready to stack Sentinel-1 C-band and ALOS-2 L-band arrays with the function concat of xarray. Now we can use the newly defined \"sensor\" dimension to concatenate the two arrays.\n\nfused_da = xr.concat([s1_da, alos_da], dim=\"sensor\", join=\"outer\").rename(\"gam0\")\nfused_da\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'gam0' (sensor: 4, time: 14, y: 1528, x: 2508)&gt; Size: 858MB\ndask.array&lt;concatenate, shape=(4, 14, 1528, 2508), dtype=float32, chunksize=(2, 1, 1094, 1094), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * sensor       (sensor) object 32B 's1_VH' 's1_VV' 'alos_HH' 'alos_HV'\n  * time         (time) datetime64[ns] 112B 2022-06-25 ... 2022-10-15\n  * y            (y) float64 12kB 1.397e+06 1.397e+06 ... 1.382e+06 1.382e+06\n  * x            (x) float64 20kB 4.769e+06 4.769e+06 ... 4.794e+06 4.794e+06\n    spatial_ref  int64 8B 0xarray.DataArray'gam0'sensor: 4time: 14y: 1528x: 2508dask.array&lt;chunksize=(1, 1, 1094, 1094), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n818.65 MiB\n9.13 MiB\n\n\nShape\n(4, 14, 1528, 2508)\n(2, 1, 1094, 1094)\n\n\nDask graph\n252 chunks in 241 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n           4 1                                                          2508 1528 14\n\n\n\n\nCoordinates: (5)sensor(sensor)object's1_VH' 's1_VV' 'alos_HH' 'alos_HV'array(['s1_VH', 's1_VV', 'alos_HH', 'alos_HV'], dtype=object)time(time)datetime64[ns]2022-06-25 ... 2022-10-15array(['2022-06-25T00:00:00.000000000', '2022-06-25T05:27:26.000000000',\n       '2022-07-07T05:27:27.000000000', '2022-07-19T05:27:28.000000000',\n       '2022-07-31T05:27:29.000000000', '2022-08-12T05:27:29.000000000',\n       '2022-08-20T00:00:00.000000000', '2022-09-05T05:27:31.000000000',\n       '2022-09-17T00:00:00.000000000', '2022-09-17T05:27:31.000000000',\n       '2022-09-29T05:27:31.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-10-11T05:27:31.000000000', '2022-10-15T00:00:00.000000000'],\n      dtype='datetime64[ns]')y(y)float641.397e+06 1.397e+06 ... 1.382e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1397365., 1397355., 1397345., ..., 1382115., 1382105., 1382095.],\n      shape=(1528,))x(x)float644.769e+06 4.769e+06 ... 4.794e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([4769375., 4769385., 4769395., ..., 4794425., 4794435., 4794445.],\n      shape=(2508,))spatial_ref()int640crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0array(0)\n\n\nThe measurements for both satellites don’t occur at the same time. Hence the cube is now padded with 2-D arrays entirely filled with NaN (Not A Number) for some time slices. As we have learned in notebook 2 we can use the resample method to make temporally coherent timeslices for each month. To deal with the dB scale backscatter values as well as the low number of observations per month we use a median of the samples. As taking the median only sorts the samples according to the sample quantiles we do not have to convert the observations to the linear scale.\n\nfused_da = fused_da.resample(time=\"ME\", skipna=True).median().compute()\n\n/home/runner/work/microwave-remote-sensing/microwave-remote-sensing/.conda_envs/microwave-remote-sensing/lib/python3.13/site-packages/dask/_task_spec.py:758: RuntimeWarning: All-NaN slice encountered\n  return self.func(*new_argspec, **kwargs)\n\n\nWe can plot each of the variables: “ALOS-2” and “Sentinel-1” to check our results.\n\nfused_da.hvplot.image(robust=True, data_aspect=1, cmap=\"Greys_r\", rasterize=True).opts(\n    frame_height=600,\n    aspect=\"equal\",\n)\n\n\n\n\n\n  \n\n\n\n\nFigure 3: Stacked array with ALOS-2 L-band and Sentinel-1 C-band \\(\\gamma^0_T (dB)\\).",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "unit_02/05_in_class_exercise.html",
    "href": "unit_02/05_in_class_exercise.html",
    "title": "5  Wavelength and Polarization",
    "section": "",
    "text": "5.1 Data Loading\nIn this notebook, we aim to demonstrate how C-band (4–8 GHz, wavelengths of approximately 3.75–7.5 cm) and L-band (1–2 GHz, wavelengths of approximately 15–30 cm) radio frequencies differ for different land covers and times of the year. In addition, we’ll look at co- and cross-polarized backscattering:\nWe load the data again with the help of intake.\nurl = get_intake_url()\ncat = intake.open_catalog(url)\nfused_ds = cat.fused.read().compute()\nfused_ds\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 460MB\nDimensions:      (time: 5, y: 1528, x: 2508, sensor: 4)\nCoordinates:\n  * time         (time) datetime64[ns] 40B 2022-06-30 2022-07-31 ... 2022-10-31\n  * y            (y) float64 12kB 1.397e+06 1.397e+06 ... 1.382e+06 1.382e+06\n  * x            (x) float64 20kB 4.769e+06 4.769e+06 ... 4.794e+06 4.794e+06\n  * sensor       (sensor) object 32B 's1_VH' 's1_VV' 'alos_HH' 'alos_HV'\n    crs          int64 8B 0\n    spatial_ref  int64 8B 0\nData variables:\n    LAI          (time, y, x) float64 153MB 5.0 5.0 5.133 5.133 ... nan nan nan\n    gam0         (time, sensor, y, x) float32 307MB -14.52 -14.8 ... -31.16xarray.DatasetDimensions:time: 5y: 1528x: 2508sensor: 4Coordinates: (6)time(time)datetime64[ns]2022-06-30 ... 2022-10-31array(['2022-06-30T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000'], dtype='datetime64[ns]')y(y)float641.397e+06 1.397e+06 ... 1.382e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1397365., 1397355., 1397345., ..., 1382115., 1382105., 1382095.],\n      shape=(1528,))x(x)float644.769e+06 4.769e+06 ... 4.794e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([4769375., 4769385., 4769395., ..., 4794425., 4794435., 4794445.],\n      shape=(2508,))sensor(sensor)object's1_VH' 's1_VV' 'alos_HH' 'alos_HV'array(['s1_VH', 's1_VV', 'alos_HH', 'alos_HV'], dtype=object)crs()int640GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)spatial_ref()int640GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)Data variables: (2)LAI(time, y, x)float645.0 5.0 5.133 5.133 ... nan nan nanlong_name :Leaf Area Index 333mstandard_name :leaf_area_indexunits :m^2/m^2valid_range :[0, 210]array([[[4.99999999, 4.99999999, 5.13333333, ..., 3.73333333,\n         3.73333333, 3.73333333],\n        [4.86666666, 4.86666666, 5.29999999, ..., 3.73333333,\n         3.73333333, 3.73333333],\n        [4.86666666, 4.86666666, 5.29999999, ..., 3.73333333,\n         3.73333333, 3.73333333],\n        ...,\n        [0.83333333, 0.83333333, 0.83333333, ...,        nan,\n                nan,        nan],\n        [0.83333333, 0.83333333, 0.83333333, ...,        nan,\n                nan,        nan],\n        [0.83333333, 0.83333333, 0.83333333, ...,        nan,\n                nan,        nan]],\n\n       [[2.46666666, 2.46666666, 3.        , ..., 1.26666667,\n         1.26666667, 1.26666667],\n        [2.96666666, 2.96666666, 3.66666666, ..., 1.26666667,\n         1.26666667, 1.26666667],\n        [2.96666666, 2.96666666, 3.66666666, ..., 1.26666667,\n         1.26666667, 1.26666667],\n...\n        [1.23333333, 1.23333333, 1.23333333, ...,        nan,\n                nan,        nan],\n        [1.23333333, 1.23333333, 1.23333333, ...,        nan,\n                nan,        nan],\n        [1.23333333, 1.23333333, 1.23333333, ...,        nan,\n                nan,        nan]],\n\n       [[1.76666666, 1.76666666, 1.93333333, ..., 1.6       ,\n         1.6       , 1.6       ],\n        [1.83333333, 1.83333333, 2.1       , ..., 1.6       ,\n         1.6       , 1.6       ],\n        [1.83333333, 1.83333333, 2.1       , ..., 1.6       ,\n         1.6       , 1.6       ],\n        ...,\n        [0.86666667, 0.86666667, 0.86666667, ...,        nan,\n                nan,        nan],\n        [0.86666667, 0.86666667, 0.86666667, ...,        nan,\n                nan,        nan],\n        [0.86666667, 0.86666667, 0.86666667, ...,        nan,\n                nan,        nan]]], shape=(5, 1528, 2508))gam0(time, sensor, y, x)float32-14.52 -14.8 ... -30.78 -31.16array([[[[-14.5199995, -14.799999 , -15.94     , ..., -22.07     ,\n          -19.99     , -20.369999 ],\n         [-15.67     , -14.9      , -14.599999 , ..., -18.48     ,\n          -14.509999 , -16.39     ],\n         [-16.4      , -15.679999 , -14.889999 , ..., -15.42     ,\n          -11.19     , -12.62     ],\n         ...,\n         [-16.74     , -18.279999 , -21.05     , ..., -24.72     ,\n          -25.599998 , -26.369999 ],\n         [-15.349999 , -15.259999 , -17.64     , ..., -25.47     ,\n          -25.08     , -25.75     ],\n         [-15.61     , -15.98     , -16.619999 , ..., -26.32     ,\n          -26.789999 , -25.91     ]],\n\n        [[-10.76     ,  -9.969999 ,  -7.83     , ..., -10.7      ,\n           -8.21     , -10.05     ],\n         [-10.69     ,  -9.2      ,  -8.36     , ...,  -9.29     ,\n           -5.93     ,  -7.3999996],\n         [-11.12     , -10.11     ,  -9.15     , ...,  -9.889999 ,\n           -4.99     ,  -6.6      ],\n...\n          -19.319828 , -18.72637  ],\n         [        nan,         nan,         nan, ..., -20.127197 ,\n          -19.506496 , -18.70882  ],\n         [        nan,         nan,         nan, ..., -20.10392  ,\n          -19.47015  , -18.68003  ]],\n\n        [[-14.129457 , -14.054055 , -13.846073 , ...,         nan,\n                  nan,         nan],\n         [-15.771104 , -15.154463 , -14.165511 , ...,         nan,\n                  nan,         nan],\n         [-13.967249 , -14.349602 , -14.299993 , ...,         nan,\n                  nan,         nan],\n         ...,\n         [        nan,         nan,         nan, ..., -28.712454 ,\n          -28.836363 , -29.904612 ],\n         [        nan,         nan,         nan, ..., -29.798288 ,\n          -30.100616 , -30.784294 ],\n         [        nan,         nan,         nan, ..., -30.489552 ,\n          -30.782894 , -31.163181 ]]]],\n      shape=(5, 4, 1528, 2508), dtype=float32)\nThe loaded data contains the Leaf Area Index (LAI), which is used as an estimate of foliage cover of forest canopies. So high LAI is interpreted as forested area, whereas low values account for less vegetated areas (shrubs, grass-land, and crops).\nFirst we’ll have a look at the mean and standard deviation of LAI over all timeslices. This can be achieved by using the mean and std methods of the xarray object and by supplying a dimension over which these aggregating operations will be applied. We use the dimension “time”, thereby flattening the cube to a 2-D array with dimensions x and y.\nfig, ax = plt.subplots(1, 2, figsize=(15, 6))\n\nLAI_dc = fused_ds.LAI\nLAI_mean = LAI_dc.mean(\"time\")\nLAI_std = LAI_dc.std(\"time\")\n\nLAI_mean.plot(ax=ax[0], vmin=0, vmax=6).axes.set_aspect(\"equal\")\nLAI_std.plot(ax=ax[1], vmin=0, vmax=3).axes.set_aspect(\"equal\")\nplt.tight_layout()\n\n/home/runner/work/microwave-remote-sensing/microwave-remote-sensing/.conda_envs/microwave-remote-sensing/lib/python3.13/site-packages/numpy/lib/_nanfunctions_impl.py:2015: RuntimeWarning: Degrees of freedom &lt;= 0 for slice.\n  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\nFigure 1: Map of mean LAI (left) and the associated standard deviation (right) for each pixel over time around Lake Garda.\nIt appears that the northern parts of our study area contain more and variable amounts of green elements per unit area. This might indicate a more complete coverage of foliage and thus forest.",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Wavelength and Polarization</span>"
    ]
  },
  {
    "objectID": "unit_02/05_in_class_exercise.html#timeseries",
    "href": "unit_02/05_in_class_exercise.html#timeseries",
    "title": "5  Wavelength and Polarization",
    "section": "5.2 Timeseries",
    "text": "5.2 Timeseries\nNow that we have detected possible forested areas, let’s delve a bit deeper into the data. Remember that we deal with a spatiotemporal datacube. This gives us the possibility to study changes for each time increment. Hence we can show what happens to LAI for areas marked with generally low values as well as high values. We can achieve this by filtering the datacube with the where method for areas marked with low and high mean LAI values. In turn we will aggregate the remaining datacube over the spatial dimensions (“x” and “y”) to get a mean values for each time increment.\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 4))\n\nthreshold = 4\nLAI_low = LAI_dc.where(LAI_mean &lt; threshold)\nLAI_high = LAI_dc.where(LAI_mean &gt; threshold)\n\nLAI_low.mean([\"x\", \"y\"]).plot.scatter(x=\"time\", ax=ax[0], ylim=(0, 6))\nLAI_high.mean([\"x\", \"y\"]).plot.scatter(x=\"time\", ax=ax[1], ylim=(0, 6))\nax[0].set_title(\"Low Mean LAI ($\\\\bar{LAI} &lt; {threshold}$)\")\nax[1].set_title(\"High Mean LAI ($\\\\bar{LAI} &gt; {threshold}$)\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nFigure 2: Timeseries of mean LAI per timeslice for areas with low (left) and high (right) mean LAI of Figure1.\nNow we can see that areas with high mean LAI values (Figure 1) show a drop-off to values as low as those for areas with low mean LAI during the autumn months (Figure 2 ; right panel). Hence we might deduce that we deal with deciduous forest that becomes less green during autumn, as can be expected for the study area.\nRemember that longer wavelengths like L-bands are more likely to penetrate through a forest canopy and would interact more readily with larger object like tree trunks and the forest floor. In turn, C-band microwaves are more likely to interact with sparse and shrub vegetation. The polarization of the emitted and received microwaves is on the other hand dependent on the type of backscattering with co-polarization (HH and VV) happening more frequently with direct backscatter or double bounce scattering. Whereas volume scattering occurs when the radar signal is subject to multiple reflections within 3-dimensional matter, as the orientation of the main scatterers is random, the polarization of the backscattered signal is also random. Volume scattering can therefore cause an increase of cross-polarized intensity.\nLet’s put this to the test by checking the microwave backscatter signatures over forested and sparsely vegetated areas as well as water bodies (Lake Garda). Let’s first look at the different sensor readings for the beginning of summer and autumn.\n\nhv.output(widget_location=\"bottom\")\n\nt1 = (\n    fused_ds.gam0.isel(time=2)\n    .hvplot.image(\n        robust=True,\n        data_aspect=1,\n        cmap=\"Greys_r\",\n        rasterize=True,\n        clim=(-25, 0),\n    )\n    .opts(frame_height=400, aspect=\"equal\")\n)\n\nt2 = (\n    fused_ds.gam0.isel(time=-1)\n    .hvplot.image(\n        robust=True,\n        data_aspect=1,\n        cmap=\"Greys_r\",\n        rasterize=True,\n        clim=(-25, 0),\n    )\n    .opts(frame_height=400, aspect=\"equal\")\n)\n\nt1 + t2\n\n\n\n\n\n  \n\n\n\n\nFigure 3: Maps of Sentinel-1 and Alos-2 \\(\\gamma^0_T \\,[dB]\\) for the beginning of summer (left) and autumn (right).\nThe most notable difference is the lower energy received for cross-polarized than for co-polarized microwaves for both Sentinel-1 and Alos-2. The latter differences are independent of the time of year. However, one can also note small changes in the received energy for the same satellite dependent on the time of year. To get a better feel for these changes over time we generate the following interactive plot. On the following plot one can select areas of a certain mean LAI (by clicking on the map) and see the associated timeseries of \\(\\gamma^0_T\\) for each of the sensors.\n\nLAI_image = LAI_mean.hvplot.image(rasterize=True, cmap=\"viridis\", clim=(0, 6)).opts(\n    title=\"Mean LAI (Selectable)\",\n    frame_height=400,\n    frame_width=400,\n    aspect=\"equal\",\n)\n\n\ndef get_timeseries(x: float, y: float) -&gt; hv.Scatter:\n    \"\"\"Plot LAI timeseries.\n\n    Parameters\n    ----------\n    x: float\n        numeric value for x selected on LAI map\n    y: float\n        numeric value for y selected on LAI map\n\n    Returns\n    -------\n    hvplot.Scatter : LAI timeseries plot\n\n    \"\"\"\n    lai_value = LAI_mean.sel(x=x, y=y, method=\"nearest\").values\n\n    if np.isnan(lai_value):\n        select = fused_ds.where(LAI_mean.isnull())\n        label = \"Water\"\n    else:\n        mask = np.isclose(LAI_mean, lai_value, atol=0.05)\n        select = fused_ds.where(mask)\n        label = \"Mean LAI: \" + str(np.round(lai_value, 1))\n\n    return (\n        select.gam0.to_dataset(\"sensor\")\n        .median([\"x\", \"y\"], skipna=True)\n        .hvplot.scatter(ylim=(-30, 5))\n        .opts(title=label, frame_height=400)\n    )\n\n\npoint_stream = hv.streams.SingleTap(source=LAI_image)\ntime_series = hv.DynamicMap(get_timeseries, streams=[point_stream])\nLAI_image + time_series\n\n\n\n\n\n  \n\n\n\n\nFigure 4: Map of MEAN LAI around Lake Garda. The pixel values can be seen by hovering your mouse over the pixels. Clicking on the pixel will generate the timeseries for the associated mean LAI on the right hand-side. (Right) Timeseries of for Sentinel-1 and Alos-2 \\(\\gamma^0_T [dB]\\).\nCan you see some patterns when analyzing the different wavelengths and polarizations?\nRemember again that we deal with a logarithmic scale. A measurement of 10 dB is 10 times brighter than the intensity measured at 0 dB, and 100 times brighter at 20 dB. The most notable difference is that the offset between cross- and co-polarised signals becomes larger at low LAI and lower at higher LAI. This might indicate the effect of volume scattering in forested areas where co- and cross-polarization render backscattering values more equal. You will study the differences among cross- and co-polarized backscattering in more detail in the homework exercise.",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Wavelength and Polarization</span>"
    ]
  },
  {
    "objectID": "unit_02/06_in_class_exercise.html",
    "href": "unit_02/06_in_class_exercise.html",
    "title": "6  Dielectric Properties",
    "section": "",
    "text": "In this notebook, we will investigate the varying backscatter values associated with different land surfaces like water bodies, forests, grasslands and urban areas. We will use backscatter data from the Sentinel-1 satellite and we will utilize the CORINE Land Cover dataset to classify and extrapolate these surfaces, enabling us to analyze how different land cover types influence backscatter responses.",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Backscatter Variability</span>"
    ]
  },
  {
    "objectID": "unit_02/06_in_class_exercise.html#load-sentinel-1-data",
    "href": "unit_02/06_in_class_exercise.html#load-sentinel-1-data",
    "title": "6  Dielectric Properties",
    "section": "6.1 Load Sentinel-1 Data",
    "text": "6.1 Load Sentinel-1 Data\nFor our analysis we are using sigma naught backscattering data from Sentinel-1. The images that we are analyzing cover the region south of Vienna and west of Lake Neusiedl. We will now load the data and and apply again a preprocessing function. Here we extract the scaling factor and the date the image was taken from the metadata. We will focus our attention to a smaller area containing a part of the Lake Neusiedl Lake and its surrounding land. The obtainedxarray dataset and is then converted to an array, because we only have one variable, the VV backscatter values.\n\nurl = get_intake_url()\ncat = intake.open_catalog(url)\nsig0_da = cat.neusiedler.read().sig0.compute()\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\nLet’s have a look at the data by plotting the first timeslice.\n\nsig0_da.isel(time=0).plot(robust=True, cmap=\"Greys_r\").axes.set_aspect(\"equal\")",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Backscatter Variability</span>"
    ]
  },
  {
    "objectID": "unit_02/06_in_class_exercise.html#load-corine-landcover-data",
    "href": "unit_02/06_in_class_exercise.html#load-corine-landcover-data",
    "title": "6  Dielectric Properties",
    "section": "6.2 Load CORINE Landcover Data",
    "text": "6.2 Load CORINE Landcover Data\nWe will load the CORINE Land Cover, which is a pan-European land cover and land use inventory with 44 thematic classes. The resolution of this classification is 100 by 100m and the file was created in 2018 (CORINE Land Cover).\n\ncor_da = cat.corine.read().land_cover.compute()\n\n\n6.2.1 Colormapping and Encoding\nFor the different land cover types we use the official color encoding which can be found in CORINE Land Cover.\n\n# Load encoding and validate with Pydantic\nwith cat.corine_cmap.read()[0] as f:\n    corine_colors = CorineColorCollection.model_validate(json.load(f))\n\n# Create cmap and norm for plotting\ncolors = [info[\"color\"].as_hex() for info in corine_colors.items]\ncategories = [info[\"value\"] for info in corine_colors.items]\ncmap = ListedColormap(colors)\nnorm = BoundaryNorm([*categories, max(categories) + 1], len(categories))\n\nNow we can plot the CORINE Land Cover dataset.\n\npresent_landcover_codes = np.unique(cor_da.values[~np.isnan(cor_da.values)].astype(int))\n\n# Create the plot\nplot_corine_data(cor_da, cmap, norm, corine_colors, present_landcover_codes)\n\n\n\n\n\n\n\n\nNow we are ready to merge the backscatter data (sig0_da) with the land cover dataset (cor_da) to have one dataset combining all data.\n\nvar_ds = xr.merge([sig0_da, cor_da], compat=\"no_conflicts\").drop_vars(\"band\")\nvar_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 96MB\nDimensions:      (time: 7, x: 1230, y: 1221)\nCoordinates:\n  * time         (time) datetime64[ns] 56B 2023-08-17T16:51:22 ... 2023-10-28...\n  * x            (x) float64 10kB 5.282e+06 5.282e+06 ... 5.294e+06 5.294e+06\n  * y            (y) float64 10kB 1.571e+06 1.571e+06 ... 1.559e+06 1.559e+06\n    spatial_ref  int64 8B 0\nData variables:\n    sig0         (time, y, x) float64 84MB -8.5 -10.65 -12.07 ... -14.32 -14.22\n    land_cover   (y, x) float64 12MB 12.0 12.0 12.0 12.0 ... 41.0 41.0 41.0 41.0xarray.DatasetDimensions:time: 7x: 1230y: 1221Coordinates: (4)time(time)datetime64[ns]2023-08-17T16:51:22 ... 2023-10-...array(['2023-08-17T16:51:22.000000000', '2023-08-29T16:51:23.000000000',\n       '2023-09-10T16:51:24.000000000', '2023-09-22T16:51:24.000000000',\n       '2023-10-04T16:51:24.000000000', '2023-10-16T16:51:24.000000000',\n       '2023-10-28T16:51:24.000000000'], dtype='datetime64[ns]')x(x)float645.282e+06 5.282e+06 ... 5.294e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([5281995., 5282005., 5282015., ..., 5294265., 5294275., 5294285.],\n      shape=(1230,))y(y)float641.571e+06 1.571e+06 ... 1.559e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1570955., 1570945., 1570935., ..., 1558775., 1558765., 1558755.],\n      shape=(1221,))spatial_ref()int640GeoTransform :5281990.0 10.0 0.0 1570960.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)Data variables: (2)sig0(time, y, x)float64-8.5 -10.65 ... -14.32 -14.22array([[[ -8.5 , -10.65, -12.07, ..., -22.27, -20.91, -21.92],\n        [ -9.  , -10.03, -10.82, ..., -16.46, -16.9 , -21.84],\n        [ -6.74,  -7.87,  -8.1 , ..., -17.41, -22.64, -23.01],\n        ...,\n        [ -8.74,  -7.44,  -6.69, ..., -10.85,  -8.39,  -7.08],\n        [ -9.39,  -9.55,  -8.9 , ..., -13.  , -11.03,  -9.15],\n        [-10.86, -10.84,  -9.7 , ..., -17.47, -14.58, -10.65]],\n\n       [[-10.39, -11.92, -11.74, ..., -19.02, -20.28, -17.92],\n        [ -8.65, -14.64, -12.34, ..., -21.77, -19.55, -16.67],\n        [ -8.11, -11.29, -10.25, ..., -23.16, -20.23, -16.73],\n        ...,\n        [-10.69,  -7.85,  -6.51, ..., -11.02,  -8.21,  -7.69],\n        [-12.83, -10.4 ,  -9.26, ..., -14.74,  -9.62,  -7.99],\n        [-13.76, -12.13, -12.08, ..., -18.51, -12.62,  -9.14]],\n\n       [[ -9.47, -14.49, -15.86, ..., -23.19, -24.68, -25.28],\n        [ -9.7 , -13.62, -12.49, ..., -27.02, -23.13, -22.35],\n        [-10.84, -12.3 , -12.61, ..., -23.46, -22.93, -21.64],\n        ...,\n...\n        [ -9.82,  -9.11,  -8.73, ...,  -9.79,  -7.33,  -6.92],\n        [-12.23, -11.64,  -9.59, ..., -12.29,  -7.65,  -8.14],\n        [-13.6 , -13.41, -11.73, ..., -19.82, -12.53, -11.83]],\n\n       [[-12.49, -12.55, -12.89, ..., -21.35, -23.29, -23.87],\n        [-12.15, -12.38, -14.03, ..., -18.07, -23.53, -23.23],\n        [-12.41, -12.52, -14.08, ..., -18.7 , -21.47, -22.17],\n        ...,\n        [ -6.87,  -5.98,  -5.32, ..., -18.47, -12.26, -11.2 ],\n        [-11.18,  -6.31,  -6.12, ..., -20.17, -12.56, -11.61],\n        [-11.98,  -9.02,  -8.46, ..., -13.06, -10.4 ,  -9.  ]],\n\n       [[ -6.41,  -6.59,  -7.16, ..., -22.25, -25.96, -25.45],\n        [ -6.75,  -9.42,  -9.54, ..., -20.65, -26.34, -23.53],\n        [ -8.24, -12.04, -10.46, ..., -20.65, -20.63, -21.05],\n        ...,\n        [ -6.64,  -5.06,  -4.89, ..., -13.67, -12.26,  -9.96],\n        [ -9.62,  -8.06, -10.02, ..., -16.11, -14.74, -10.64],\n        [-11.93, -11.41, -12.68, ..., -19.01, -14.32, -14.22]]],\n      shape=(7, 1221, 1230))land_cover(y, x)float6412.0 12.0 12.0 ... 41.0 41.0 41.0AREA_OR_POINT :AreaDataType :ThematicRepresentationType :THEMATICSTATISTICS_COVARIANCES :136.429646247598STATISTICS_MAXIMUM :48STATISTICS_MEAN :25.753373398066STATISTICS_MINIMUM :1STATISTICS_SKIPFACTORX :1STATISTICS_SKIPFACTORY :1STATISTICS_STDDEV :11.680310194836array([[12., 12., 12., ..., 41., 41., 41.],\n       [12., 12., 12., ..., 41., 41., 41.],\n       [12., 12., 12., ..., 41., 41., 41.],\n       ...,\n       [ 2.,  2.,  2., ..., 41., 41., 41.],\n       [ 2.,  2.,  2., ..., 41., 41., 41.],\n       [ 2.,  2.,  2., ..., 41., 41., 41.]], shape=(1221, 1230))",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Backscatter Variability</span>"
    ]
  },
  {
    "objectID": "unit_02/06_in_class_exercise.html#backscatter-variability",
    "href": "unit_02/06_in_class_exercise.html#backscatter-variability",
    "title": "6  Dielectric Properties",
    "section": "6.3 Backscatter Variability",
    "text": "6.3 Backscatter Variability\nWith this combined dataset we can study the backscatter variability in relation to natural media. For example, we can analyze the backscatter variability for water by clipping the dataset to include only the water land cover class, as shown below.\n\n# 41 = encoded value for water bodies\nencoded_value_for_waterbodies = 41\nwaterbodies_mask = var_ds.land_cover == encoded_value_for_waterbodies\nwaterbodies_mask.plot().axes.set_aspect(\"equal\")\n\n\n\n\n\n\n\n\nThis gives use backscatter values over water only.\n\nwaterbodies_sig0 = var_ds.sig0.isel(time=0).where(waterbodies_mask)\nwaterbodies_sig0.plot(robust=True, cmap=\"Greys_r\").axes.set_aspect(\"equal\")\n\n\n\n\n\n\n\n\nTo get an idea of the variability we can create a histogram. Radar backscatter from water bodies fluctuates with surface roughness, which changes with wind conditions, creating spatial and temporal variations in signal intensity.\n\nwaterbodies_sig0.plot.hist(bins=50, edgecolor=\"black\")\nplt.show()",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Backscatter Variability</span>"
    ]
  },
  {
    "objectID": "unit_02/06_in_class_exercise.html#variability-over-time",
    "href": "unit_02/06_in_class_exercise.html#variability-over-time",
    "title": "6  Dielectric Properties",
    "section": "6.4 Variability over Time",
    "text": "6.4 Variability over Time\nNext we will look at the changes in variability in backscatter values over time for each of the CORINE Land Cover types. We do this by creating the following interactive plot.\nWe can observe that backscatter in agricultural fields varies throughout the year due to several factors:\n\nSeasonal cycles such as planting, growing, and harvesting, which alter the vegetation structure.\nSoil moisture variations driven by irrigation or rainfall events.\nCrop phenology, where different growth stages affect canopy density and structure.\nCanopy moisture dynamics, influencing how radar signals are scattered and absorbed.\n\n\nplot_variability_over_time(\n    var_ds=var_ds,\n    color_mapping=corine_colors.to_dict(),\n    present_landcover_codes=present_landcover_codes,\n)",
    "crumbs": [
      "Unit 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Backscatter Variability</span>"
    ]
  },
  {
    "objectID": "unit_03/07_in_class_exercise.html",
    "href": "unit_03/07_in_class_exercise.html",
    "title": "7  Speckle Statistics",
    "section": "",
    "text": "This notebook will provide an empirical demonstration of speckle - how it originates, how it visually and statistically looks like, and some of the most common approaches to filter it.\nSpeckle is defined as a kind of noise that affects all radar images. Given the multiple scattering contributions originating from the various elementary objects present within a resolution cell, the resulting backscatter signal can be described as a random constructive and destructive interference of wavelets. As a consequence, speckle is the reason why a granular pattern normally affects SAR images, making it more challenging to interpret and analyze them.\nCredits: ESRI",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "unit_03/07_in_class_exercise.html#lake-neusiedl-data",
    "href": "unit_03/07_in_class_exercise.html#lake-neusiedl-data",
    "title": "7  Speckle Statistics",
    "section": "7.1 Lake Neusiedl data",
    "text": "7.1 Lake Neusiedl data\nWe load a dataset that contains the CORINE land cover and Sentinel-1 \\(\\sigma^0_E\\) at a 20 meter resolution. This is the same data presented in notebook 6.\n\nurl = get_intake_url()\ncat = intake.open_catalog(url)\nfused_ds = cat.speckle.read().compute()\nfused_ds\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 96MB\nDimensions:      (y: 1221, x: 1230, time: 7)\nCoordinates:\n  * y            (y) float64 10kB 1.571e+06 1.571e+06 ... 1.559e+06 1.559e+06\n  * x            (x) float64 10kB 5.282e+06 5.282e+06 ... 5.294e+06 5.294e+06\n  * time         (time) datetime64[ns] 56B 2023-08-17T16:51:22 ... 2023-10-28...\n    spatial_ref  int64 8B 0\nData variables:\n    land_cover   (y, x) float64 12MB 12.0 12.0 12.0 12.0 ... 41.0 41.0 41.0 41.0\n    sig0         (time, y, x) float64 84MB -8.5 -10.65 -12.07 ... -14.32 -14.22xarray.DatasetDimensions:y: 1221x: 1230time: 7Coordinates: (4)y(y)float641.571e+06 1.571e+06 ... 1.559e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1570955., 1570945., 1570935., ..., 1558775., 1558765., 1558755.],\n      shape=(1221,))x(x)float645.282e+06 5.282e+06 ... 5.294e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([5281995., 5282005., 5282015., ..., 5294265., 5294275., 5294285.],\n      shape=(1230,))time(time)datetime64[ns]2023-08-17T16:51:22 ... 2023-10-...array(['2023-08-17T16:51:22.000000000', '2023-08-29T16:51:23.000000000',\n       '2023-09-10T16:51:24.000000000', '2023-09-22T16:51:24.000000000',\n       '2023-10-04T16:51:24.000000000', '2023-10-16T16:51:24.000000000',\n       '2023-10-28T16:51:24.000000000'], dtype='datetime64[ns]')spatial_ref()int640GeoTransform :5281990.0 10.0 0.0 1570960.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)Data variables: (2)land_cover(y, x)float6412.0 12.0 12.0 ... 41.0 41.0 41.0AREA_OR_POINT :AreaDataType :ThematicRepresentationType :THEMATICSTATISTICS_COVARIANCES :136.429646247598STATISTICS_MAXIMUM :48STATISTICS_MEAN :25.753373398066STATISTICS_MINIMUM :1STATISTICS_SKIPFACTORX :1STATISTICS_SKIPFACTORY :1STATISTICS_STDDEV :11.680310194836array([[12., 12., 12., ..., 41., 41., 41.],\n       [12., 12., 12., ..., 41., 41., 41.],\n       [12., 12., 12., ..., 41., 41., 41.],\n       ...,\n       [ 2.,  2.,  2., ..., 41., 41., 41.],\n       [ 2.,  2.,  2., ..., 41., 41., 41.],\n       [ 2.,  2.,  2., ..., 41., 41., 41.]], shape=(1221, 1230))sig0(time, y, x)float64-8.5 -10.65 ... -14.32 -14.22array([[[ -8.5 , -10.65, -12.07, ..., -22.27, -20.91, -21.92],\n        [ -9.  , -10.03, -10.82, ..., -16.46, -16.9 , -21.84],\n        [ -6.74,  -7.87,  -8.1 , ..., -17.41, -22.64, -23.01],\n        ...,\n        [ -8.74,  -7.44,  -6.69, ..., -10.85,  -8.39,  -7.08],\n        [ -9.39,  -9.55,  -8.9 , ..., -13.  , -11.03,  -9.15],\n        [-10.86, -10.84,  -9.7 , ..., -17.47, -14.58, -10.65]],\n\n       [[-10.39, -11.92, -11.74, ..., -19.02, -20.28, -17.92],\n        [ -8.65, -14.64, -12.34, ..., -21.77, -19.55, -16.67],\n        [ -8.11, -11.29, -10.25, ..., -23.16, -20.23, -16.73],\n        ...,\n        [-10.69,  -7.85,  -6.51, ..., -11.02,  -8.21,  -7.69],\n        [-12.83, -10.4 ,  -9.26, ..., -14.74,  -9.62,  -7.99],\n        [-13.76, -12.13, -12.08, ..., -18.51, -12.62,  -9.14]],\n\n       [[ -9.47, -14.49, -15.86, ..., -23.19, -24.68, -25.28],\n        [ -9.7 , -13.62, -12.49, ..., -27.02, -23.13, -22.35],\n        [-10.84, -12.3 , -12.61, ..., -23.46, -22.93, -21.64],\n        ...,\n...\n        [ -9.82,  -9.11,  -8.73, ...,  -9.79,  -7.33,  -6.92],\n        [-12.23, -11.64,  -9.59, ..., -12.29,  -7.65,  -8.14],\n        [-13.6 , -13.41, -11.73, ..., -19.82, -12.53, -11.83]],\n\n       [[-12.49, -12.55, -12.89, ..., -21.35, -23.29, -23.87],\n        [-12.15, -12.38, -14.03, ..., -18.07, -23.53, -23.23],\n        [-12.41, -12.52, -14.08, ..., -18.7 , -21.47, -22.17],\n        ...,\n        [ -6.87,  -5.98,  -5.32, ..., -18.47, -12.26, -11.2 ],\n        [-11.18,  -6.31,  -6.12, ..., -20.17, -12.56, -11.61],\n        [-11.98,  -9.02,  -8.46, ..., -13.06, -10.4 ,  -9.  ]],\n\n       [[ -6.41,  -6.59,  -7.16, ..., -22.25, -25.96, -25.45],\n        [ -6.75,  -9.42,  -9.54, ..., -20.65, -26.34, -23.53],\n        [ -8.24, -12.04, -10.46, ..., -20.65, -20.63, -21.05],\n        ...,\n        [ -6.64,  -5.06,  -4.89, ..., -13.67, -12.26,  -9.96],\n        [ -9.62,  -8.06, -10.02, ..., -16.11, -14.74, -10.64],\n        [-11.93, -11.41, -12.68, ..., -19.01, -14.32, -14.22]]],\n      shape=(7, 1221, 1230))\n\n\nWe also create the same dashboard for backscatter of different landcover types over time. In order to make this code reusable and adaptable we will define the following function plot_variability, which allows the injection of a spatial and/or temporal filter. It is not important to understand all the code of the following cell!\n\n# Load encoding and validate with Pydantic\nwith cat.corine_cmap.read()[0] as f:\n    corine_colors = CorineColorCollection.model_validate(json.load(f))\n\n# Get mapping\ncolor_mapping = {item[\"value\"]: item for item in corine_colors.items}\n\n# Get landcover codes present in the image\npresent_landcover_codes = np.unique(\n    fused_ds.land_cover.where(~np.isnan(fused_ds.land_cover)).astype(int),\n)\n\nNow, lets work on the real-life dataset to see how speckle actually looks like.\n\nplot_variability_over_time(\n    var_ds=fused_ds,\n    color_mapping=corine_colors.to_dict(),\n    present_landcover_codes=present_landcover_codes,\n)\n\n\n\n\n\n  \n\n\n\n\nFigure 2: Lake Neusiedl \\(\\sigma^0_E\\) without any filter.\nThe speckle noise typically appears as a “salt-and-pepper” pattern. Also, please note the distribution of backscatter for each land cover. Even though speckle is known for following non-normal distributions (i.e., Rayleigh distribution for amplitude in the linear domain, and the Gumple for intensity in the log domain), we can assume that due to the Central Limit Theorem, the overall backscatter means (dB) tend to follow a Gaussian distribution.\nWe can mitigate speckle (it is impossible to remove it completely) by following approaches such as: - spatial filtering - taking mean backscatter value over the same land cover, or - temporal filtering - taking the average backscatter value over some time period.\nEither way, one pixel is never representative of ground truth! Therefore we need to look at samples and distributions.",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "unit_03/07_in_class_exercise.html#spatial-filtering",
    "href": "unit_03/07_in_class_exercise.html#spatial-filtering",
    "title": "7  Speckle Statistics",
    "section": "7.2 Spatial filtering",
    "text": "7.2 Spatial filtering\nWe first introduce a common spatial filter. The Lee filter is an adaptive speckle filter. The filter works using a kernel window with a configurable size, which refers to the dimensions of the neighborhood over which the filter operates. The kernel slides across the data, applying the smoothing operation at each pixel position of the image. It follows three assumptions:\n\nSAR speckle is modeled as a multiplicative noise - the brighter the area the noisier the data.\nThe noise and the signal are statistically independent of each other.\nThe sample mean and sample variance of a pixel is equal to its local mean and local variance.\n\nThis approach comes with some limitations: it reduces the spatial resolution of the SAR image.\nLet’s build up a function for applying a Lee filter with a kernel window size of 7 (do not forget to switch back to linear units before doing this computation and to dB after it):\n\ndef lee_filter(raster: npt.NDArray, size: int = 7) -&gt; npt.NDArray:\n    \"\"\"Apply the lee-filter to an Image array.\n\n    Parameters\n    ----------\n    raster: ndarray\n        2D array representing the noisy image (e.g., radar image with speckle)\n    size: int\n        Size of the kernel window for the filter (must be odd, default is 7)\n\n    Returns\n    -------\n    filtered_image (ndarray): The filtered image with reduced speckle noise\n\n    \"\"\"\n    raster = np.nan_to_num(raster)\n    linear = 10 ** (raster / 10)\n\n    # Mean and variance over local kernel window\n    mean_window = uniform_filter(linear, size=size)\n    mean_sq_window = uniform_filter(linear**2, size=size)\n    variance_window = mean_sq_window - mean_window**2\n\n    # Noise variance estimation (this could also be set manually)\n    overall_variance = np.var(linear)\n\n    # Compute the Lee filter\n    weights = variance_window / (variance_window + overall_variance)\n\n    return 10 * np.log10(mean_window + weights * (linear - mean_window))\n\n\nplot_variability(\n    var_ds=fused_ds,\n    color_mapping=color_mapping,\n    present_landcover_codes=present_landcover_codes,\n    filter_spatial=lee_filter,\n)\n\n\n\n\n\n  \n\n\n\n\nFigure 3: Lake Neusiedl \\(\\sigma^0_E\\) with a Lee filter applied.",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "unit_03/07_in_class_exercise.html#temporal-filtering",
    "href": "unit_03/07_in_class_exercise.html#temporal-filtering",
    "title": "7  Speckle Statistics",
    "section": "7.3 Temporal filtering",
    "text": "7.3 Temporal filtering\nTemporal filtering would involve taking the average of all previous (past) observations for each pixel. This approach comes with some limitations: it takes out the content-rich information tied to the temporal variability of backscatter.\n\ndef temporal_filter(raster: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Apply a temporal mean filter.\n\n    Parameters\n    ----------\n    raster: ndarray\n        3D array representing the noisy image over time\n        (e.g., radar image with speckle)\n\n    Returns\n    -------\n    filtered_image (ndarray): The filtered image with reduced speckle noise\n\n    \"\"\"\n    return raster.mean(\"time\")\n\n\nplot_variability(\n    var_ds=fused_ds,\n    color_mapping=color_mapping,\n    present_landcover_codes=present_landcover_codes,\n    filter_temporal=temporal_filter,\n)\n\n\n\n\n\n  \n\n\n\n\nFigure 4: Lake Neusiedl \\(\\sigma^0_E\\) with a temporal filter applied.\nLet´s observe the histograms of the two plots. Especially in the region around the lake, it is clear that the distribution is now less dispersed and more centered around a central value.",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "unit_03/08_in_class_exercise.html",
    "href": "unit_03/08_in_class_exercise.html",
    "title": "8  Interferograms",
    "section": "",
    "text": "8.1 Single Look Complex (SLC) Data\nOn July 5th, 2019, an earthquake with a magnitude of 7.1 mainshock struck eastern California, near the city of Ridgecrest. The seismic event produced a surface rupture spanning more than 50 kilometers with a complex vertical and horizontal offset pattern along the main fault line. SAR imagery can be employed for accurately measuring and describing ground motion through a well-established technique called SAR Interferometry. In this framework, the phase information contained in Synthetic Aperture Radar (SAR) data is employed. In this notebook, we will dive into the main interferometric SAR processing operations which involves retrieving the difference between the phase signals of repeated SAR acquisitions to analyze the shape and deformation of the Earth’s surface. In our case, we will use a pair of Single Look Complex (SLC) Sentinel-1 images to obtain an interferogram of the Ridgecrest earthquake.\nThis notebook will outline the process of working with interferograms and the steps needed to extract valuable information. Here, we will focus on displaying products generated by the Sentinel Application Platform (SNAP) software from the European Space Agency (ESA).\nPhoto by Brian Olson / California Geological Survey\nWe introduce now another level-1 radar product type, which is called Single Look Complex (SLC). Interferometry can only be performed with SLC data. What are the main differences between SLC and GRD (the other level-1 radar product)? + SLC vs GRD: + SLC contains complex-value data (amplitude and phase) vs GRD contains intensity only (amplitude) + SLC geometry is Slant Range (radar’s line of sight) vs GRD data are projected onto ground range + SLC resolution is full vs GRD has lower resolution (it is multi-looked) + SLC supports phase-based applications (Interferometry) vs GRD supports only amplitude-based ones + SLC has larger file sizes compared to GRD\nurl = get_intake_url()\ncat = intake.open_catalog(url)\niw1_ds = cat.iw1.read()\niw2_ds = cat.iw2.read()\niw3_ds = cat.iw3.read()\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\nLet’s plot all three sub-swaths to view the full scene acquired by the satellite. The acquisition times for each swath on July 10th, 2019 are the following: - IW1 at 01:50:01 - 01:50:26 - IW2 at 01:49:59 - 01:50:24 - IW3 at 01:50:00 - 01:50:25\ndatasets = [iw1_ds, iw2_ds, iw3_ds]\n\nplot_slc_all(datasets)\nWe don’t need all three of the subswaths for our notebook, so we will focus on IW2 and display its intensity and phase measurements.\nplot_slc_iw2(iw2_ds)\nIntensity is represented in an 8-bit format (ranging from 0 to 255), while phase measurements range from \\(- \\pi\\) to \\(\\pi\\) . At first glance, phase does not correspond to easily observable physical properties of the ground. However, the phase becomes incredibly valuable when, for example, it is used comparatively between two successive phase measurements (two Sentinel-1 images acquired at different times over the same area). Here are the processing steps needed to retrieve a difference between the phases of two radar acquisitions:",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "unit_03/08_in_class_exercise.html#coregistering",
    "href": "unit_03/08_in_class_exercise.html#coregistering",
    "title": "8  Interferograms",
    "section": "8.2 Coregistering",
    "text": "8.2 Coregistering\nBefore creating an interferogram, measurements from two different dates need to be coregistered. This means that each pixel from the two acquisitions must be precisely aligned so that they are representing the same ground object. Accurate and successful co-registration of the two (or more) images is vital for interferometry processing. We call the “master” image the reference image (typically the earliest acquisition in time) to which we coregister the “slave” image (typically acquired later in time).\n\ncoregistered_ds = cat.coreg.read()\n\nplot_coregistering(coregistered_ds)",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "unit_03/08_in_class_exercise.html#interferogram-formation-and-coherence-estimation",
    "href": "unit_03/08_in_class_exercise.html#interferogram-formation-and-coherence-estimation",
    "title": "8  Interferograms",
    "section": "8.3 Interferogram Formation and Coherence Estimation",
    "text": "8.3 Interferogram Formation and Coherence Estimation\nThe interferogram formation process combines the amplitudes of both images and calculates the difference between their respective phases at each SAR image pixel (cross-multiplication of the master image with the complex conjugate of the slave image).\nAfter building up the interferogram, we have to take into account the presence of other contributing terms that could hinder our goal of measuring the surface deformation due to the earthquake. For example, we need to subtract from the interferogram the flat-earth phase contribution, which is a signal contribution due to the curvature of the Earth’s surface. This is here done automatically through the SNAP software operators.\nIn general, the accuracy of interferometric measurements are influenced by many contributors that could result in a loss of coherence. But what is coherence? It is a measure of phase correlation between the master and slave image. Interferometric coherence (γ) can be expressed as:\n\\[γ = γ_{proc}*γ_{geom}*γ_{vol}*γ_{SNR}*γ_{temp}\\]\nwhere \\(γ_{proc}\\) refers to inaccuracies in the processing (e.g., coregistration errors), \\(γ_{geom}\\) refers to the baseline decorrelation (different position of satellites during the two acquisitions), \\(γ_{vol}\\) refers to volume decorrelation (vegetation related), \\(γ_{SNR}\\) refers to the radar instrument thermal noise and \\(γ_{temp}\\) refers to the decorrelation caused by change of position of the objects in the scene during the time interval of the images acquisitions (e.g., plant growth, wind-induced movements or ground deformation due to earthquakes, landslides).\nTherefore, we can conclude that interferometric accuracy is sensitive to many processes, hence isolating the ground deformation signal involves several operations. On the other hand, interferometric coherence sensitivity could be exploited to track and map phenomena that cause its degradation (e.g., vegetation features, and water content).\n\ninterferogram_ds = cat.inter.read()\n\nplot_interferogram(interferogram_ds)\n\n\n\n\n\n  \n\n\n\n\nNow we can observe patterns that emerged between the two acquisitions. If you look at the data range in the interferogram (left plot), you’ll notice it spans approximately one wavelength, from \\(-\\pi\\) to \\(\\pi\\). On the right, you find a plot of the interferometric coherence (values ranging between 0 and 1), where low coherence is found along the ground surface ruptures caused by the earthquake. Please note, that the interferogram has already undergone a deburst operation (all bursts merged into a single image).",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "unit_03/08_in_class_exercise.html#topographic-phase-removal",
    "href": "unit_03/08_in_class_exercise.html#topographic-phase-removal",
    "title": "8  Interferograms",
    "section": "8.4 Topographic Phase Removal",
    "text": "8.4 Topographic Phase Removal\nSince the local topography is an additional phase term constituting the interferogram that we built up so far, we need to make an estimate of its impact in order to further remove it to keep only the ground deformation-related phase. For this purpose, we use a reference known DEM to simulate an interferogram and to subtract it from the original interferogram.\n\ntopo_ds = cat.topo.read()\n\nplot_topographic_phase_removal(interferogram_ds, topo_ds)",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "unit_03/08_in_class_exercise.html#multi-looking-goldstein-phase-filtering-and-geocoding",
    "href": "unit_03/08_in_class_exercise.html#multi-looking-goldstein-phase-filtering-and-geocoding",
    "title": "8  Interferograms",
    "section": "8.5 Multi-looking, Goldstein Phase Filtering and Geocoding",
    "text": "8.5 Multi-looking, Goldstein Phase Filtering and Geocoding\nIn order to improve the phase signatures contained within our interferogram and get a generally higher signal-to-noise (SNR) ratio, we will perform two additional operations called multi-looking and Goldstein phase filtering. Multi-looking is the process of averaging adjacent pixels using a moving window of the interferogram to reduce noise (at the cost of reducing the spatial resolution). Coherence is involved in this operation to flag and set areas to no data that are considered unreliable (low coherence) and to keep the reliable ones (high coherence).\nFinally, to make data interpretable, we geocode the wrapped interferogram. So far we performed the interferometric processing in the radar geometry. The transformation into geographic coordinates will help us to perform further comparisons in a real-world coordinate system.\n\ngeocoded_ds = cat.geocode.read()\n\nstep = 4  # if you want to zoom in, suggestion is to make this step smaller\n\nplot_igf_coh(geocoded_ds, step)\n\n\n\n\n\n  \n\n\n\n\nIn the above plot, we can compare georeferenced data in the form of the interferogram (left) and the coherence (right). Along the earthquake fault line, low coherence between the two phase acquisitions is visible. This occurs due to extreme changes in terrain heights or displacements, which are beyond the sensitivity of the SAR sensor. This area of low coherence indicates higher uncertainty in the interferogram. However, this isn’t necessarily a drawback, as it helps to clearly identify the earthquake epicenter.\nYou can also explore and zoom into regions with “fringe patterns” to observe ground movement. Each fringe cycle (e.g., from red to red or blue to blue) corresponds to ground motion in this case. The fringe patterns indicate motion in the line-of-sight (LOS) of the satellite (Sentinel-1 has a mean incidence angle of 38°) in terms of either uplift (relative motion of the ground towards the satellite) or sinking (relative motion of the ground away from the satellite). If the interferogram phase changes from 0 to -3.14 (cycles in the negative direction), the surface is moving away from the satellite (i.e., sinking movement). Vice versa, if cycles go in the positive direction (from 0 to +3.14), it would mean a relative uplifting movement of the ground.\nN.B.: - When making your interpretations about the visualised deformations, start analyzing from a stable outer area toward the center of deformation, and interpret whether the phase (or color sequence) indicates motion toward or away from the satellite. - Considering the orbit geometry is fundamental. Interpret LOS displacement relative to the satellite look direction, not just the color pattern. - In areas with no ground motion, fringe patterns disappear. - The radar’s sensitivity to motion depends on its wavelength. For Sentinel-1 (~5.6cm), a full fringe cycle (\\(2\\pi\\)) represents a displacement of ~2.8 cm in the LOS direction.",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "unit_03/08_in_class_exercise.html#visualisation-of-the-earthquake-event-on-july-5th-2019",
    "href": "unit_03/08_in_class_exercise.html#visualisation-of-the-earthquake-event-on-july-5th-2019",
    "title": "8  Interferograms",
    "section": "8.6 Visualisation of the Earthquake Event on July 5th, 2019",
    "text": "8.6 Visualisation of the Earthquake Event on July 5th, 2019\n\nstep = 4  # Downsample data for visualization\n\nplot_earthquake(geocoded_ds, step)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "unit_03/09_in_class_exercise.html",
    "href": "unit_03/09_in_class_exercise.html",
    "title": "9  Phase Unwrapping",
    "section": "",
    "text": "9.1 Loading Data\nThe goal of this notebook is to read an interferogram image (i.e., 2-D array of phase values) and unwrap it. Phase unwrapping is a critical process in interferometry, which involves recovering unambiguous phase data from the interferogram.\nA SAR interferogram represents the phase difference between two radar acquisitions (i.e., two SLC images). The phase difference is usually wrapped within a range of 0 to 2π, because the phase is inherently cyclical. When the true phase difference exceeds 2π, it gets “wrapped” into this range, creating a discontinuous phase signal. Phase unwrapping refers to the process of reconstructing the continuous phase field from the wrapped phase data.\nUnwrapping an interferogram is essential for extracting correct information contained in the phase such as surface topography and earth surface deformations.\nThere are many approaches that tried to solve the unwrapping problem, tackling challenging scenarios involving noise or large phase discontinuities. Here we present the Network-flow Algorithm for phase unwrapping (C. W. Chen and H. A. Zebker, 2000), which is implemented in the snaphu package.\nThe data is stored on the Jupyterhub server, so we need to load it using their respective paths. In this notebook we will use the resulting wrapped interferogram from notebook “Interferograms”, but we need to process it in the radar geometry in order to unwrap it (while in notebook “Interferograms” we end the whole process by performing the geocoding, just for better visualization purposes).\nfrom typing import Any\n\nimport cmcrameri as cmc  # noqa: F401\nimport intake\nimport numpy as np\nimport seaborn as sns\nimport snaphu  # noqa: F401\nimport xarray as xr\n\nfrom mrs.catalog import get_intake_url\nfrom mrs.plot import (\n    plot_coarsened_image,\n    plot_compare_coherence_mask_presence,\n    plot_compare_wrapped_unwrapped_completewrapped,\n    plot_different_coherence_thresholds,\n    plot_displacement_map,\n    plot_interferogram_map,\n    plot_summary,\n)\nfrom mrs.processing import subsetting, unwrap_array\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\nurl = get_intake_url()\ncatalog = intake.open_catalog(url)\nds: xr.Dataset = catalog.complex_handout.read().compute()\nds[\"cmplx\"] = ds[\"real\"] + ds[\"imag\"] * 1j\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\n\n# Set cyclic and linear colormaps\ncmap_cyc = sns.color_palette(\"hls\", as_cmap=True)\ncmap_lin = \"cmc.roma_r\"\ncmap_disp = \"cmc.vik\"\n\n# Create a mask for the areas which have no data\nmask = ds.phase.where(ds.phase == 0, other=True, drop=False).astype(bool)\n\nLet’s start by displaying the interferogram that needs to be unwrapped. Recall that due to the Slant Range geometry and the satellite acquisition pass (ascending, in our case), the image appears north/south flipped (with respect to the geocoded image)!\n\n# Plot Phase Interferogram Image\nplot_interferogram_map(ds=ds, mask=mask, cmap_cyc=cmap_cyc)",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Phase Unwrapping</span>"
    ]
  },
  {
    "objectID": "unit_03/09_in_class_exercise.html#phase-unwrapping",
    "href": "unit_03/09_in_class_exercise.html#phase-unwrapping",
    "title": "9  Phase Unwrapping",
    "section": "9.2 Phase Unwrapping",
    "text": "9.2 Phase Unwrapping\nAs we will be doing the unwrapping multiple times in this notebook let’s create a function that does the unwrapping for us on xarray DataArray objects. The actual core function where the unwrapping is happening is snaphu.unwrap_phase from the snaphu package. This function needs a 2D numpy array as input, where each pixel value is a complex number. Therefore, we have to convert the xarray DataArray to a 2D numpy array with complex values. We do that by combining the phase and intensity bands to a complex array. The actual unwrapping is essentially an addition of the phase values, such that the values are continuous and not between \\(-\\pi\\) and \\(\\pi\\).\n\nFigure 1: Illustration of how the unwrapping of the phase works. (Source: ESA).\n\n9.2.1 Unwrapping on a Subset\nAs the original image is too large to unwrap in a reasonable time, we will unwrap a subset of the image. In this case, we will unwrap an area of 500x500 pixels.\n\n# Select a subset of the data\ndx, dy = 500, 500\nx0, y0 = 2800, 1700\n\n\n# Subsetting the data arrays\nsubset: xr.Dataset = subsetting(ds.where(mask), x0, y0, dx, dy)\n\n# Unwrap the subset\nsubset = unwrap_array(subset, complex_var=\"cmplx\", ouput_var=\"unwrapped\")\n\nNow let’s compare the wrapped and unwrapped phase images.\n\nplot_compare_wrapped_unwrapped_completewrapped(\n    subset=subset,\n    cmap_cyc=cmap_cyc,\n    ds=ds,\n    mask=mask,\n    p0=(x0, y0),\n    dxy=(dx, dy),\n)\n\n\n\n\n\n\n\n\n\n\n9.2.2 Unwrapping with coherence mask\nAdditionally, can we try to calculate the unwrapped image by excluding pixels which the coherence values are lower than a certain threshold. This is done by masking the coherence image with the threshold value and then unwrapping the phase image with the masked coherence image.\n\nthreshold1 = 0.3\n\nsubset_unwrapped_coherence = unwrap_array(\n    subset,\n    coherence=subset.coh,\n    coh_low_threshold=threshold1,\n    complex_var=\"cmplx\",\n    ouput_var=\"unwrapped_coh\",\n)\n\nLet’s compare the unwrapped image with and without the coherence mask.\n\nplot_compare_coherence_mask_presence(\n    subset=subset_unwrapped_coherence,\n    cmap_cyc=cmap_cyc,\n    threshold=threshold1,\n)\n\n\n\n\n\n\n\n\nLet’s see if another threshold value for the coherence mask gives better results.\n\nthreshold2 = 0.5\nsubset_unwrapped_coherence_threshold2 = unwrap_array(\n    subset,\n    coherence=subset.coh,\n    coh_low_threshold=threshold2,\n    complex_var=\"cmplx\",\n    ouput_var=\"unwrapped_coh\",\n)\n\n\nplot_different_coherence_thresholds(\n    ds_coh=subset_unwrapped_coherence,\n    ds_coh_2=subset_unwrapped_coherence_threshold2,\n    cmap_cyc=cmap_cyc,\n)\n\n\n\n\n\n\n\n\nA higher coherence threshold means that only pixels with a coherence value greater than 0.5 will be used for phase unwrapping. This would result in an unwrapping process that is likely more stable, with reduced noise (invalid phase information in the proximity of the earthquake faults is discarded). However, an excessive coherence threshold might have significant gaps or missing information, especially in areas where motion or surface changes have occurred. The choice of a coherence threshold depends on the balance you want to strike between the accuracy and coverage of the output unwrapped image.\nKeep in mind that in case of large displacements, such as the Ridgecrest earthquake, phase unwrapping can be problematic and lead to poor results: when the displacement is large, the phase difference becomes wrapped multiple times, leading to phase aliasing. In this case, the phase values become ambiguous, we cannot distinguish between multiple phase wraps, thus leading to incorrect results.",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Phase Unwrapping</span>"
    ]
  },
  {
    "objectID": "unit_03/09_in_class_exercise.html#applying-an-equation-for-the-displacement-map",
    "href": "unit_03/09_in_class_exercise.html#applying-an-equation-for-the-displacement-map",
    "title": "9  Phase Unwrapping",
    "section": "9.3 Applying an Equation for the Displacement Map",
    "text": "9.3 Applying an Equation for the Displacement Map\nFrom the unwrapped phase image (we will use the phase masked with a coherence threshold of 0.3) we can calculate the displacement map using the following equation:\n$ d = - _d $\nwhere: - \\(\\lambda = 0.056\\) for Sentinel-1 - \\(\\Delta \\phi_d\\) is the unwrapped image\nThis operation can be very useful for monitoring ground deformation.\n\ndef displacement(unw: xr.DataArray, lambda_val: float = 0.056) -&gt; xr.DataArray:\n    \"\"\"Compute the displacement given the unwrapped phase.\"\"\"\n    return unw * -lambda_val / (4 * np.pi)\n\n\n# Calculate the displacement\ndisp_subset = displacement(subset.unwrapped_coh)\n\n\n# Plot the displacement map\nplot_displacement_map(\n    subset=disp_subset,\n    cmap_disp=cmap_disp,\n    title=\"Displacement Map of the Subset\",\n)",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Phase Unwrapping</span>"
    ]
  },
  {
    "objectID": "unit_03/09_in_class_exercise.html#coarsen-approach",
    "href": "unit_03/09_in_class_exercise.html#coarsen-approach",
    "title": "9  Phase Unwrapping",
    "section": "9.4 Coarsen Approach",
    "text": "9.4 Coarsen Approach\nAs the whole data is too large and the processing time already exceeds 20 minutes when using an image with 4000x4000 pixels, we can coarsen the image so that we can unwrap and compute the displacement for the whole scene.\n\nkernel_size = 3\n\nlowres = ds.coarsen(x=kernel_size, y=kernel_size, boundary=\"trim\").median()\n\n\nextra_kwargs: dict[str, Any] = {\"tile_overlap\": 10, \"ntiles\": (20, 30)}\nlowres = unwrap_array(\n    data=lowres,\n    coherence=lowres.coh,\n    coh_low_threshold=0.3,\n    **extra_kwargs,\n)\n\nWe can now plot the unwrapped image of the low resolution image.\n\n# Plot the unwrapped phase\nplot_coarsened_image(lowres=lowres, cmap_cyc=cmap_cyc)\n\n\n\n\n\n\n\n\nWe can also now calculate the displacement map and compare them.\n\nlowres_disp = displacement(lowres.unwrapped)\n\n# Plot the displacement map\nplot_displacement_map(\n    subset=lowres_disp,\n    cmap_disp=cmap_disp,\n    title=\"Displacement Map entire scene (coarse resolution)\",\n)\n\n\n\n\n\n\n\n\nHere is a summary of the previous plots: N.B.: The visualised deformation pattern is correct relative to radar geometry, but it will look “flipped” or “on the wrong side” when compared to a geocoded (map-aligned) image.\n\n# Plot summary of previous plots\nplot_summary(\n    subset=subset,\n    subset_disp=disp_subset,\n    lowres=lowres,\n    lowres_disp=lowres_disp,\n    cmap_cyc=cmap_cyc,\n    cmap_disp=cmap_disp,\n)\n\n\n\n\n\n\n\n\nIn the following animation, we can capture the 3D displacement caused by the Ridgecrest quake by observing the after and before elevation model.\n Credits: NASA",
    "crumbs": [
      "Unit 3",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Phase Unwrapping</span>"
    ]
  },
  {
    "objectID": "unit_01/01_homework_exercise.html",
    "href": "unit_01/01_homework_exercise.html",
    "title": "Appendix A — Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog",
    "section": "",
    "text": "A.1 List all collection names and select one\nIn the previous notebook, you have learnt how to access Sentinel-1 data from EODC using the STAC API. Your task now is to find and plot a Sentinel-1 acquisition of your latest holiday destination. To successfully finish the exercise, you need to perform the following tasks:\nTo help you to get started, we already imported all required packages and provided some code blocks. Your task is now to fill in the missing code cells indicated with # YOUR CODE HERE.\neodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n\ncolllection_id = ...  # YOUR CODE HERE\n\ncollection = eodc_catalog.get_collection(colllection_id)\ncollection",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog</span>"
    ]
  },
  {
    "objectID": "unit_01/01_homework_exercise.html#define-spatial-and-temporal-extent-and-use-client-to-load-the-metadata",
    "href": "unit_01/01_homework_exercise.html#define-spatial-and-temporal-extent-and-use-client-to-load-the-metadata",
    "title": "Appendix A — Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog",
    "section": "A.2 Define spatial and temporal extent and use client to load the metadata",
    "text": "A.2 Define spatial and temporal extent and use client to load the metadata\n\n# Define the area of interest by providing coordinates that cover your latest\n# holiday destination (can be a city, state, country, etc.)\nlatmin, latmax = ...  # YOUR CODE HERE\nlonmin, lonmax = ...  # YOUR CODE HERE\nbounds = (lonmin, latmin, lonmax, latmax)\n\n# Define the time range. This can either be the data of your actual holiday or\n# any other time range between 2016 and 2023\ntime_range = ...  # YOUR CODE HERE\n\nitems = ...  # YOUR CODE HERE\n\nprint(len(items), \"scenes found.\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog</span>"
    ]
  },
  {
    "objectID": "unit_01/01_homework_exercise.html#find-necessary-metadata-like-bands-resolution-coordinate-reference-system",
    "href": "unit_01/01_homework_exercise.html#find-necessary-metadata-like-bands-resolution-coordinate-reference-system",
    "title": "Appendix A — Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog",
    "section": "A.3 Find necessary metadata, like bands, resolution, coordinate reference system",
    "text": "A.3 Find necessary metadata, like bands, resolution, coordinate reference system\n\n# Pick one item from items using indexing get the relative orbit from the item\n# properties\nrelative_orbit = ...  # YOUR CODE HERE\nprint(f\"The relative orbit number of the item is {relative_orbit}\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog</span>"
    ]
  },
  {
    "objectID": "unit_01/01_homework_exercise.html#lazily-load-the-data-into-an-xarray",
    "href": "unit_01/01_homework_exercise.html#lazily-load-the-data-into-an-xarray",
    "title": "Appendix A — Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog",
    "section": "A.4 Lazily load the data into an Xarray",
    "text": "A.4 Lazily load the data into an Xarray\nTake care that your dataset is not to big by limiting the bounds and time range!\n\nbands = ...  # YOUR CODE HERE\nchunks = {\"time\": 1, \"x\": 1000, \"y\": 1000}\n\nsig0_dc = odc_stac.load(\n    items,\n    bands=bands,\n    bbox=bounds,\n    chunks=chunks,\n)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog</span>"
    ]
  },
  {
    "objectID": "unit_01/01_homework_exercise.html#define-the-nodata-value-and-scale-factor-and-decode-the-data",
    "href": "unit_01/01_homework_exercise.html#define-the-nodata-value-and-scale-factor-and-decode-the-data",
    "title": "Appendix A — Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog",
    "section": "A.5 Define the nodata value and scale factor and decode the data",
    "text": "A.5 Define the nodata value and scale factor and decode the data\n\nnodata = ...  # YOUR CODE HERE\nscale = ...  # YOUR CODE HERE\n\nsig0_dc = ...  # YOUR CODE HERE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog</span>"
    ]
  },
  {
    "objectID": "unit_01/01_homework_exercise.html#plot-the-loaded-data",
    "href": "unit_01/01_homework_exercise.html#plot-the-loaded-data",
    "title": "Appendix A — Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog",
    "section": "A.6 Plot the loaded data",
    "text": "A.6 Plot the loaded data\n\n...  # YOUR CODE HERE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Homework Exercise 1: Discover Sentinel 1 data using the EODC STAC catalog</span>"
    ]
  },
  {
    "objectID": "unit_01/02_homework_exercise.html",
    "href": "unit_01/02_homework_exercise.html",
    "title": "Appendix B — Homework Exercise 2: Unit conversion",
    "section": "",
    "text": "B.1 Load the data\nYour task in this notebook is to load some data from EODC and create weekly mosaics across the whole year (the area can be relatively small), plot one of the weekly mosaics, and save it to a file. To successfully finish the exercise, you need to perform the following tasks:\nAs a reminder, backscatter data is typically provided in ‘dB’, so make sure to perform the mean calculation for the weekly mosaics in the correct domain.\nimport pystac_client\nimport odc.stac\nfrom rasterio.crs import CRS\nimport rioxarray  # noqa\n# Search for some data\ncrs = CRS.from_epsg(27704)  # WGS 84\n\n# Set Spatial extent\nlatmin, latmax = (\n    ...,\n    ...,\n)\n# YOUR CODE HERE, you can choose any location that you like e.g. a city in\n# Austria\nlonmin, lonmax = ..., ...  # YOUR CODE HERE\nbounds = (lonmin, latmin, lonmax, latmax)\n\n# Set Temporal extent\ntime_range = ...  # YOUR CODE HERE\n\n# Search for Sentinel-1 data\nitems = (\n    pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n    .search(\n        bbox=bounds,\n        collections=[\"SENTINEL1_SIG0_20M\"],\n        datetime=time_range,\n        limit=100,\n    )\n    .item_collection()\n)\n\nprint(len(items), \"scenes found\")\n# Load the data and lazily combine items\nsig0_dc = odc.stac.stac_load(\n    items,\n    bbox=bounds,\n    bands=[\"VV\"],\n    chunks={\"time\": 1, \"x\": 1000, \"y\": 1000},\n)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Homework Exercise 2: Unit conversion</span>"
    ]
  },
  {
    "objectID": "unit_01/02_homework_exercise.html#preprocess-the-data",
    "href": "unit_01/02_homework_exercise.html#preprocess-the-data",
    "title": "Appendix B — Homework Exercise 2: Unit conversion",
    "section": "B.2 Preprocess the Data",
    "text": "B.2 Preprocess the Data\n\n# Define the nodata value and scale factor\nnodata = -9999  # Sentinel-1 nodata value as defined by EODC\nscale = 10  # Sentinel-1 scale factor as defined by EODC\n\n# Preprocess the data\nsig0 = ...  # YOUR CODE HERE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Homework Exercise 2: Unit conversion</span>"
    ]
  },
  {
    "objectID": "unit_01/02_homework_exercise.html#create-weekly-mosaics",
    "href": "unit_01/02_homework_exercise.html#create-weekly-mosaics",
    "title": "Appendix B — Homework Exercise 2: Unit conversion",
    "section": "B.3 Create Weekly Mosaics",
    "text": "B.3 Create Weekly Mosaics\n\nsig0_weekly = ...  # YOUR CODE HERE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Homework Exercise 2: Unit conversion</span>"
    ]
  },
  {
    "objectID": "unit_01/02_homework_exercise.html#plot-one-of-the-weekly-mosaics",
    "href": "unit_01/02_homework_exercise.html#plot-one-of-the-weekly-mosaics",
    "title": "Appendix B — Homework Exercise 2: Unit conversion",
    "section": "B.4 Plot one of the Weekly Mosaics",
    "text": "B.4 Plot one of the Weekly Mosaics\n\n# YOUR CODE HERE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Homework Exercise 2: Unit conversion</span>"
    ]
  },
  {
    "objectID": "unit_01/02_homework_exercise.html#save-one-of-the-weekly-mosaics-as-tif",
    "href": "unit_01/02_homework_exercise.html#save-one-of-the-weekly-mosaics-as-tif",
    "title": "Appendix B — Homework Exercise 2: Unit conversion",
    "section": "B.5 Save one of the Weekly Mosaics as Tif",
    "text": "B.5 Save one of the Weekly Mosaics as Tif\n\n# YOUR CODE HERE",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Homework Exercise 2: Unit conversion</span>"
    ]
  },
  {
    "objectID": "unit_01/03_homework_exercise.html",
    "href": "unit_01/03_homework_exercise.html",
    "title": "Appendix C — Homework Exercise 3: Backscattering Coefficients",
    "section": "",
    "text": "C.1 Question 1\nTo successfully finish this notebook, you have to answer/solve the following three questions.\nExecute the lines below to create the plot. You now see a SAR image with unknown processing level. Based on what you see, which pre-processing steps have been applied to the image?\nSelect the answers you think are correct by editing the markdown text and putting an ‘x’ in the brackets. Note: One, several, or all answers are possible.\nex3_dc.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    robust=True,\n    data_aspect=1,\n    cmap=\"Greys_r\",\n    groupby=\"band\",\n    rasterize=True,\n).opts(frame_height=600, framewise=False, aspect=\"equal\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Homework Exercise 3: Backscattering Coefficients</span>"
    ]
  },
  {
    "objectID": "unit_01/03_homework_exercise.html#question-1",
    "href": "unit_01/03_homework_exercise.html#question-1",
    "title": "Appendix C — Homework Exercise 3: Backscattering Coefficients",
    "section": "",
    "text": "Cloud masking\nGeometric terrain correction\nConversion to dB\nRadiometric terrain correction (terrain flattening)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Homework Exercise 3: Backscattering Coefficients</span>"
    ]
  },
  {
    "objectID": "unit_01/03_homework_exercise.html#question-2",
    "href": "unit_01/03_homework_exercise.html#question-2",
    "title": "Appendix C — Homework Exercise 3: Backscattering Coefficients",
    "section": "C.2 Question 2",
    "text": "C.2 Question 2\nName all types of geometric radar image distortions in a SAR image. How are they caused, and how can we get rid of them?\nYour answer here",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Homework Exercise 3: Backscattering Coefficients</span>"
    ]
  },
  {
    "objectID": "unit_01/03_homework_exercise.html#question-3",
    "href": "unit_01/03_homework_exercise.html#question-3",
    "title": "Appendix C — Homework Exercise 3: Backscattering Coefficients",
    "section": "C.3 Question 3",
    "text": "C.3 Question 3\nUse the figure below question 1 to identify areas that are affected by foreshortening and radar shadows. Use the mouseover to retrieve their x/y coordinates. Then use these coordinates to annotate the following matplotlib figure with labels by putting them in the lines indicated with # Your coordinates here.\n\nzoom = ex3_dc.sel(x=slice(11.25, 11.5), y=slice(47.75, 47.5)).band_data\nfig, ax = plt.subplots(figsize=(10, 8))\n\nbbox = dict(boxstyle=\"round\", fc=\"0.8\")\n\nax.annotate(\n    \"foreshortening\",\n    xy=(..., ...),  # Your foreshortening coordinates here\n    xytext=(0.3, 0.25),\n    textcoords=\"subfigure fraction\",\n    bbox=bbox,\n    arrowprops=dict(facecolor=\"white\", shrink=0.05),\n)\nax.annotate(\n    \"shadows\",\n    xy=(..., ...),  # Your radar shadow coordinates here\n    xytext=(0.47, 0.8),\n    textcoords=\"subfigure fraction\",\n    bbox=bbox,\n    arrowprops=dict(facecolor=\"white\", shrink=0.05),\n)\n\nzoom.sel(band=\"unknown1\").plot(robust=True, cmap=\"Greys_r\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Homework Exercise 3: Backscattering Coefficients</span>"
    ]
  },
  {
    "objectID": "unit_02/04_homework_exercise.html",
    "href": "unit_02/04_homework_exercise.html",
    "title": "Appendix D — Homework Exercise 4: Datacubes",
    "section": "",
    "text": "D.1 Question 1\nFor the homework assignement we will continue work on the same data as in the in-class exercise. Hence we will load the same data which has been stored as a Zarr datastore. Zarr is efficient for storing chunked data and much faster for reading.\nWe want to expand the datacube of the in-class exercise with a new variable in this assignment. The new variable is the Leaf Area Index (LAI), which is a dimensionless index measuring the one-sided green leaf area over a unit of land (\\(m^2 \\cdot m^{-2}\\)).\nLoad the new LAI data with the below provided code snippet and extract the CRS and resolution of the raster. Apply what you have learned in the in-class exercise by only using the packages as listed in the imports of this notebook.\nurl = get_intake_url()\ncat = intake.open_catalog(url)\nlai_ds = cat[\"lai\"].read().compute()\nlai_ds\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 32MB\nDimensions:  (time: 35, lat: 337, lon: 337)\nCoordinates:\n  * time     (time) datetime64[ns] 280B 2022-01-20 2022-01-31 ... 2022-12-31\n  * lat      (lat) float64 3kB 46.0 46.0 45.99 45.99 ... 45.01 45.01 45.0 45.0\n  * lon      (lon) float64 3kB 10.0 10.0 10.01 10.01 ... 10.99 10.99 11.0 11.0\n    crs      int64 8B 0\nData variables:\n    LAI      (time, lat, lon) float64 32MB nan nan nan nan ... nan nan nan nanxarray.DatasetDimensions:time: 35lat: 337lon: 337Coordinates: (4)time(time)datetime64[ns]2022-01-20 ... 2022-12-31axis :Tlong_name :Timearray(['2022-01-20T00:00:00.000000000', '2022-01-31T00:00:00.000000000',\n       '2022-02-10T00:00:00.000000000', '2022-02-20T00:00:00.000000000',\n       '2022-02-28T00:00:00.000000000', '2022-03-10T00:00:00.000000000',\n       '2022-03-20T00:00:00.000000000', '2022-03-31T00:00:00.000000000',\n       '2022-04-10T00:00:00.000000000', '2022-04-20T00:00:00.000000000',\n       '2022-04-30T00:00:00.000000000', '2022-05-10T00:00:00.000000000',\n       '2022-05-20T00:00:00.000000000', '2022-05-31T00:00:00.000000000',\n       '2022-06-10T00:00:00.000000000', '2022-06-20T00:00:00.000000000',\n       '2022-06-30T00:00:00.000000000', '2022-07-10T00:00:00.000000000',\n       '2022-07-20T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-10T00:00:00.000000000', '2022-08-20T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-10T00:00:00.000000000',\n       '2022-09-20T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-10T00:00:00.000000000', '2022-10-20T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000', '2022-11-10T00:00:00.000000000',\n       '2022-11-20T00:00:00.000000000', '2022-11-30T00:00:00.000000000',\n       '2022-12-10T00:00:00.000000000', '2022-12-20T00:00:00.000000000',\n       '2022-12-31T00:00:00.000000000'], dtype='datetime64[ns]')lat(lat)float6446.0 46.0 45.99 ... 45.01 45.0 45.0DIMENSION_LABELS :lat_CoordinateAxisType :Lataxis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([46.      , 45.997024, 45.994048, ..., 45.005952, 45.002976, 45.      ],\n      shape=(337,))lon(lon)float6410.0 10.0 10.01 ... 10.99 11.0 11.0DIMENSION_LABELS :lon_CoordinateAxisType :Lonaxis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([10.      , 10.002976, 10.005952, ..., 10.994048, 10.997024, 11.      ],\n      shape=(337,))crs()int640GeoTransform :9.998511905625918 0.0029761904762040103 0.0 46.001488095245826 0.0 -0.0029761904761897995crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9108\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]geographic_crs_name :WGS 84grid_mapping_name :latitude_longitudehorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9108\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]towgs84 :[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]array(0)Data variables: (1)LAI(time, lat, lon)float64nan nan nan nan ... nan nan nan nanlong_name :Leaf Area Index 333mstandard_name :leaf_area_indexunits :m^2/m^2valid_range :[0, 210]array([[[       nan,        nan,        nan, ..., 0.73333333,\n         0.66666667, 0.73333333],\n        [       nan,        nan,        nan, ..., 0.56666667,\n         0.7       , 0.63333333],\n        [       nan,        nan,        nan, ..., 0.56666667,\n         0.6       , 0.53333333],\n        ...,\n        [0.46666667, 0.33333333, 0.3       , ..., 1.6       ,\n         1.76666666, 0.93333333],\n        [0.36666667, 0.36666667, 0.43333333, ..., 0.63333333,\n         1.13333333, 0.6       ],\n        [0.46666667, 0.36666667, 0.5       , ..., 0.4       ,\n         0.73333333, 0.53333333]],\n\n       [[       nan,        nan,        nan, ..., 0.8       ,\n         0.7       , 0.66666667],\n        [       nan,        nan,        nan, ..., 0.66666667,\n         0.66666667, 0.6       ],\n        [       nan,        nan,        nan, ..., 0.6       ,\n         0.5       , 0.56666667],\n...\n        [       nan,        nan,        nan, ...,        nan,\n                nan, 1.4       ],\n        [       nan,        nan,        nan, ..., 0.73333333,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n         0.63333333,        nan]],\n\n       [[       nan,        nan,        nan, ..., 0.56666667,\n         0.53333333, 0.56666667],\n        [       nan,        nan,        nan, ..., 0.4       ,\n         0.43333333, 0.6       ],\n        [       nan,        nan,        nan, ..., 0.4       ,\n         0.5       ,        nan],\n        ...,\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan]]], shape=(35, 337, 337))",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Homework Exercise 4: Datacubes</span>"
    ]
  },
  {
    "objectID": "unit_02/04_homework_exercise.html#question-2",
    "href": "unit_02/04_homework_exercise.html#question-2",
    "title": "Appendix D — Homework Exercise 4: Datacubes",
    "section": "D.2 Question 2",
    "text": "D.2 Question 2\nIn order to compare LAI with ALOS-2 L-band and Sentinel-1 C-band data, we will merge this variable with the SAR datacube (of the in-class exercise). Let’s first check the temporal range of the SAR datacube (fused_ds) and the new xarray dataset: lai_ds.\n\nfused_ds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 5)&gt; Size: 40B\narray(['2022-06-30T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000'], dtype='datetime64[ns]')\nCoordinates:\n  * time         (time) datetime64[ns] 40B 2022-06-30 2022-07-31 ... 2022-10-31\n    spatial_ref  int64 8B 0xarray.DataArray'time'time: 52022-06-30 2022-07-31 2022-08-31 2022-09-30 2022-10-31array(['2022-06-30T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000'], dtype='datetime64[ns]')Coordinates: (2)time(time)datetime64[ns]2022-06-30 ... 2022-10-31array(['2022-06-30T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000'], dtype='datetime64[ns]')spatial_ref()int640GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)\n\n\n\nlai_ds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 35)&gt; Size: 280B\narray(['2022-01-20T00:00:00.000000000', '2022-01-31T00:00:00.000000000',\n       '2022-02-10T00:00:00.000000000', '2022-02-20T00:00:00.000000000',\n       '2022-02-28T00:00:00.000000000', '2022-03-10T00:00:00.000000000',\n       '2022-03-20T00:00:00.000000000', '2022-03-31T00:00:00.000000000',\n       '2022-04-10T00:00:00.000000000', '2022-04-20T00:00:00.000000000',\n       '2022-04-30T00:00:00.000000000', '2022-05-10T00:00:00.000000000',\n       '2022-05-20T00:00:00.000000000', '2022-05-31T00:00:00.000000000',\n       '2022-06-10T00:00:00.000000000', '2022-06-20T00:00:00.000000000',\n       '2022-06-30T00:00:00.000000000', '2022-07-10T00:00:00.000000000',\n       '2022-07-20T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-10T00:00:00.000000000', '2022-08-20T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-10T00:00:00.000000000',\n       '2022-09-20T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-10T00:00:00.000000000', '2022-10-20T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000', '2022-11-10T00:00:00.000000000',\n       '2022-11-20T00:00:00.000000000', '2022-11-30T00:00:00.000000000',\n       '2022-12-10T00:00:00.000000000', '2022-12-20T00:00:00.000000000',\n       '2022-12-31T00:00:00.000000000'], dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 280B 2022-01-20 2022-01-31 ... 2022-12-31\n    crs      int64 8B 0\nAttributes:\n    axis:       T\n    long_name:  Timexarray.DataArray'time'time: 352022-01-20 2022-01-31 2022-02-10 ... 2022-12-10 2022-12-20 2022-12-31array(['2022-01-20T00:00:00.000000000', '2022-01-31T00:00:00.000000000',\n       '2022-02-10T00:00:00.000000000', '2022-02-20T00:00:00.000000000',\n       '2022-02-28T00:00:00.000000000', '2022-03-10T00:00:00.000000000',\n       '2022-03-20T00:00:00.000000000', '2022-03-31T00:00:00.000000000',\n       '2022-04-10T00:00:00.000000000', '2022-04-20T00:00:00.000000000',\n       '2022-04-30T00:00:00.000000000', '2022-05-10T00:00:00.000000000',\n       '2022-05-20T00:00:00.000000000', '2022-05-31T00:00:00.000000000',\n       '2022-06-10T00:00:00.000000000', '2022-06-20T00:00:00.000000000',\n       '2022-06-30T00:00:00.000000000', '2022-07-10T00:00:00.000000000',\n       '2022-07-20T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-10T00:00:00.000000000', '2022-08-20T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-10T00:00:00.000000000',\n       '2022-09-20T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-10T00:00:00.000000000', '2022-10-20T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000', '2022-11-10T00:00:00.000000000',\n       '2022-11-20T00:00:00.000000000', '2022-11-30T00:00:00.000000000',\n       '2022-12-10T00:00:00.000000000', '2022-12-20T00:00:00.000000000',\n       '2022-12-31T00:00:00.000000000'], dtype='datetime64[ns]')Coordinates: (2)time(time)datetime64[ns]2022-01-20 ... 2022-12-31axis :Tlong_name :Timearray(['2022-01-20T00:00:00.000000000', '2022-01-31T00:00:00.000000000',\n       '2022-02-10T00:00:00.000000000', '2022-02-20T00:00:00.000000000',\n       '2022-02-28T00:00:00.000000000', '2022-03-10T00:00:00.000000000',\n       '2022-03-20T00:00:00.000000000', '2022-03-31T00:00:00.000000000',\n       '2022-04-10T00:00:00.000000000', '2022-04-20T00:00:00.000000000',\n       '2022-04-30T00:00:00.000000000', '2022-05-10T00:00:00.000000000',\n       '2022-05-20T00:00:00.000000000', '2022-05-31T00:00:00.000000000',\n       '2022-06-10T00:00:00.000000000', '2022-06-20T00:00:00.000000000',\n       '2022-06-30T00:00:00.000000000', '2022-07-10T00:00:00.000000000',\n       '2022-07-20T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-10T00:00:00.000000000', '2022-08-20T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-10T00:00:00.000000000',\n       '2022-09-20T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-10T00:00:00.000000000', '2022-10-20T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000', '2022-11-10T00:00:00.000000000',\n       '2022-11-20T00:00:00.000000000', '2022-11-30T00:00:00.000000000',\n       '2022-12-10T00:00:00.000000000', '2022-12-20T00:00:00.000000000',\n       '2022-12-31T00:00:00.000000000'], dtype='datetime64[ns]')crs()int640GeoTransform :9.998511905625918 0.0029761904762040103 0.0 46.001488095245826 0.0 -0.0029761904761897995crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9108\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]geographic_crs_name :WGS 84grid_mapping_name :latitude_longitudehorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9108\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]towgs84 :[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]array(0)Attributes: (2)axis :Tlong_name :Time\n\n\nThe temporal range of lai_ds is longer then the fused ALOS-2 L-band and Sentinel-1 C-band datacube. To fit lai_ds object to the SAR datacube, we will need to cut the lai_ds temporal extent using the selection method (sel). Complete the following code snippet to perform the previous described selection operation.\n\nlai_ds = ...  # YOUR CODE HERE\nlai_ds.time",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Homework Exercise 4: Datacubes</span>"
    ]
  },
  {
    "objectID": "unit_02/04_homework_exercise.html#question-3",
    "href": "unit_02/04_homework_exercise.html#question-3",
    "title": "Appendix D — Homework Exercise 4: Datacubes",
    "section": "D.3 Question 3",
    "text": "D.3 Question 3\nNow that the temporal range of the LAI datacube matches that of fused_ds, we can continue by aligning the spatial coordinates, so that we can create a datacube containing both variables (LAI and SAR data). Yet again, apply the same methods as shown in the in-class exercise.\nLet’s break this down into steps first align both datacubes.\n\nAlign both datacubes. Remember to use the rioxarray package and use the default resampling method.\n\n\nlai_ds = ...  # YOUR CODE HERE\nlai_ds\n\n\nWrite the coordinates of fused_ds to the reprojected lai_ds object to prevent mistakes caused by floating point errors. Use the assign_coords method.\n\n\nlai_ds = ...  # YOUR CODE HERE\nlai_ds\n\nIf the previous operations were successfull, 3) we can merge the two variables: SAR and LAI. We use a different xarray function for this, where we combine the two variable to a xarray.DataSet with the merge function.\n\n# YOUR CODE HERE ----------------------------------------------------------\nfused_ds = ...  # combine two variables in an Xarray.Dataset\n# YOUR CODE HERE ----------------------------------------------------------\nfused_ds\n\nThe last step is the 4) resample operation to align the timestamps. Use again a median value.\n\nfused_ds = ...  # YOUR CODE HERE\n\nPlot the LAI variable with the following lines of code to check your results:\n\nfused_ds.LAI.\\\n    dropna(dim=\"time\", how=\"all\").\\\n    hvplot.image(robust=True, data_aspect=1, cmap=\"viridis\", rasterize=True).\\\n    opts(frame_height=400, aspect=\"equal\")\n\n\nto_store = fused_ds.copy()\nfor var in to_store.variables:\n    to_store[var].encoding.clear()\nto_store.to_zarr(\"fused_ds.zarr\", mode=\"w\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Homework Exercise 4: Datacubes</span>"
    ]
  },
  {
    "objectID": "unit_02/05_homework_exercise.html",
    "href": "unit_02/05_homework_exercise.html",
    "title": "Appendix E — Homework Exercise 5: SAR Wavelength and Polarization",
    "section": "",
    "text": "E.1 Question 1\nWe have seen that cross- and co-polarized signals for Sentinel-1 and ALOS-2 seem to be dependent on the type of vegetation. Let’s have a closer look at this.\nWe will try to highlight the difference between cross- and co-polarized microwave backscattering for Sentinel-1 and ALOS-2 separately. As already indicated volume scattering leads to depolarization effects, where multiple scattering can cause a change in polarization. Hence, a cross-polarized receiving antenna, such as on-board the Sentinel-1 and ALOS-2 satellites, may receive less energy from smooth bare soils than from vegetated surfaces. And the received energy for a cross-polarized receiving antenna will increase with increasing vegetation density. Hence this property of depolarization with vegetation density can be formulated as the cross-polarised ratio.\n\\(r_{cross} = \\frac{P_{VH}}{P_{VV}} = \\frac{\\gamma^0_{VH}}{\\gamma^0_{VV}}  \\quad \\text{for Sentinel-1}\\)\n\\(r_{cross} = \\frac{P_{HV}}{P_{HH}} = \\frac{\\gamma^0_{HV}}{\\gamma^0_{HH}}  \\quad \\text{for ALOS-2}\\)\nNote that in the literature, this formulation may also appear with the numerator and denominator swapped (i.e., as VV/VH instead of VH/VV), depending on the convention adopted by the authors. In this notebook you will calculate cross-polarised ratios for Sentinel-1 and ALOS-2 as reported in the above equations.\nFirst load again the same dataset.\nurl = get_intake_url()\ncat = intake.open_catalog(url)\nfused_ds = cat[\"fused_array\"].read().compute()\nfused_ds\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 307MB\nDimensions:      (sensor: 4, time: 5, y: 1528, x: 2508)\nCoordinates:\n  * sensor       (sensor) object 32B 's1_VH' 's1_VV' 'alos_HH' 'alos_HV'\n  * time         (time) datetime64[ns] 40B 2022-06-30 2022-07-31 ... 2022-10-31\n  * y            (y) float64 12kB 1.397e+06 1.397e+06 ... 1.382e+06 1.382e+06\n  * x            (x) float64 20kB 4.769e+06 4.769e+06 ... 4.794e+06 4.794e+06\n    spatial_ref  int64 8B 0\nData variables:\n    gam0         (sensor, time, y, x) float32 307MB -14.52 -14.8 ... -31.16xarray.DatasetDimensions:sensor: 4time: 5y: 1528x: 2508Coordinates: (5)sensor(sensor)object's1_VH' 's1_VV' 'alos_HH' 'alos_HV'array(['s1_VH', 's1_VV', 'alos_HH', 'alos_HV'], dtype=object)time(time)datetime64[ns]2022-06-30 ... 2022-10-31array(['2022-06-30T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000'], dtype='datetime64[ns]')y(y)float641.397e+06 1.397e+06 ... 1.382e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1397365., 1397355., 1397345., ..., 1382115., 1382105., 1382095.],\n      shape=(1528,))x(x)float644.769e+06 4.769e+06 ... 4.794e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([4769375., 4769385., 4769395., ..., 4794425., 4794435., 4794445.],\n      shape=(2508,))spatial_ref()int640GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)Data variables: (1)gam0(sensor, time, y, x)float32-14.52 -14.8 ... -30.78 -31.16array([[[[-14.5199995, -14.799999 , -15.94     , ..., -22.07     ,\n          -19.99     , -20.369999 ],\n         [-15.67     , -14.9      , -14.599999 , ..., -18.48     ,\n          -14.509999 , -16.39     ],\n         [-16.4      , -15.679999 , -14.889999 , ..., -15.42     ,\n          -11.19     , -12.62     ],\n         ...,\n         [-16.74     , -18.279999 , -21.05     , ..., -24.72     ,\n          -25.599998 , -26.369999 ],\n         [-15.349999 , -15.259999 , -17.64     , ..., -25.47     ,\n          -25.08     , -25.75     ],\n         [-15.61     , -15.98     , -16.619999 , ..., -26.32     ,\n          -26.789999 , -25.91     ]],\n\n        [[-15.049999 , -15.299999 , -14.96     , ..., -15.58     ,\n          -14.08     , -12.179999 ],\n         [-13.559999 , -13.96     , -15.73     , ..., -16.32     ,\n          -11.78     , -12.389999 ],\n         [-13.82     , -14.54     , -15.5199995, ..., -16.25     ,\n          -12.45     , -13.259999 ],\n...\n          -24.919933 , -24.837606 ],\n         [        nan,         nan,         nan, ..., -25.47786  ,\n          -25.48013  , -25.71463  ],\n         [        nan,         nan,         nan, ..., -25.465223 ,\n          -25.860966 , -26.551125 ]],\n\n        [[-14.129457 , -14.054055 , -13.846073 , ...,         nan,\n                  nan,         nan],\n         [-15.771104 , -15.154463 , -14.165511 , ...,         nan,\n                  nan,         nan],\n         [-13.967249 , -14.349602 , -14.299993 , ...,         nan,\n                  nan,         nan],\n         ...,\n         [        nan,         nan,         nan, ..., -28.712454 ,\n          -28.836363 , -29.904612 ],\n         [        nan,         nan,         nan, ..., -29.798288 ,\n          -30.100616 , -30.784294 ],\n         [        nan,         nan,         nan, ..., -30.489552 ,\n          -30.782894 , -31.163181 ]]]],\n      shape=(4, 5, 1528, 2508), dtype=float32)\nCalculate the cross-polarised ratios separately for each of the satellites with standard mathematical operations on the fused xarray and store the results in two new xarray objects. Make sure to transform the cross-polarised ratio (CR) to linear units for easier interpretation (see below for useful tips).\nSince the ratio in linear scale is:\n\\[\n\\frac{\\gamma^0_{VH,\\text{linear}}}{\\gamma^0_{VV,\\text{linear}}}\n\\]\nand the relationship between dB and linear is:\n\\[\n\\gamma^0_{\\text{dB}} = 10 \\log_{10}(\\gamma^0_{\\text{linear}})\n\\]\nthen the VH/VV cross ratio in linear units is:\n\\[\n\\frac{\\gamma^0_{VH,\\text{linear}}}{\\gamma^0_{VV,\\text{linear}}}\n= 10^{\\frac{\\gamma^0_{VH,\\text{dB}} - \\gamma^0_{VV,\\text{dB}}}{10}}\n\\]\nrcross_da_s1 = ...  # YOUR CODE HERE\nrcross_da_alos = ...  # YOUR CODE HERE\nAfter you calculate the CR, plot the results with the following code.\nLAI_mean = fused_ds.LAI.mean(\"time\")\n\nLAI_image = LAI_mean.hvplot.\\\n    image(rasterize=True, cmap='viridis', clim=(0, 6)).\\\n    opts(title=\"Mean LAI (Selectable)\", frame_height=400, aspect=\"equal\")\n\nid_sat = pd.Index([\"sentinel\", \"alos\"], name=\"sat\")\nrcross_da = xr.concat([rcross_da_s1, rcross_da_alos], id_sat)\n\n\ndef get_timeseries(x, y):\n    \"\"\"\n    Callback Function Holoviews\n\n    Parameters\n    ----------\n    x: float\n        numeric value for x selected on LAI map\n    y: float\n        numeric value for y selected on LAI map\n    \"\"\"\n\n    lai_value = LAI_mean.sel(x=x, y=y, method=\"nearest\").values\n\n    if np.isnan(lai_value):\n        select = rcross_da.where(LAI_mean.isnull())\n        label = \"Water\"\n    else:\n        mask = np.isclose(LAI_mean, lai_value, atol=0.05)\n        select = rcross_da.where(mask)\n        label = \"Mean LAI: \" + str(np.round(lai_value, 1))\n\n    time_series = select.to_dataset(\"sat\").\\\n        median([\"x\", \"y\"], skipna=True).\\\n        hvplot.scatter(ylim=(0, 0.5)).\\\n        opts(title=label, frame_height=400)\n\n    return time_series\n\n\npoint_stream = hv.streams.SingleTap(source=LAI_image)\ntime_series = hv.DynamicMap(get_timeseries, streams=[point_stream])\nLAI_image + time_series\nFigure 1: (Left) Map of MEAN LAI around Lake Garda. The pixel values can be seen by hovering your mouse over it. Clicking on the pixel will generate the timeseries for the associated mean LAI on the right hand-side. (Right) Timeseries of CR for Sentinel-1 and ALOS-2.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Homework Exercise 5: SAR Wavelength and Polarization</span>"
    ]
  },
  {
    "objectID": "unit_02/05_homework_exercise.html#question-1",
    "href": "unit_02/05_homework_exercise.html#question-1",
    "title": "Appendix E — Homework Exercise 5: SAR Wavelength and Polarization",
    "section": "",
    "text": "Tip: The calculation of the cross-ratio refers to the linear domain and therefore needs a conversion from dB to linear scale. Checkout Notebook 2 again for the conversion.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Homework Exercise 5: SAR Wavelength and Polarization</span>"
    ]
  },
  {
    "objectID": "unit_02/05_homework_exercise.html#question-2",
    "href": "unit_02/05_homework_exercise.html#question-2",
    "title": "Appendix E — Homework Exercise 5: SAR Wavelength and Polarization",
    "section": "E.2 Question 2",
    "text": "E.2 Question 2\nAnalyse the plot that you created above. Based on what you see, select the correct statements.\n\nAs a forest gets denser (higher LAI), the strength of the cross-polarized return signal will always increase, regardless of the radar band used.\nAs a forest gets denser (lower LAI), the strength of the cross-polarized return signal will not change, regardless of the radar band used.\nAt high Leaf Area Index, the cross-polarized backscatter returns are stronger at L-band than at C-band wavelengths.\nThe received energy of co-polarized backscattering at high LAI is higher for L-band than for C-band wavelength",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Homework Exercise 5: SAR Wavelength and Polarization</span>"
    ]
  },
  {
    "objectID": "unit_02/05_homework_exercise.html#question-3",
    "href": "unit_02/05_homework_exercise.html#question-3",
    "title": "Appendix E — Homework Exercise 5: SAR Wavelength and Polarization",
    "section": "E.3 Question 3",
    "text": "E.3 Question 3\nFor this question we will create a boxplot to analyse the sensitivity of CR with to changes in LAI. Sensitivity means how high a response is when we change another variable, like LAI in this case. So an increased sensitivity means a higher response for the same increase in LAI. The boxplot uses boxes to illustrate the distributions of binned LAI values. Box limits indicate the range of the central 50% of the data (a.k.a inter quartile range: IQR), with the median value depicted as a central red line. The whisker limits demarcate 1.5 times the distance of the IQR. Values outside of the whiskers are considered outliers. Outliers have been eliminated in this plot to make the plot more readable.\n\n# labels for LAI bins\nranger = [str(x).zfill(1) for x in range(1, 6)]\n\n# fuse LAI and ALOS-2 and Sentinel-1 CR\nLAI_df = fused_ds.LAI.to_dask_dataframe()\nLAI_df[\"LAI\"] = LAI_df[\"LAI\"].\\\n    map_partitions(pd.cut, bins=range(6), labels=ranger)\nLAI_df[\"alos\"] = rcross_da_alos.to_dask_dataframe()[\"gam0\"]\nLAI_df[\"s1\"] = rcross_da_s1.to_dask_dataframe()[\"gam0\"]\n\n# boxplot\nax = LAI_df.compute().plot.box(column=[\"s1\", \"alos\"], by=\"LAI\",\n                               showfliers=False, figsize=(15, 6))\nax[0].set_xlabel(r\"$\\text{LAI}$ [$m^2 \\cdot m^{-2}$]\")\nax[0].set_ylabel(r\"$\\text{CR}$ [$m^2 \\cdot m^{-2}$]\")\nax[1].set_xlabel(r\"$\\text{LAI}$ [$m^2 \\cdot m^{-2}$]\")\nax[1].set_ylabel(r\"$\\text{CR}$ [$m^2 \\cdot m^{-2}$]\")\n\nFigure 2: Boxplot for CR of Sentinel-1 and ALOS-2 for binned LAI values\nAnalyse the boxplot above. Based on what you see in the plot, can you tell whether the L-band or the C-band sensor have different sensibilities with regards to changes in vegetation? Can you also tell to what type of vegetation each satellite-sensor is most sensitive to? Explain your reasoning in detail.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Homework Exercise 5: SAR Wavelength and Polarization</span>"
    ]
  },
  {
    "objectID": "unit_02/06_homework_exercise.html",
    "href": "unit_02/06_homework_exercise.html",
    "title": "Appendix F — Homework Exercise 6: Dielectric Properties of Natural Media",
    "section": "",
    "text": "F.1 RGB Composite\nNot only radar reflectivity vary according to different land cover classes. The backscattered signal also depends on the change of the imagined natural media over time. We may want to capture in one single image how different land covers comparably change across the same time range. A way to do achieve that is by generating a RGB composite. But what is a RGB composite? It all comes down to combining three image bands into one picture by setting each band as either Red, Green or Blue channel.\nIn order to highlight the temporal variability of the backscatter response, we want to select 3 images with maximal distance in time. Therefore we take the first, the middle and the last time available out of the input images available for this exercise. We use RGB coloring where we want to color the first image with Red, the second with Green and the Third with Blue color. When we overlay the images the color will show the differences over time.\nimport intake\nimport numpy as np  # noqa\nimport pandas as pd\nimport xarray as xr\nimport rasterio\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom functools import partial\nfrom shapely.geometry import box\n\nfrom mrs.catalog import CorineColorCollection, get_intake_url",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Homework Exercise 6: Dielectric Properties of Natural Media</span>"
    ]
  },
  {
    "objectID": "unit_02/06_homework_exercise.html#load-sentinel-1-data",
    "href": "unit_02/06_homework_exercise.html#load-sentinel-1-data",
    "title": "Appendix F — Homework Exercise 6: Dielectric Properties of Natural Media",
    "section": "F.2 Load Sentinel-1 Data",
    "text": "F.2 Load Sentinel-1 Data\n\nurl = get_intake_url()\ncat = intake.open_catalog(url)\nsig0_da = cat.neusiedler.read().sig0.compute()\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Homework Exercise 6: Dielectric Properties of Natural Media</span>"
    ]
  },
  {
    "objectID": "unit_02/06_homework_exercise.html#select-the-dates-of-interest",
    "href": "unit_02/06_homework_exercise.html#select-the-dates-of-interest",
    "title": "Appendix F — Homework Exercise 6: Dielectric Properties of Natural Media",
    "section": "F.3 Select the Dates of Interest",
    "text": "F.3 Select the Dates of Interest\nTo create an RGB composite, we need to choose three distinct dates. It’s recommended to select dates that are spaced out to capture noticeable changes over time (e.g., first available date, second date as the middle date of the datacube time window, third date as the last availavable date). Pay attention to the season as well, as vegetation and other environmental factors often change significantly throughout the year.\nTips:\n\nSelect your dates from the sig0_da object and define them using the numpy datetime64 data type.\nUse the sel method with nearest neighbor (method=\\\"nearest\\\") interpolation method to obtain the resulting sig0_rgb_da object.\nDo not forget to use the compute() method (when you use the sel method) to finally load the result into memory.\n\n\n# YOUR CODE HERE ----------------------------------------------------------\nfirst = ...  # YOUR CODE HERE\nsecond = ...  # YOUR CODE HERE\nthird = ...  # YOUR CODE HERE\n# YOUR CODE HERE ----------------------------------------------------------\n\nsig0_rgb_da = ... # YOUR CODE HERE\nsig0_rgb_da\n\n\nF.3.1 Map the backscatter to RGB values\nTo visualize backscatter data in RGB, we need to transform the data into values between 0 and 1 to match it to colors. The first step is to convert the backscattering values into linear scale so we can perform meaningful calculations. Now we can normalise the values to be between 0 and 1 using the following formula: \\[\nsig0_{norm} = \\frac{sig0 - sig0_{min}}{sig0_{98th} - sig0_{min}}\n\\] We replaced the traditional maximum value with the 98th quantile in our normalization process to enhance robustness against outliers. Due to the nature of backscattering some sigma nought values get very high so taking the 98th quantile is important. The linear backscattering values are bounded by 0 so using for example the 2nd quantile is not necessary. After applying the formula, any values exceeding the 98th quantile will be greater than 1. We map these values to 1 to ensure they fit within our specified range.”\n\nlinear_ds = 10 ** (sig0_rgb_da / 10)\n\nmin_value = linear_ds.quantile(0.02).item()\nmax_robust = linear_ds.quantile(0.98).item()\n\n\ndef normalize(val, min, max):\n    \"\"\"\n    Min-max normalize value\n\n    Parameters\n    ----------\n    val: float\n        target\n    min: float\n        minimum value of range\n    max: float\n        maximum value of range\n    Returns\n    -------\n    float\n    \"\"\"\n\n    return (val - min) / (max - min)\n\n\nnormalized_ds = normalize(linear_ds, min_value, max_robust).clip(min=0, max=1)\n\nfig, ax = plt.subplots(figsize=(8, 5))\nnormalized_ds.isel(time=0).plot().axes.set_aspect(\"equal\")\nplt.tight_layout()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Homework Exercise 6: Dielectric Properties of Natural Media</span>"
    ]
  },
  {
    "objectID": "unit_02/06_homework_exercise.html#individual-rgb-channels",
    "href": "unit_02/06_homework_exercise.html#individual-rgb-channels",
    "title": "Appendix F — Homework Exercise 6: Dielectric Properties of Natural Media",
    "section": "F.4 Individual RGB Channels",
    "text": "F.4 Individual RGB Channels\nLet´s first plot the three normalized images separately (Red = Oldest image, Green = Middle image, Blue = Newest image).\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nnormalized_ds.isel(time=0).plot(ax=axes[0], cmap=\"Reds\")\nnormalized_ds.isel(time=1).plot(ax=axes[1], cmap=\"Greens\")\nnormalized_ds.isel(time=2).plot(ax=axes[2], cmap=\"Blues\")\n\naxes[0].set_aspect(\"equal\")\naxes[1].set_aspect(\"equal\")\naxes[2].set_aspect(\"equal\")\n\nplt.tight_layout()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Homework Exercise 6: Dielectric Properties of Natural Media</span>"
    ]
  },
  {
    "objectID": "unit_02/06_homework_exercise.html#plotting-the-rgb-composite",
    "href": "unit_02/06_homework_exercise.html#plotting-the-rgb-composite",
    "title": "Appendix F — Homework Exercise 6: Dielectric Properties of Natural Media",
    "section": "F.5 Plotting the RGB Composite",
    "text": "F.5 Plotting the RGB Composite\nAnd finally, let´s plot the RGB composite.\n\nfig, ax = plt.subplots(figsize=(8, 5))\n\nnormalized_ds.plot.imshow()\nax.set_aspect('equal')\n\nplt.tight_layout()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Homework Exercise 6: Dielectric Properties of Natural Media</span>"
    ]
  },
  {
    "objectID": "unit_02/06_homework_exercise.html#question",
    "href": "unit_02/06_homework_exercise.html#question",
    "title": "Appendix F — Homework Exercise 6: Dielectric Properties of Natural Media",
    "section": "F.6 Question",
    "text": "F.6 Question\nWhat can you infer about the landscape features (focus on the crops appearance, forested areas, water bodies, urban areas) based on the variations in color across the image? Describe how you might interpret the colors in terms of changes over time, surface properties, and dielectric properties of the natural and artificial media. Focus on the crops: keeping in mind the polarization of the visualized backscatter data (i.e., VV) and its sensitivity to smoother surfaces (which indicates lack of vegetation), what does the blue color represent?",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Homework Exercise 6: Dielectric Properties of Natural Media</span>"
    ]
  },
  {
    "objectID": "unit_03/07_homework_exercise.html",
    "href": "unit_03/07_homework_exercise.html",
    "title": "Appendix G — Homework Exercise 7: Speckle Statistics",
    "section": "",
    "text": "G.1 Question 1\nDuring the in-class exercise, we learned about the origin of speckles and ways to mitigate it. In this exercise, your task will be to apply a Lee filter (spatial filter) with different kernel sizes to the same study area.\nWe will use already known data, which consists of Sentinel-1 sigma naught \\(\\sigma^0\\) images focusing on Lake Neusiedl and the surrounding area, where the CORINE land cover is used for land cover-based visualization and analysis.\nurl = get_intake_url()\ncat = intake.open_catalog(url)\nsig0_da = cat.speckle.read().sig0.compute()\nsig0_da\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'sig0' (time: 7, y: 1221, x: 1230)&gt; Size: 84MB\narray([[[ -8.5 , -10.65, -12.07, ..., -22.27, -20.91, -21.92],\n        [ -9.  , -10.03, -10.82, ..., -16.46, -16.9 , -21.84],\n        [ -6.74,  -7.87,  -8.1 , ..., -17.41, -22.64, -23.01],\n        ...,\n        [ -8.74,  -7.44,  -6.69, ..., -10.85,  -8.39,  -7.08],\n        [ -9.39,  -9.55,  -8.9 , ..., -13.  , -11.03,  -9.15],\n        [-10.86, -10.84,  -9.7 , ..., -17.47, -14.58, -10.65]],\n\n       [[-10.39, -11.92, -11.74, ..., -19.02, -20.28, -17.92],\n        [ -8.65, -14.64, -12.34, ..., -21.77, -19.55, -16.67],\n        [ -8.11, -11.29, -10.25, ..., -23.16, -20.23, -16.73],\n        ...,\n        [-10.69,  -7.85,  -6.51, ..., -11.02,  -8.21,  -7.69],\n        [-12.83, -10.4 ,  -9.26, ..., -14.74,  -9.62,  -7.99],\n        [-13.76, -12.13, -12.08, ..., -18.51, -12.62,  -9.14]],\n\n       [[ -9.47, -14.49, -15.86, ..., -23.19, -24.68, -25.28],\n        [ -9.7 , -13.62, -12.49, ..., -27.02, -23.13, -22.35],\n        [-10.84, -12.3 , -12.61, ..., -23.46, -22.93, -21.64],\n        ...,\n...\n        [ -9.82,  -9.11,  -8.73, ...,  -9.79,  -7.33,  -6.92],\n        [-12.23, -11.64,  -9.59, ..., -12.29,  -7.65,  -8.14],\n        [-13.6 , -13.41, -11.73, ..., -19.82, -12.53, -11.83]],\n\n       [[-12.49, -12.55, -12.89, ..., -21.35, -23.29, -23.87],\n        [-12.15, -12.38, -14.03, ..., -18.07, -23.53, -23.23],\n        [-12.41, -12.52, -14.08, ..., -18.7 , -21.47, -22.17],\n        ...,\n        [ -6.87,  -5.98,  -5.32, ..., -18.47, -12.26, -11.2 ],\n        [-11.18,  -6.31,  -6.12, ..., -20.17, -12.56, -11.61],\n        [-11.98,  -9.02,  -8.46, ..., -13.06, -10.4 ,  -9.  ]],\n\n       [[ -6.41,  -6.59,  -7.16, ..., -22.25, -25.96, -25.45],\n        [ -6.75,  -9.42,  -9.54, ..., -20.65, -26.34, -23.53],\n        [ -8.24, -12.04, -10.46, ..., -20.65, -20.63, -21.05],\n        ...,\n        [ -6.64,  -5.06,  -4.89, ..., -13.67, -12.26,  -9.96],\n        [ -9.62,  -8.06, -10.02, ..., -16.11, -14.74, -10.64],\n        [-11.93, -11.41, -12.68, ..., -19.01, -14.32, -14.22]]],\n      shape=(7, 1221, 1230))\nCoordinates:\n  * time         (time) datetime64[ns] 56B 2023-08-17T16:51:22 ... 2023-10-28...\n  * y            (y) float64 10kB 1.571e+06 1.571e+06 ... 1.559e+06 1.559e+06\n  * x            (x) float64 10kB 5.282e+06 5.282e+06 ... 5.294e+06 5.294e+06\n    spatial_ref  int64 8B 0xarray.DataArray'sig0'time: 7y: 1221x: 1230-8.5 -10.65 -12.07 -10.45 -8.65 ... -21.7 -22.42 -19.01 -14.32 -14.22array([[[ -8.5 , -10.65, -12.07, ..., -22.27, -20.91, -21.92],\n        [ -9.  , -10.03, -10.82, ..., -16.46, -16.9 , -21.84],\n        [ -6.74,  -7.87,  -8.1 , ..., -17.41, -22.64, -23.01],\n        ...,\n        [ -8.74,  -7.44,  -6.69, ..., -10.85,  -8.39,  -7.08],\n        [ -9.39,  -9.55,  -8.9 , ..., -13.  , -11.03,  -9.15],\n        [-10.86, -10.84,  -9.7 , ..., -17.47, -14.58, -10.65]],\n\n       [[-10.39, -11.92, -11.74, ..., -19.02, -20.28, -17.92],\n        [ -8.65, -14.64, -12.34, ..., -21.77, -19.55, -16.67],\n        [ -8.11, -11.29, -10.25, ..., -23.16, -20.23, -16.73],\n        ...,\n        [-10.69,  -7.85,  -6.51, ..., -11.02,  -8.21,  -7.69],\n        [-12.83, -10.4 ,  -9.26, ..., -14.74,  -9.62,  -7.99],\n        [-13.76, -12.13, -12.08, ..., -18.51, -12.62,  -9.14]],\n\n       [[ -9.47, -14.49, -15.86, ..., -23.19, -24.68, -25.28],\n        [ -9.7 , -13.62, -12.49, ..., -27.02, -23.13, -22.35],\n        [-10.84, -12.3 , -12.61, ..., -23.46, -22.93, -21.64],\n        ...,\n...\n        [ -9.82,  -9.11,  -8.73, ...,  -9.79,  -7.33,  -6.92],\n        [-12.23, -11.64,  -9.59, ..., -12.29,  -7.65,  -8.14],\n        [-13.6 , -13.41, -11.73, ..., -19.82, -12.53, -11.83]],\n\n       [[-12.49, -12.55, -12.89, ..., -21.35, -23.29, -23.87],\n        [-12.15, -12.38, -14.03, ..., -18.07, -23.53, -23.23],\n        [-12.41, -12.52, -14.08, ..., -18.7 , -21.47, -22.17],\n        ...,\n        [ -6.87,  -5.98,  -5.32, ..., -18.47, -12.26, -11.2 ],\n        [-11.18,  -6.31,  -6.12, ..., -20.17, -12.56, -11.61],\n        [-11.98,  -9.02,  -8.46, ..., -13.06, -10.4 ,  -9.  ]],\n\n       [[ -6.41,  -6.59,  -7.16, ..., -22.25, -25.96, -25.45],\n        [ -6.75,  -9.42,  -9.54, ..., -20.65, -26.34, -23.53],\n        [ -8.24, -12.04, -10.46, ..., -20.65, -20.63, -21.05],\n        ...,\n        [ -6.64,  -5.06,  -4.89, ..., -13.67, -12.26,  -9.96],\n        [ -9.62,  -8.06, -10.02, ..., -16.11, -14.74, -10.64],\n        [-11.93, -11.41, -12.68, ..., -19.01, -14.32, -14.22]]],\n      shape=(7, 1221, 1230))Coordinates: (4)time(time)datetime64[ns]2023-08-17T16:51:22 ... 2023-10-...array(['2023-08-17T16:51:22.000000000', '2023-08-29T16:51:23.000000000',\n       '2023-09-10T16:51:24.000000000', '2023-09-22T16:51:24.000000000',\n       '2023-10-04T16:51:24.000000000', '2023-10-16T16:51:24.000000000',\n       '2023-10-28T16:51:24.000000000'], dtype='datetime64[ns]')y(y)float641.571e+06 1.571e+06 ... 1.559e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1570955., 1570945., 1570935., ..., 1558775., 1558765., 1558755.],\n      shape=(1221,))x(x)float645.282e+06 5.282e+06 ... 5.294e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([5281995., 5282005., 5282015., ..., 5294265., 5294275., 5294285.],\n      shape=(1230,))spatial_ref()int640GeoTransform :5281990.0 10.0 0.0 1570960.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)\nLet’s build up the Lee filter function:\ndef lee_filter(raster, size=...):\n    \"\"\"\n    Parameters:\n    raster: ndarray\n\n    size: int\n\n    Returns:\n    filtered_image (ndarray): The filtered image with reduced speckle noise\n    \"\"\"\n\n    filtered_image = ...  # YOUR CODE HERE\n\n    return filtered_image",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Homework Exercise 7: Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "unit_03/07_homework_exercise.html#question-2",
    "href": "unit_03/07_homework_exercise.html#question-2",
    "title": "Appendix G — Homework Exercise 7: Speckle Statistics",
    "section": "G.2 Question 2",
    "text": "G.2 Question 2\nApply your function and compute the Lee filter for at least two different kernel sizes (size number must be odd).\n\nsig0_da.data = ...  # YOUR CODE HERE\n\nPlot you results usign the following code:\n\nsig0_da.hvplot.image(\n    x=\"x\", y=\"y\", robust=True, data_aspect=1, cmap=\"Greys_r\", rasterize=True\n).opts(frame_height=600, framewise=False, aspect=\"equal\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Homework Exercise 7: Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "unit_03/07_homework_exercise.html#question-3",
    "href": "unit_03/07_homework_exercise.html#question-3",
    "title": "Appendix G — Homework Exercise 7: Speckle Statistics",
    "section": "G.3 Question 3",
    "text": "G.3 Question 3\nBased on your plotted results, select which of the below statement is correct:\n\nEnlarging the kernel increases the degree of spatial averaging, which effectively degrades the image’s spatial resolution by suppressing local detail.\nThe smaller the kernel size, the more speckle noise is removed.\nThe choice of the kernel size has no impact on the speckle noise removal.\nTo preserve the temporal resolution of an image, speckle should not be removed.\nThe larger the kernel size, the more speckle noise is removed.\nA temporal filtering approach is generally preferable to a purely spatial filtering approach for speckle reduction, even when surface changes are evident across temporal observations of the same scene.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Homework Exercise 7: Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "unit_03/08_homework_exercise.html",
    "href": "unit_03/08_homework_exercise.html",
    "title": "Appendix H — Homework Exercise 8: Generation and Interpretation of an Interferogram using Sentinel-1 Imagery",
    "section": "",
    "text": "H.1 Load the data\nThe following data were acquired from Sentinel-1 on April 23, 2018, from 16:15:24 to 16:15:51 over the region of Hawaii, with Descending orbit direction. Use the provided code to load and plot the preprocessed SAR interferometric data. Observe, analyse, and visually interpret the results.\nurl = get_intake_url()\ncat = intake.open_catalog(url)\nds = cat.ex8.read().compute()\nds\n\nhttps://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 105MB\nDimensions:      (y: 4131, x: 3179)\nCoordinates:\n  * y            (y) float64 33kB 20.14 20.14 20.14 20.14 ... 19.1 19.1 19.1\n  * x            (x) float64 25kB -155.5 -155.5 -155.5 ... -154.7 -154.7 -154.7\n    spatial_ref  int64 8B 0\nData variables:\n    CohBand      (y, x) float32 53MB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n    PhaseBand    (y, x) float32 53MB 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0xarray.DatasetDimensions:y: 4131x: 3179Coordinates: (3)y(y)float6420.14 20.14 20.14 ... 19.1 19.1array([20.139453, 20.139201, 20.138949, ..., 19.100535, 19.100283, 19.100032],\n      shape=(4131,))x(x)float64-155.5 -155.5 ... -154.7 -154.7array([-155.499865, -155.499614, -155.499362, ..., -154.700543, -154.700291,\n       -154.70004 ], shape=(3179,))spatial_ref()int640GeoTransform :-155.51685341513007 0.00025167578292311846 0.0 20.13957861432755 0.0 -0.00025167578292311846crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]geographic_crs_name :WGS 84grid_mapping_name :latitude_longitudehorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]array(0)Data variables: (2)CohBand(y, x)float320.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0AREA_OR_POINT :AreaSTATISTICS_APPROXIMATE :YESSTATISTICS_MAXIMUM :0.9790118932724STATISTICS_MEAN :0.07907648124917STATISTICS_MINIMUM :0STATISTICS_STDDEV :0.14581841958814STATISTICS_VALID_PERCENT :100TIFFTAG_RESOLUTIONUNIT :1 (unitless)TIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], shape=(4131, 3179), dtype=float32)PhaseBand(y, x)float320.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0AREA_OR_POINT :AreaSTATISTICS_APPROXIMATE :YESSTATISTICS_MAXIMUM :3.1328022480011STATISTICS_MEAN :-0.02452060501156STATISTICS_MINIMUM :-3.1353642940521STATISTICS_STDDEV :0.71084059253527STATISTICS_VALID_PERCENT :100TIFFTAG_RESOLUTIONUNIT :1 (unitless)TIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], shape=(4131, 3179), dtype=float32)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Homework Exercise 8: Generation and Interpretation of an Interferogram using Sentinel-1 Imagery</span>"
    ]
  },
  {
    "objectID": "unit_03/08_homework_exercise.html#plotting-the-data",
    "href": "unit_03/08_homework_exercise.html#plotting-the-data",
    "title": "Appendix H — Homework Exercise 8: Generation and Interpretation of an Interferogram using Sentinel-1 Imagery",
    "section": "H.2 Plotting the data",
    "text": "H.2 Plotting the data\n\nstep = 4\n\ncmap_hls = sns.color_palette(\"hls\", n_colors=256).as_hex()\n\nds = ds.where(ds != 0)\nigf_data = ds.PhaseBand.isel(x=slice(0, -1, step), y=slice(0, -1, step))\ncoh_da = ds.CohBand.isel(x=slice(0, -1, step), y=slice(0, -1, step))\n\nigf_plot = igf_data.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    cmap=cmap_hls,\n    width=600,\n    height=600,\n    dynamic=False\n)\n\n\ncoh_plot = coh_da.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    cmap=\"viridis\",\n    width=600,\n    height=600,\n    dynamic=False,\n).opts(clim=(0, 1))\n\n(igf_plot + coh_plot).opts(shared_axes=True)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Homework Exercise 8: Generation and Interpretation of an Interferogram using Sentinel-1 Imagery</span>"
    ]
  },
  {
    "objectID": "unit_03/08_homework_exercise.html#question-1",
    "href": "unit_03/08_homework_exercise.html#question-1",
    "title": "Appendix H — Homework Exercise 8: Generation and Interpretation of an Interferogram using Sentinel-1 Imagery",
    "section": "H.3 Question 1",
    "text": "H.3 Question 1\nPlease refer to the above plots. Which of the following statements are correct?\n\nThe image on the left shows a phase interferogram.\nThe image on the right shows an amplitude interferogram, also called coherence.\nAmplitude, backscatter and coherence are linearly correlated.\nCoherence is mainly related to a decrease in backscatter between two acquistions.\nThe image on the right shows a RTC sigma nougth backscatter.\n\nFocus on the left plot. Which of the following statements are correct?\n\nThe fringe pattern could be indicative of both local surface topography and ground deformation.\nThe fringe pattern is indicative of a loss of coherence.\nFocus on the left part of the image, where you see the circular fringe pattern: the deformation is faster towards the center of the circular pattern.\n\nDon’t change anything in the next cell, besides the step for sampling (skipping pixels in the plot), if the plotting takes too long to finish.\n\ncmap_hls = ListedColormap(sns.color_palette(\"hls\", 256).as_hex())\n\n\ndef array_to_img(data_array, cmap=\"viridis\"):\n    \"\"\"Convert an xarray DataArray to a base64-encoded PNG image.\"\"\"\n    fig, ax = plt.subplots(figsize=(6, 6), dpi=600)\n    data_array.plot(ax=ax, cmap=cmap, add_colorbar=False, add_labels=False)\n    ax.set_axis_off()\n    buf = BytesIO()\n    plt.savefig(\n        buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0, transparent=True\n    )\n    plt.close(fig)\n    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n\n\n# Prepare data\nstep = 1\nigf_image = array_to_img(\n    ds.PhaseBand.isel(x=slice(0, -1, step), y=slice(0, -1, step)),\n    cmap=cmap_hls,\n)\ncoh_image = array_to_img(\n    ds.CohBand.isel(x=slice(0, -1, step), y=slice(0, -1, step))\n)\n\n# Map setup and overlay function\nbounds = [\n    [float(ds.y.min()), float(ds.x.min())],\n    [float(ds.y.max()), float(ds.x.max())],\n]\nm = folium.Map(location=[ds.y.median(), ds.x.median()], zoom_start=10)\nfolium.TileLayer(\n    tiles=(\n        \"https://server.arcgisonline.com/ArcGIS/rest/\"\n        + \"services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n    ),\n    attr=\"Tiles &copy; Esri &mdash; Source: Esri, DeLorme, NAVTEQ\",\n    name=\"ESRI World Imagery\",\n).add_to(m)\n\n\ndef overlay_image(map_obj, img_base64, bounds, name):\n    folium.raster_layers.ImageOverlay(\n        image=f\"data:image/png;base64,{img_base64}\",\n        bounds=bounds,\n        opacity=0.65,\n        name=name,\n    ).add_to(map_obj)\n\n\n# Add images and controls\noverlay_image(m, igf_image, bounds, \"IGF Data\")\noverlay_image(m, coh_image, bounds, \"Coherence Data\")\nfolium.LayerControl().add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Homework Exercise 8: Generation and Interpretation of an Interferogram using Sentinel-1 Imagery</span>"
    ]
  },
  {
    "objectID": "unit_03/08_homework_exercise.html#question-2",
    "href": "unit_03/08_homework_exercise.html#question-2",
    "title": "Appendix H — Homework Exercise 8: Generation and Interpretation of an Interferogram using Sentinel-1 Imagery",
    "section": "H.4 Question 2",
    "text": "H.4 Question 2\nPlease refer to the above plot, select the “IGF Data” layer, and select the correct statements:\n\nThe interferogram above depicts ground deformation due to a landslide event.\nThe interferogram above depicts ground deformation due to a volcanic eruption event.\nThe interferogram above depicts ground deformation due to a tsunami event.\nThe interferogram above show negligible evidence of ground deformation.\n\nPlease refer to the above plot, select the “Coherence Data” layer, and select the correct statements:\n\nThe coherence is high (bright color) over urban areas.\nThe coherence is low (dark color) over forested areas.\nThe coherence is high over bare soil (non-forested areas).\nHigh coherence is typically seen in areas affected by high rates of change in surface structure, moisture and vegetation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Homework Exercise 8: Generation and Interpretation of an Interferogram using Sentinel-1 Imagery</span>"
    ]
  },
  {
    "objectID": "unit_03/09_homework_exercise.html",
    "href": "unit_03/09_homework_exercise.html",
    "title": "Appendix I — Homework Exercise 9: Phase Unwrapping Exercise",
    "section": "",
    "text": "I.1 Question 1\nYour task in this exercise is to read the provided data, plot it, unwrap and plot the phase, and calculate the displacement. Then interpret your results. The following data were acquired from Sentinel-1 on April 23, 2018, from 16:15:24 to 16:15:51 over the region of Hawaii (same data as 08_homework_exercise).\nPlot the above provided data. Please note that we are plotting images in Slant Range geometry (East-West flipped due to the descending acquisition pass).\nfig, axes = plt.subplots(1,3, figsize=(15,5))\nds.phase.where(mask).plot.imshow(cmap=cmap_cyc, ax=axes[0]).axes.set_title('Phase')\n# YOUR CODE HERE -&gt; (Plot intensity map)\n# YOUR CODE HERE -&gt; (Plot coherence map)\nplt.tight_layout()\ndef unwrap_array(data: xr.DataArray,\n                 mask: xr.DataArray = True,\n                 coherence: xr.DataArray = None,\n                 mask_nodata_value: int = 0,\n                 coh_low_threshold: float = None,\n                 coh_high_threshold: float = None,\n                 nlooks=1.0, cost=\"smooth\", init=\"mcf\",\n                 **kwargs) -&gt; xr.DataArray:\n    \"\"\"\n    Unwraps the phase data using the snaphu algorithm.\n\n    data: xarray DataArray with complex numbers\n    mask: xarray DataArray with mask values\n    coherence: xarray DataArray with coherence values (optional)\n    mask_nodata_value: Value of the no data pixels in the mask\n    coh_low_threshold: Lower threshold for the coherence values\n    coh_high_threshold: Higher threshold for the coherence values\n\n    Return: xarray DataArray with the unwrapped phase\n    \"\"\"\n\n    # Create a mask for areas with no data\n    if mask is True:\n        mask = (data.real != mask_nodata_value).astype(bool)\n\n    # Apply coherence thresholds if provided\n    if coherence is not None:\n        if coh_low_threshold is not None:\n            coh_mask = (coherence &gt;= coh_low_threshold).astype(bool)\n            mask = mask & coh_mask\n        if coh_high_threshold is not None:\n            coh_mask = (coherence &lt;= coh_high_threshold).astype(bool)\n            mask = mask & coh_mask\n\n    # Apply the mask to the data\n    data = data.where(mask)\n\n    if coherence is None:\n        coherence = np.ones_like(data.real)\n\n    # Unwrap the phase (already in complex form)\n    unw, _ = snaphu.unwrap(data,\n                           coherence, nlooks=nlooks,\n                           cost=cost, init=init,\n                           mask=mask, **kwargs)\n\n    # clear snaphu output\n    clear_output()\n\n    # Build xarray DataArray with the unwrapped phase\n    unw_da = xr.DataArray(unw, coords=data.coords, dims=data.dims)\n\n    # Mask the unwrapped phase\n    unw_da = unw_da.where(mask)\n    return unw_da",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Homework Exercise 9: Phase Unwrapping Exercise</span>"
    ]
  },
  {
    "objectID": "unit_03/09_homework_exercise.html#question-2",
    "href": "unit_03/09_homework_exercise.html#question-2",
    "title": "Appendix I — Homework Exercise 9: Phase Unwrapping Exercise",
    "section": "I.2 Question 2",
    "text": "I.2 Question 2\nUse the above function to unwrap the given interferogram and to plot your result. Use a coherence threshold of 0.2 for your unwrapping and use the provided lines of code below to coarsen the input (to fasten the process). Kernels with values higher than 3 might lead the unwrapping function to crash, therefore please do not change it. It might take up to 1 or 2 minutes to execute the function, let the code run, and the output be printed (it will be cleared out at the end).\n\n# coarsen \nkernel = 3\nds = ds.coarsen(x=kernel, y=kernel, boundary=\"trim\").mean()\n\n\nunwrapped = ... # YOUR CODE HERE -&gt; perform unwrapping function\n\nunwrapped.plot.imshow(cmap=cmap_cyc)\n\n\ndef displacement(unwrapped, lambda_val: float = 0.056) -&gt; xr.DataArray:\n    \"\"\"\n    Calculates the displacement from the unwrapped phase\n\n    unw: xarray DataArray with the unwrapped phase\n    unw: xr.DataArray\n    lambda_val: Wavelength of the radar signal\n    lambda_val: float\n\n    Return: xarray DataArray with the displacement\n    \"\"\"\n    disp = unwrapped * - lambda_val / (4 * np.pi)\n    return disp",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Homework Exercise 9: Phase Unwrapping Exercise</span>"
    ]
  },
  {
    "objectID": "unit_03/09_homework_exercise.html#question-3",
    "href": "unit_03/09_homework_exercise.html#question-3",
    "title": "Appendix I — Homework Exercise 9: Phase Unwrapping Exercise",
    "section": "I.3 Question 3",
    "text": "I.3 Question 3\nUse the above function to calculate the displacement from the unwrapped interferogram, then plot your result with the correct colormap. Can you guess which kind of phenomenon is responsible for the ground surface displacement that you observe? Elaborate on the direction of the displacement movement (is it towards or away from satellite?)\n\n# YOUR CODE HERE -&gt; perform displacement function\n# YOUR CODE HERE -&gt; plot displacement map",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Homework Exercise 9: Phase Unwrapping Exercise</span>"
    ]
  }
]